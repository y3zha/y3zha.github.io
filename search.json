[{"title":"树状数组","url":"/2019/12/02/BinaryIndexTree/","content":"树状数组一、树状数组概念Binary Indexed Tree，用于维护前缀信息的结构，对前缀信息处理也十分高校，用于解决前缀信息问题和区间类问题。\n比如：给定一个数组，实现两个函数\n\nupdate(int index,int val)，将数组下标为index的元素改为val\nquerySum(int start,int end)，返回区间内元素和\n\n这两个用线段树求过很多遍了。树状数组也是通过前缀和的思想来完成单点更新和区间查询。它比线段树用的空间更小，速度更快。\n二、树状数组算法分析注意：树状数组的下标从 1 开始计数。定义数组 C 是一个对原始数组 A 的预处理数组。\n由原数组构造树状数组\n\n\n\n\n\n\n结论：C[i]来自几个数组A中的元素:取决于i的二进制末尾有几个连续的0。比 如有k个0，那么C[i]来自2^k^个A中的元素。\n\n\n如果i是当前位置，当前有  个来自A中的元素，有哪  个呢？就是从C[i]的正下方出发，往前数  个，C[i]就是这2^k^个数的和。\n定义一个  函数，就是把下标i传到函数中来，返回 ，lowbit表示C[i]这个数值是由A中的多少个元素相加得来的。（根据上面一段，你还能找到这几个元素是啥，从C[i]的正下方开始往前数2^k^个）\n怎么找父亲节点？i+lowbit(i) = 父亲比如C[4]，4的lowbit是4，它有个宽度为4的梯子，这个梯子就是它到它父亲的距离宽度。4+lowbit(4) = 8。再比如6，6的lowbit是2，6+2 = 8\n\n三、lowbit函数lowbit函数用到了补码相关知识。给定一个数，比如12，我们能求得它的二进制1100，如何求-12的二进制？实际上二进制前面有个符号位，正数前面符号位是0，负数前面符号位是1，12的二进制实际上是01100，那么求-12的二进制有两步\n\n首先把符号位从0改成1，然后对12每位取反。变成10011\n最后+1，即10011+1 = 10100，这就是-12的二进制\n\n推荐一篇关于原码、反码、补码博客\nlowbit(i) = 2^k，它就是利用了正数和负数的二进制\nnum &amp; (-num) = 2^k\n\n\n\n四、树状数组的构建、修改、查询1、构建把原始数组A和预处理数组C都初始化为0，每更新一个元素，都要把它的值累加到它父亲的值上面去。比如初始化A1后，要把它的值累加到它父亲C1上面去，C1接收到值后，还要把C1的值传递给C2，然后C2传递给C4，C4传递给C8，如果A1的值为10，那第一次更新完就是这个样子\n\n再更新A2，C2就要开始累加A2的值，并传给C2的父亲们，比如A2为5，就是下面这样子\n\n2、更新比如我要把A1从10改为1，那么就会有一个差值delta为9，C1更新成1，然后不断传给它的父亲们继续更新。\n3、查询想要查询区间[i,j]的和，首先要查询区间[1,j]（树状数组起点从1开始的）和区间[1,i-1]的和，前者减去后者就是我们要求的答案。\n这里还有个求前缀和[1,i]的公式，是推导出来的，sum(i) = sum(i - lowbit(i)) + C[i]\nclass BinaryIndexedTree{        private int[] A, C; //定义原始数组A和预处理数组C        //init        public BinaryIndexedTree(int[] nums) {            int n = nums.length;            A = new int[n];            C = new int[n + 1];            for (int i = 0; i &lt; n; i++) {                update(i, nums[i]);            }        }        public void update(int index, int val) {            int delta = val - A[index]; //得到新val与原val的差值            A[index] = val;            /**             * 从index+1开始，因为C数组我们定义从1开始的。             * 每次更新完C[index+1]，还要再继续更新它的父亲。距离就是宽度lowbit(i)             */            for (int i = index + 1; i &lt;= A.length; i += lowbit(i)) {                C[i] += delta;            }        }        public int querySum(int start, int end) {            return getPrefixSum(end) - getPrefixSum(start - 1);        }        //获取前缀和        public int getPrefixSum(int index) {            int sum = 0;            /**             * 从正下方开始，先找到它前面2^k个的和,比如6，就是找到它前两个（包括它自身）             * i = i - lowbit(i)意思是，找完那2^k个，下一个应该从C[4]开始找了             */            for (int i = index + 1; i &gt; 0; i -= lowbit(i)) {                sum += C[i];            }            return sum;        }        private int lowbit(int index) {            return index &amp; (-index);        }    }\n\n","categories":["Algorithm"],"tags":["Dynamic programming"]},{"title":"初识JVM","url":"/2020/02/19/JVM1/","content":"认识 JVM一、初识JVM&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们写好一份Java代码，要将其部署到线上的机器去运行，就要将其打包成.jar或.war后缀的包，再进行部署。其中关键的一步是编译，也就是要把.java文件编译成.class字节码文件，有了字节码文件可以通过java命令来启动一个JVM进程，由JVM来负责运行这些字节码文件。所以说，在某个机器上部署某个系统后，一旦启动这个系统，实际上就是启动了JVM。\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们写好了一个个类是通过类加载器把字节码文件加载到JVM中的，JVM会首先从main()方法开始执行里面的代码，它需要哪个类就会使用类加载器来加载对应的类，反正对应的类就在.class文件中。\n注意：如果一个项目中有多个main()方法，在启动一个jar包的时候，就制定了是走哪个main()方法，所以入口是唯一的。\n\n程序运行机制\n二、初识JVM类加载器机制2.1引入&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;问题：JVM什么时候会加载一个类？\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;最简单的例子是直接从main()进入开始执行，比如\npublic class Kafka &#123;    public static void main(String[] args) &#123;    &#125;&#125;\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果碰到了实例化对象的操作，才把实例化的这个类的.class文件加载到内存（之前是没有加载进来的）\npublic class Kafka &#123;    public static void main(String[] args) &#123;        ReplicaManager replicaManager = new ReplicaManager();    &#125;&#125;\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先是包含main()方法的主类会在JVM启动之后首先被加载到内存中，然后开始执行main()中的代码，碰到需要使用的类，才去加载这个类对应的字节码文件，也就是说是按需加载。\n2.2类加载过程&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;类加载的过程为：加载、验证、准备、解析、初始化、使用、卸载\n\n验证：就是看字节码文件是否符合规范。\n\n准备：给类分配内存空间，其次为类变量分配内存空间，并设定一个默认值。不执行赋值！\n\n解析：符号引用替换为直接引用的过程\n\n初始化：正式执行类初始化的代码，在这里才是执行赋值代码等操作，准备阶段仅仅为类和变量开辟空间。在这个阶段执行初始化操作有很多，比如对于静态代码块的初始化就是在这个阶段执行的（JVM设计者设计先执行静态代码块的机制是希望开发者把类使用之前的准备工作在这准备好类级别的数据）。要记住，类的初始化就是初始化这个类，和里头的对象无关，只有new关键字才会构造出一个对象。\n\n什么时候会初始化一个类呢？\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一般来说包含main()方法的类是必须立马初始化的，或者说执行到new对象了，就会把这个对象的类初始化，如果这个类初始化过了，就不用进行第二次初始化。初始化重要的一个规则是：初始化一个类的时候，如果该类的父类没有初始化，（如果父类也没有加载的话）必须先加载并初始化它的父类！\npublic class ReplicaManager extends AbstractDataManager &#123;    //ReplicaManager继承AbstractDataManager，在初始化ReplicaManager时必须先初始化它的父类&#125;\n\n2.3类加载器和双亲委派机制1、Java中的类加载器\n\n启动类加载器：负责加载机器上安装的Java目录下的核心类，Java安装目录下有个lib文件存放了Java的核心库，JVM启动后，首先会依托启动类加载器去加载lib。\n扩展类加载器：就是加载lib/ext目录，和启动类加载器差不多，但它是启动类加载器的儿子。\n应用程序类加载器：负责加载ClassPath环境变量指定路径中的类，就是把你写好的代码加载进内存。\n自定义类加载器：自己写的类加载器，继承ClassLoader类，重写类加载方法\n\n2、双亲委派机制\nJVM的加载器是有亲子结构的，如图所示，提出了双亲委派机制。\n双亲委派机制：如果应用程序要加载一个类，首先会委派自己的父类加载器去加载，直至传到最顶层的加载器去加载，如果父类加载器在自己的职责范围内没有找到这个类，就会把加载权利下放给子类加载器。总的来说，就说先找父类去加载，不行再由儿子来加载。先从顶层加载器开始，发现自己加载不到，往下推给子类，这样能保证绝不会重复加载某个类。\n双亲委派的好处：避免了类的重复加载，如果两个不同层级的类加载器可以加载同一个类，就重复了。\n\n\n三、初识JVM内存区域&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们写好的代码中有很多的类，类中有许多的方法，同时方法中也有许多变量，它们都需要放到合适的区域，这就是JVM为什么要划分出不同内存区域的原因，下面介绍下JVM中的内存区域分类。\n3.1存放类的区域——方法区&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;方法区主要存放从class文件中加载进来的类，JDK 1.8后这块区域改名为Metaspace，即元数据空间，放的还是我们自己写的各种类相关的信息。\npublic class Kafka &#123;    public static void main(String[] args) &#123;        ReplicaManager replicaManager = new ReplicaManager();    &#125;&#125;\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;假设我们有上面这个例子，JVM首先类加载Kafka.class到方法区，当程序运行到实例化对象那句，就把ReplicaManager.class加载到方法区。如果Kafka类中有静态变量，也一样会进入方法区。\n\n3.2程序计数器——执行代码指令用的&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们写好的Java文件被编译成.class文件后就应对成了一行行的字节码指令，JVM加载类信息到方法区后，会去执行编译出来的字节码指令，执行的时候用到了程序计数器，它用来记录我们的程序执行到了哪一行字节码指令。由于JVM是支持多线程的，如果写好的代码开启了多个线程，那么每个线程都会有对应的程序计数器，来表示当前线程执行到了哪一条指令。\n\n3.3存放方法的区域——Java虚拟机栈&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在main()方法中有程序计数器来记录指令执行到哪了，但在方法中我们也会定义一些局部变量，JVM有一块区域是专门用来放局部变量的，即Java虚拟机栈，同样的，对于每个线程，它们有自己的Java虚拟机栈，如果一个线程执行了一个方法，会为这个方法调用创建一个对应的栈帧，栈帧中包含着局部变量表、操作数栈、动态链接、方法出口等。比如main线程执行了main()方法，那就为main()方法创建了一个栈帧，并将其压入了Java虚拟机栈，同时在main()方法的栈帧中也存放着它的局部变量。\n\n//含有main方法的Kafka类public class Kafka &#123;    public static void main(String[] args) &#123;        ReplicaManager replicaManager = new ReplicaManager();        replicaManager.loadReplicasFromDisk();    &#125;&#125;public class ReplicaManager &#123;    public void loadReplicasFromDisk() &#123;        Boolean hasFinishedLoad = false;        if (isLocalDataCorrupt()) &#123;                    &#125;    &#125;    public Boolean isLocalDataCorrupt() &#123;        Boolean isCorrect = false;        return isCorrect;    &#125;&#125;\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;比如上面这段代码，对应的Java虚拟机栈如下。在栈帧里存放了这个方法对应的局部变量之类的数据，包括这个方法执行的其他相关的信息，方法执行完毕之后就出栈。如果isLocalDataCorrupt方法执行完毕了，就会把isLocalDataCorrupt方法对应的栈帧从Java虚拟机栈里给出栈，然后如果loadReplicasFromDisk方法也执行完毕了，就会把loadReplicasFromDisk方法也从Java虚拟机栈里出栈。\n\n3.4存放对象的区域——Java内存堆&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在main方法里创建了ReplicaManager对象的时候，就会在main方法对应的栈帧的局部变量表里，让一个引用类型的“replicaManager”局部变量来存放ReplicaManager对象的地址。\n注意：\n\n新建的实例在堆内存，实例变量（对象变量）也是在堆内存的\n\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;总结一下这个过程：JVM进程启动后，首先会加载含有main方法的Kafka类到内存里（方法区），生成一个main线程，然后为这个线程分配一个程序计数器，开始执行程序。先生成main方法的栈帧，压入Java虚拟机栈，然后执行到new ReplicaManager()时，就会把ReplicaManager类加载进内存（方法区），接着发现要实例化一个对象，把这个对象的内存分配在Java内存堆中，并在main方法的栈帧里的局部变量表引入一个replicaManager局部变量，把它指向堆内存中的地址，然后main线程开始执行ReplicaManager对象中的方法依次把方法压栈，执行完出栈。\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;总结：类都是加载到方法区里的，而且是按需加载，只加载一次，要new对象时候，对象被分配在堆汇总，执行方法时为这个方法生成栈栈压入虚拟机栈，然后对应变量指向堆内存中的地址，完成方法则出栈。\n四、初识垃圾回收机制&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;一个方法执行完后的结果是怎样的？如图，也就是没有变量指向这个变量了，由于我们在内存堆里创建的对象都是占用内存资源的，所以需要回收它。JVM本身带有垃圾回收机制，它是后台自动运行的线程。它检索这个对象是否有人引用，如果没有任何人指向他，就会把这个对象给回收掉，从内存中清除。\n\n","categories":["JAVA"],"tags":["JVM"]},{"title":"CMS再优化与频繁FullGC问题分析","url":"/2020/03/01/JVM10/","content":"CMS再优化与频繁Full GC问题分析一、CMS深度优化技巧1、CMS内存碎片问题最常见的优化是用工具判断出来每次Young GC后存活对象有多少，Eden区域过小，自然会导致频繁的触发Young GC，Survivor区域过小，自然会导致经常在Young GC之后存活对象其实也没多少，但就是Survivor区域放不下，通过调整区域比例，避免对象快速进入老年代。这是优化的第一步，也是最容易想到的。\n此外，比如老年代有2G的内存，其中1.5G是连续可用内存，0.5G是很多内存碎片。本来老年代如果都是连续空内存的话，那么可能可以对象占用到将近2G才会触发Full GC。结果现在就是对象占用到了1.5G就需要触发Full GC了，剩下0.5G是没法放任何对象的。所以，在第一步降低了Full GC频率之后，由于老年代使用CMS，它的默认碎片整理次数是每5次Full GC后整理一下内存碎片，务必设置如下参数-XX:+UseCMSCompactAtFullCollection -XX:CMSFullGCsBeforeCompaction=0”，每次Full GC后都整理一下内存碎片，否则如果每次Full GC过后，都造成老年代里很多内存碎片，那么必然导致下一次Full GC更快到来。\n2、CMS深度优化引入两外两个参数。\n第一个参数是-XX:+CMSParallelInitialMarkEnabled。在使用CMS时的初始标记阶段，是会进行Stop the World的，会导致系统停顿，可以打开参数，这个参数会在CMS垃圾回收器的“初始标记”阶段开启多线程并发执行，可以尽可能优化这个阶段的性能，减少Stop the World的时间，\n另外一个参数是-XX:+CMSScavengeBeforeRemark，这个参数会在CMS的重新标记阶段之前，先尽量执行一次Young GC。CMS的重新标记也是会Stop the World的，所以所以如果在重新标记之前，先执行一次Young GC，就会回收掉一些年轻代里没有人引用的对象。所以如果先提前回收掉一些对象，那么在CMS的重新标记阶段就可以少扫描一些对象，此时就可以提升CMS的重新标记阶段的性能，减少他的耗时。\n小型业务JVM模版\n-Xms4096M -Xmx4096M -Xmn3072M -Xss1M  -XX:PermSize=256M -XX:MaxPermSize=256M -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFaction=92 -XX:+UseCMSCompactAtFullCollection -XX:CMSFullGCsBeforeCompaction=0 -XX:+CMSParallelInitialMarkEnabled -XX:+CMSScavengeBeforeRemark\n\n二、四大频繁Full GC原因分析1、大量反射代码使永久代类太多导致频繁Full GC频繁Full GC不光是老年代触发的，有时候也会因为Metaspace区域的类太多而触发，也是就是Metaspace区域被占满，Full GC 的时候回收其中部分类，我们想了解Metaspace为什么被频繁占满，是哪个类不停的被加载进入，就可以使用下面的两个参数，很有用！\n第一个参数是-XX:TraceClassLoading,第二个参数是-XX:TraceClassUnloading，分别追踪类加载和类卸载的情况，他会通过日志打印出来JVM中加载了哪些类，卸载了哪些类。对于这些类，通过查资料就会明白了，有一个案例说是java中反射时加载的类，执行反射代码时，JVM会在你反射调用一定次数之后就动态生成一些类。只要记住一个结论：如果你在代码里大量用了类似上面的反射的东西，那么JVM就是会动态的去生成一些类放入Metaspace区域里的。\n（1）为什么会这些类会被放进Metaspace呢？反射过程中生成的类的Class对象，都是软引用的，正常情况下不会被回收！（什么是Class对象？类自己本身就是一个对象，就是一个Class的对象，一个Class对象代表了一个类，这个Class对象能够派生出很多的实例）\n（2）什么时候软引用会被回收呢？通过这个公式来判断clock - timestamp &lt;= freespace * SoftRefLRUPolicyMSPerMB,“clock - timestamp”代表了一个软引用对象他有多久没被访问过了，freespace代表JVM中的空闲内存空间，SoftRefLRUPolicyMSPerMB代表每一MB空闲内存空间可以允许SoftReference对象存活多久,默认是1000毫秒。假如JVM空闲空间为3000MB，那么一个软引用的对象最多可以活50分钟（3000*1000ms）。\n（3）解决方案按理说JVM应该会随着反射代码的执行，动态的创建一些奇怪的类，他们的Class对象都是软引用的，正常情况下不会被回收，但是也不应该快速增长才对，问题出在SoftRefLRUPolicyMSPerMB这个参数，别误把它设置为0，一旦这个参数设置为0，任何软引用对象就可以尽快释放掉，但这样并不会提高内存利用率，JVM好不容易给你弄出来100个奇怪的类，结果因为瞎设置软引用的参数，导致突然一次GC就给你回收掉几十个类，接着JVM在反射代码执行的过程中，就会继续创建这种奇怪的类，在JVM的机制之下，会导致这种奇怪类越来越多。\n解决方案：在有大量反射代码的场景下，只要把-XX:SoftRefLRUPolicyMSPerMB=0，这个参数设置大一些即可，千万别让一些新手同学设置为0，可以设置个1000，2000，3000，或者5000毫秒，都可以。提高这个数值，就是让反射过程中JVM自动创建的软引用的一些类的Class对象不要被随便回收，优化这个参数之后，就可以看到系统稳定运行了。\n2、大对象导致频繁Full GC场景是这样的，有一个线上系统一天频繁Full GC数十次，开始以为是每次Young GC后的存活对象较多，Survivor区域太小，放不下了，但通过jstat工具观察，发现每次Young GC后的对象很少，每次存活也就几十MB，且通过jstat追踪观察，并不是每次Young GC后都有几十MB对象进入老年代的，而是偶尔一次Young GC才会有几十MB对象进入老年代，记住，是偶尔一次！但是不知道为什么突然有几百MB对象进入老年代中，所以才导致Young GC偶尔一次让几十MB对象升入老年代，平均30分钟左右就会触发一次Full GC！这个几百MB的对象就是大对象，我们想要知道大对象是谁，可以利用堆内存快照工具jmap，通过使用这个工具我们发现是几个Map之类的数据结构，是从数据库中出来的，通过排查SQL语句，发现有一句select * from tbl，根本没使用where语句，导致它把表中几十万条数据查出来，搞出来一个大对象。\n解决方案，一是对SQL语句的处理，不要一次性查表里全部数据，二是给新生代分配更多的空间，毕竟每次到老年代的对象较少而且频率很低，同时给老年代调整了参数“-XX:CMSInitiatingOccupancyFraction=92”，避免老年代仅仅占用68%就触发GC。\n3、致命代码：**System.gc()**导致频繁Full GC**System.gc()**不能随便瞎写，它每次执行都会指挥JVM去尝试执行一次Full GC，连带年轻代、老年代、永久代都会去回收，一秒一次Full GC太可怕了！如果写了这个代码，平时系统运行时，访问量很低，基本还不会出大乱子！但是在大促活动的时候，访问量一高，立马由System.gc()代码频繁触发了Full GC，导致了这个系统直接被卡死了！\n解决方案：一是平时写代码不要用System.gc()去随便触发GC，二是在JVM参数中加入-XX:+DisableExplicitGC,这个参数的意思就是禁止显式执行GC，不允许你来通过代码触发GC。\n4、内存泄漏引起CPU高负载导致频繁Full GC线上系统的机器CPU负载过高的两个常见的场景。\n第一个场景，是你自己在系统里创建了大量的线程，这些线程同时并发运行，而且工作负载都很重，过多的线程同时并发运行就会导致你的机器CPU负载过高。\n第二个场景，就是你的机器上运行的JVM在执行频繁的Full GC，Full GC是非常耗费CPU资源的，他是一个非常重负载的过程。所以一旦你的JVM有频繁的Full GC，带来的一个明显的感觉，一个是系统可能时不时会卡死。这可能与内存泄漏有关。\n内存泄漏问题，就是内存里驻留了大量的对象塞满了老年代，导致稍微有一些对象进入老年代就会引发Full GC，而且Full GC之后还不会回收掉老年代里大量的对象，只是回收一小部分而已！（可以使用mat分析内存泄漏）\n这个内存泄漏问题可能是没有限制JVM本次缓存大小，没有使用LRU之类的算法定期淘汰一些缓存里的数据，导致缓存在内存里的对象越来越多，进而造成了内存泄漏。\n解决问题很简单，只要使用类似EHCache之类的缓存框架就可以了，他会固定最多缓存多少个对象，定期淘汰删除掉一些不怎么访问的缓存，以便于新的数据可以进入缓存中。\n三、JVM优化阶段性总结问：如何设置JVM参数？1、初步估计首先根据拥有的设备、每秒请求量、每秒创建多少个对象以及对象的大小等来估算1秒钟会占用多少内存空间，估算多久发生一次Young GC、每次存活下来多少对象，需要多少Survivor区，接着要去看老年代中对象的增长速度，多久发生一次Full GC，这样初步估算后去分配堆内存中新生代和老年代的空间，以及新生代中区域的比例。进入压测阶段。\n2、压测后调整在这里要分析Eden区对象的增长速度有多快，Young GC后有多少对象存活，Young GC频率和耗时，老年代对象增长速率，Full GC后有多少对象存活，Full GC的频率和耗时。压测完全可以通过jstat来看，然后我们调整参数，找到一些问题，主要还是避免对象频繁进入老年代引起频繁的Full GC。\n3、系统上线后监控系统上线后要使用监控工具如Zabbix、Open-Falcon等工具来监控运行情况。如果出现了CPU负载过高、频繁Full GC或者系统无法处理请求这种现象，都要去考虑是不是Full GC太频繁了。\n频繁Full GC 的原因就是上面四个大标题\n\n大量使用反射导致Metaspace拥挤发生频繁的Full GC。\n大对象可能引起频繁Full GC，需要去修改代码和JVM参数。\n可能是内存泄漏引起的，使用MAT工具分析堆内存快照。\n最后一种是使用了System.gc()方法，并且在JVM参数中也没有添加禁止显式执行gc的参数。\n\n","categories":["JAVA"],"tags":["JVM"]},{"title":"JVM工具使用","url":"/2020/03/02/JVM11/","content":"JVM工具的使用一、jstat1、简介jstat可以让你看到当前运行中的系统，他的JVM内的Eden、Survivor、老年代的内存使用情况，还有Young GC和Full gC的执行次数以及耗时。通过这些指标，我们可以轻松的分析出当前系统的运行情况，判断当前系统的内存使用压力以及GC压力，还有就是内存分配是否合理。\n2、命令（1）jps命令jps(Java Virtual Machine Process Status Tool)是JDK 1.5提供的一个显示当前所有java进程pid的命令。\n\njps -q：只显示pid\njps -m：输出传递给main 方法的参数\njps -l：输出应用程序main class的完整package名 或者 应用程序的jar文件完整路径名\njps -v：输出传递给JVM的参数\n\n（2）jstat命令命令格式：jstat [option] LVMID [interval] [count]\n\noption : 操作参数、LVMID : 本地虚拟机进程ID、interval]: 连续输出的时间间隔、count : 连续输出的次数\njstat -gc PID：查看Java进程（JVM）的内存和GC情况，最常用的命令\njstat -gccapacity PID：堆内存分析\njstat -gcnew PID：年轻代GC分析，这里的TT和MTT可以看到对象在年轻代存活的年龄和存活的最大年龄\njstat -gcnewcapacity PID：年轻代内存分析\njstat -gcold PID：老年代GC分析\njstat -gcoldcapacity PID：老年代内存分析\njstat -gcmetacapacity PID：元数据区内存分析\n\n（3）命令结果解释\nS0C：这是From Survivor区的大小\nS1C：这是To Survivor区的大小\nS0U：这是From Survivor区当前使用的内存大小\nS1U：这是To Survivor区当前使用的内存大小\nEC：这是Eden区的大小\nEU：这是Eden区当前使用的内存大小\nOC：这是老年代的大小\nOU：这是老年代当前使用的内存大小\nMC：这是方法区（永久代、元数据区）的大小\nMU：这是方法区（永久代、元数据区）的当前使用的内存大小\nYGC：这是系统运行迄今为止的Young GC次数\nYGCT：这是Young GC的耗时\nFGC：这是系统运行迄今为止的Full GC次数\nFGCT：这是Full GC的耗时\nGCT：这是所有GC的总耗时\n\n3、工具使用姿势使用jstat来分析线上的JVM进程，要知道的信息有如下几个：新生代对象增长的速率、Young GC的触发频率、Young GC的耗时、每次Young GC后有多少对象是存活下来的、每次Young GC过后有多少对象进入了老年代、老年代对象增长的速率、Full GC的触发频率、Full GC的耗时等。知道了这些就能进行优化了。\n（1）新生代对象增长速率使用jstat -gc PID 1000 10，每隔1秒钟更新出来最新的一行jstat统计信息，通过这个命令，你可以非常灵活的对线上机器通过固定频率输出统计信息，观察每隔一段时间的jvm中的Eden区对象占用变化。时间段可以根据对象增长速度来设定。还有就是一般系统都有高峰和日常两种状态，比如系统高峰期用的人很多，此时你就应该在系统高峰期去用上述命令看看高峰期的对象增长速率。然后你再得在非高峰的日常时间段内看看对象的增长速率。\n（2）Young GC触发一频率和耗时知道了新生代对象增长速度，就可以估计Young GC的时间了，同时jstat会告诉你迄今为止系统已经发生了多少次Young GC以及这些Young GC的总耗时。比如系统运行24小时后共发生了100次Young GC，总耗时为20s。那么平均下来每次Young GC大概就耗时二十毫秒的时间。\n（3）每次Young GC后有多少对象进入老年代这个对象量只能估算出来，我们知道了多久发生一次Young GC，假设为t，可以利用jstat -gc PID t 10看看，每隔t分钟后Eden、Survivor、老年代的对象变化。老年代中内存占用会慢慢增加，这里的关键，就是观察老年代的对象增长速率。正常的角度来看，老年代的对象是不太可能不停的快速增长的，普通的系统其实没那么多长期存活的对象。如果你发现比如每次Young GC过后，老年代对象都要增长几十MB，那很有可能就是你一次Young GC过后存活对象太多了。如果老年代对象快速增长，那一定是不正常的。\n（4）Full GC出发时机和耗时知道了老年代对象的增长速率，那么Full GC的触发时机就很清晰了，jstat可以打印Full GC次数以及总耗时。\n二、jmap和jhat这两个工具可以帮助我们观察线上JVM中的对象分布，了解到系统运行过程中，到底哪些对象占据了主角位置，他们占据了多少内存空间。这篇博客写的非常详细！\n1、jmap单单看JVM运行状况，jstat足够用了，如果发现JVM新对象增加速度很快，想看这个对象是谁，可以用jmap。\n\njmap -heap PID：系统运行时内存区域信息。这个会打印出来堆内存相关的一些参数设置，以及当前堆内存里的一些基本各个区域的情况。\njmap -histo PID：系统运行时的对象分布，他会按照各种对象占用内存空间的大小降序排列，把占用内存最多的对象放在最上面。\n\n\n\njmap -dump:live,format=b,file=dump.hprof PID:把这一时刻JVM堆内存里所有对象的快照放到文件里去了，供你后续去分析。\n\n2、jhat通过jmap得到了堆内存快照，可以利用jhat去分析堆内存快照，jhat内置了web服务器，他会支持你通过浏览器来以图形化的方式分析堆转储快照。使用jhat dump.hprof -port 7000命令即可启动jhat服务器，还可以指定自己想要的http端口号，默认是7000端口号,接着你就在浏览器上访问当前这台机器的7000端口号，就可以通过图形化的方式去分析堆内存里的对象分布情况了。\n三、JVM监控工具很多中大型公司都会部署专门的监控系统，比较常见的有Zabbix、OpenFalcon、Ganglia，此时你就可以在这些监控系统可视化的界面里，看到你需要的所有指标，包括你的各个内存区域的对象占用变化曲线，直接可以看到Eden区的对象增速，还会告诉你Young GC发生的频率以及耗时，包括老年代的对象增速以及Full GC的频率和耗时。对线上运行的系统，要不然用命令行工具手动监控，发现问题就优化，要不然就是依托公司的监控系统进行自动监控，可视化查看日常系统的运行状态。\n四、Young GC实战模拟电商订单系统，机器4核8G，堆内存中的新生代分配的内存都在1.5G左右，Eden区大概也就1G左右的空间，假设每台机器500个请求，每个请求需要加载100KB的数据，1秒就是50MB，大概20s左右就会填满Eden区然后触发Young GC进行回收。\n-XX:NewSize=104857600 \t\t//新生代100MB-XX:MaxNewSize=104857600 -XX:InitialHeapSize=209715200\t\t//堆内存200MB-XX:MaxHeapSize=209715200 -XX:SurvivorRatio=8\t\t//Eden80MB，S区各占10MB  \t-XX:MaxTenuringThreshold=15 -XX:PretenureSizeThreshold=3145728 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:gc.log\n\npublic class Demo1 &#123;\t\t//模拟系统按照每秒钟50个请求，每个请求加载100KB数据的方式不停的运行，每秒5MB    public static void main(String[] args) throws InterruptedException &#123;        Thread.sleep(30000);        while (true) &#123;            loadData();        &#125;    &#125;    private static void loadData() throws InterruptedException &#123;        byte[] data = null;        for (int i = 0; i &lt; 50; i++) &#123;            data = new byte[100 * 1024];        &#125;        data = null;        Thread.sleep(1000);    &#125;&#125;\n\n启动！首先找到进程号\n\n接着输入jstat命令\n\n观察EU可以发现Eden刚开始被用了8MB左右，然后以5MB/s速度增长，Eden一共80MB，当使用量达到70多MB的时候，再要分配5MB的对象就失败了，此时就会触发一次Young GC，Eden区的使用量从70多MB降低为了1MB多，大致在十几秒左右会触发一次Young GC，同时我们也看到回收对象也只用了0.002s，速度非常快。，S1U就是Survivor中被使用的内存，之前一直是0，在一次Young GC过后变成了875.3KB，所以一次Young GC后也就存活875.3KB的对象而已，轻松放入10MB的Survivor中。同时OU一直都是0 ，说明这个系统运行良好，Young GC都不会导致对象进入老年代，这就几乎不需要什么优化了。因为几乎可以默认老年代对象增速为0，Full  GC发生频率趋向于0，对系统无影响。\n五、Full GC实战1、背景百亿数据量计算系统，从数据库中提取数据到内存中来计算。这是一套分布式运行系统，平均每台机器每分钟执行100次数据提取和计算，每次会提取大概1万条左右的数据到内存里来计算，平均每次计算大概需要耗费10秒左右的时间。机器4核8G，JVM内存给4G，新生代老年代分别1.5G。这里每条数据都是比较大的，大概每条数据包含了平均20个字段，可以认为平均每条数据在1KB左右的大小，1万条数据就对应了10MB的大小。新生代按8:1:1，则Eden占1.2GB，每个S区占100MB，这样一分钟大概对应100次计算任务，Eden区大概满了，执行Young GC前会检查老年代可用空间，那么此时Eden区里有多少对象还是存活的，无法被垃圾回收呢？每个计算任务1万条数据需要计算10秒钟，所以假设此时80个计算任务都执行结束了，但是还有20个计算任务共计200MB的数据，还在计算中，那么此时就是200MB的对象是存活的，不能被垃圾回收掉，然后有1GB的对象是可以垃圾回收的，由于Survivor区实际上就100MB的空间，此时就会通过空间担保机制，让这200MB对象直接进入老年代去。\n\n按照上述计算，每分钟都是一个轮回，大概算下来是每分钟都会把新生代的Eden区填满，然后触发一次Minor GC，然后大概都会有200MB左右的数据进入老年代，所以大概在8分钟左右，新生代慢了，要进入老年代，但是老年代放不下了，要进行GC。假设此时老年代被占据的1.4G空间里，全部都是可以回收的对象，那么此时一次性就会把这些对象都给回收了，然后这200MB对象再进入老年代，再回到上图的结果。\n2、优化因为这个系统是数据计算系统，每次Minor GC的时候，必然会有一批数据没计算完毕，但是按照现有的内存模型，最大的问题，其实就是 每次Survivor区域放不下存活对象。所以就增加了新生代的内存比例，3GB左右的堆内存，其中2GB分配给新生代，1GB留给老年代，这样Survivor区大概就是200MB，每次刚好能放得下Minor GC过后存活的对象了。\n3、场景模拟JVM参数唯一修改的就是“**-XX:PretenureSizeThreshold**”，把大对象阈值修改为了20MB，避免程序里分配的大对象直接进入老年代。\n-XX:NewSize=104857600 -XX:MaxNewSize=104857600 -XX:InitialHeapSize=209715200 -XX:MaxHeapSize=209715200 -XX:SurvivorRatio=8  -XX:MaxTenuringThreshold=15 -XX:PretenureSizeThreshold=20971520 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:gc.log\n\n代码\npublic class Demo1 &#123;    public static void main(String[] args) throws InterruptedException &#123;        Thread.sleep(30000);        while (true) &#123;            loadData();        &#125;    &#125;    private static void loadData() throws InterruptedException &#123;        byte[] data = null;        for (int i = 0; i &lt; 4; i++) &#123;            data = new byte[10 * 1024 * 1024];        &#125;        data = null;        byte[] data1 = new byte[10 * 1024 * 1024];        byte[] data2 = new byte[10 * 1024 * 1024];        byte[] data3 = new byte[10 * 1024 * 1024];        data3 = new byte[10 * 1024 * 1024];                Thread.sleep(1000);    &#125;&#125;\n\n每秒钟都会执行一次loadData()方法，他会分配4个10MB的数组，但是都立马成为垃圾，但是会有data1和data2两个10MB的数组是被变量引用必须存活的，此时Eden区已经占用了六七十MB空间了，接着是data3变量依次指向了两个10MB的数组，这是为了在1s内触发Young GC的。采用jstat监控其运行状态可以看到如下的信息：\n\n按照我们上述的代码，他一定会在一秒内触发一次Young GC，Young GC过后，我们发现S1U中有798.8KB的存活对象，就是未知存活对象，同时每秒会发生一次Young GC，都会导致20MB~30MB左右的对象进入老年代（因为Survivor区域是放不下只能进老年代），然后老年代的对象占用从30KB一路到60MB左右，此时突然在60MB之后下一秒，明显发生了一次Full GC。\n从YGC可以看到，23次Young GC，结果耗费了105毫秒，平均下来一次Young GC要5毫秒左右。但是11次Full GC才耗费22毫秒，平均下来一次Full GC才耗费2毫秒，这是因为这个Full GC是由Young GC触发的，必须得等Full GC执行完毕了，Young GC才能把存活对象放入老年代才算结束，导致Young GC速度非常慢。\n4、场景优化JVM参数\n-XX:NewSize=209715200 -XX:MaxNewSize=209715200 -XX:InitialHeapSize=314572800 \t//调整到300MB-XX:MaxHeapSize=314572800 -XX:SurvivorRatio=2\t\t\t//调整为2:1:1-XX:MaxTenuringThreshold=15 -XX:PretenureSizeThreshold=20971520 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:gc.log\n\n把堆大小从200MB调整到300MB，新生代给了200MB，同时-XX:SurvivorRatio=2表明，Eden:Survivor:Survivor的比例为2:1:1，所以Eden区是100MB，每个Survivor区是50MB，老年代也是100MB。运行程序，结果如下：\n\n可以看到，只有Young GC，没有Full GC，没有Full GC的干扰后，Young GC速度是很快的\n","categories":["JAVA"],"tags":["JVM"]},{"title":"JVM分代模型与内存参数设置","url":"/2020/02/20/JVM2/","content":"JVM分代模型与内存参数设置一、JVM分代模型1、背景public class Kafka &#123;    // 年轻代    public static void main(String[] args) throws InterruptedException &#123;        while (true) &#123;            loadReplicasFromDisk();            Thread.sleep(1000);        &#125;    &#125;    private static void loadReplicasFromDisk() &#123;        ReplicaManager replicaManager = new ReplicaManager();        replicaManager.load();    &#125;&#125;\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们可以看到在main()方法的while循环中，不断调用loadReplicasFromDisk()方法生成新对象，这个新生成对象的存活时间是极其短的，大致过程是loadReplicasFromDisk()入栈，在堆内存中生成对象，栈帧里的局部变量指向这个对象，然后方法结束，出栈，这个对象就没人指向了，结果如下图\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但有些对象是长期存活的，比如下面这段代码。\npublic class Kafka &#123;    // 老年代    private static ReplicaManager replicaManager = new ReplicaManager();    public static void main(String[] args) &#123;        while (true) &#123;            loadReplicasFromDisk();            Thread.sleep(1000);        &#125;    &#125;    private static void loadReplicasFromDisk() &#123;        replicaManager.load();    &#125;&#125;\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在Kafka类中定一个一个静态变量，这个静态变量指向堆内存中的对象，while循环中不停得调用这个对象的方法，使得这个对象一直被引用，这样就长期存活下来了。\n2、年轻代、老年代、永久代\nJVM将Java堆内存分成两个区域，即年轻代和老年代，年轻代就是生命周期极短、用完就要被回收的对象所在的区域，老年代就是生命周期较长对象存在的区域，需要一直存在堆中，让程序后续不断的去使用。\n\n为什么要设计两个区域呢？因为针对每个对象的生命周期特点来设计不同的GC算法，保证GC的稳定性。\n\n永久代：之前讲过的方法区就是永久代，它存放了类相关的信息\n\n永久代会产生回收嘛？肯定是会的，有这样几种情况会导致回收\n\n该类在堆中的所有实例对象都被回收了\n加载这个类的ClassLoader也被回收了（比如自己定义的类加载器也是个对象，没人用就会被回收）\n最后对该类的Class对象也没有引用（如果有变量引用类的Class对象，就是有引用）\n比如利用反射，来获取一个对象的类的Class对象实例，如Class c = replicaManager.getClass()，可以通过replicaManager引用的对象来获取ReplicaManager类的Class对象，这个变量c就能引用这个Class对象\n\n\n\n\n\npublic class Kafka &#123;    private static ReplicaFetcher fetcher = new ReplicaFetcher();    public static void main(String[] args) &#123;        //年轻代        loadReplicasFromDisk();        //老年代        while (true) &#123;            loadReplicasFromRemote();            Thread.sleep(1000);        &#125;    &#125;    private static void loadReplicasFromDisk() &#123;        ReplicaManager replicaManager = new ReplicaManager();        replicaManager.load();    &#125;    private static void loadReplicasFromRemote() &#123;        fetcher.fetch();    &#125;&#125;\n\n对应下面这张图\n\n二、JVM内存如何分配？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;虽然有了年轻代和老年代，但是对于大部分正常对象，都是先升在新生代中分配内存的，新生代就是年轻代和老年代的总和，一开始并没有区分。我们的对象有两种类型，一种是像ReplicaManager这样的，用完一次就没人指向他了，这样的对象在新生代内存中不断囤积，最后导致空间几乎都被它占满了，那就会触发Minor GC，又称之为Young GC，它就把新生代中的没用的这些垃圾回收掉；另一种对象是像ReplicaFetcher这样的，始终有人指向它，JVM中有规定，垃圾每回收一次，如果一个对象没被回收掉，它的年龄就增加1，如果一个对象年龄超过15，就会把它放置到老年代区域（这个阈值我们可以修改，默认值是15），也就是说老年代存放了年龄很大的对象，下面两张图就很形象。同样的，如果老年代也满了也会被回收。\n小结：\n\n一般对象先分在新生代，新生代满了就GC，有些对象满足条件进入老年代，老年代满了也会GC，清除没用的\n\n对象分配的机制有很多，如\n\nMinor GC后存活对象太多，大量对象直接进入老年代\n超大对象不经新生代直接进入老年代\n动态对象年龄判断机制\n空间担保机制\n\n\nReplicaManager的对象太多导致内存不够\n\nReplicaManager的对象被回收掉，且ReplicaFetcher对象符合要求进入老年代\n三、JVM内存分配参数-Xms：Java堆内存大小-Xmx：Java堆内存最大大小-Xmn：Java堆内存中新生代大小，扣除新生代就是老年代的大小了-XX:PermSize：永久代大小-XX:MaxPermSize：永久代最大大小-Xss：每个线程栈内大小，一般0.5～1M\n\n\n四、JVM堆内存、栈内存、永久代大小设置1、堆内存大小设置&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;背景是电商支付系统，首先看一下支付流程：\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个系统的支付压力就是每日百万订单的交易，从JVM角度来看，就是在堆内存中生存了百万个订单对象，而这些订单频繁的创建和销毁就是核心问题。\n\n我们怎么去设定堆内存的大小呢？按照下边的步骤估计：\n\n确定业务规模，分析系统压力点\n确定我们的系统部署了多少台机器，计算每秒请求数，考虑每个请求的耗时\n结合每个请求消耗的内存，确定机器的参数，分配多少内存空间合适\n确定每台机器JVM分配的内存空间（方法区、栈内存、堆内存，堆中新生代、老年代大小）\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;假设我们一天100万个订单，共三台机器，把这100w个订单分配到几个小时里（考虑高峰时间段），假设算下来一秒钟100个订单。把这100个订单的任务分配个3台机器，每台机器一秒30个订单，那这30个订单占多少内存？就要看我们订单对象是多大了，看订单对象里面的变量来计算（Integer变量4字节，Long类型8字节…），假设1kb，那么30个订单也就30kb，大概情况如下。系统运行起来后，一台机器每秒有30个对象不被使用了，然后直到新生代空间快满了，就发生一次Minor GC，这就是这个业务运行的模型。但是实际情况下，每秒钟创建出来的对象不单单就订单对象，还会创建许多其他对象，所以每秒创建出来的被栈内存中局部变量引用的对象所占用的空间大致在几百KB～1MB之间。\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;做完了前三步后，我们要估算JVM堆内存如何分配了，常见的机器配置也就2核4G或4核8G。以2核4G为例，一半内存要给机器本身运行，另一半分配给JVM，也就是说分配到了2G，这2G要分配给方法区、栈内存、堆内存，堆内存最多再分得一半，也就是1G，堆内存中要划分新生代和老年代，假设都给一半，实际业务情况下1秒占1M那么过不了多了就会GC，频繁的GC影响了系统的稳定性，所以不行，还是得换4核8G，这样堆内存还能分得多一点，比如分3G（-Xms和-Xmx设置为3G，整个堆内存，然后-Xmn给新生代2G），能够大大降低GC频率，当然部署机器越多，对JVM压力更小。\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果我们设置内存过小会出现什么情况？比如双十一，这会每秒支付不再是1秒100个了，而是秒1000个，这时候所有资源都会吃紧，当然有些支付请求并不是立即支付的，它可能卡好久，使得这些数据在Minor GC后都放到了老年代，与此同时新生代中又不断增加对象，最后新生代又爆满，然后再Minor GC放到老年代。。。最后老年代对象越来越多，可能频繁触发老年代的垃圾回收，老年代的垃圾回收速度是很慢的！，然后不断影响系统性能\n\n2、栈内存和永久代大小设置栈内存：不用特别的去估计和设置，默认的是512KB～1MB，差不多够了。\n永久代：存放类相关信息，一般设置几百MB是够的，当然有些系统会导致永久代内存溢出，后面分析。\n","categories":["JAVA"],"tags":["JVM"]},{"title":"JVM垃圾回收机制详解","url":"/2020/02/21/JVM3/","content":"JVM 垃圾回收机制详解一、GC Roots的类型JVM使用了可达性分析算法，该算法会分析每个对象，看有谁在引用他，一层层判断有没有一个GC Roots，在JVM规范中，局部变量是可以作为GC Roots的，只要一个类的对象被局部变量引用了，那就说明有一个GC Roots，就不能被回收了。当然，静态变量也可以看作是一种GC Roots。总结下来就是，只要你的对象被方法的局部变量或是类的静态变量引用了，就不能回收它。\n至此我们知道回收和引 用有关，Java中有四种引用类型，它们分别是：强引用、软引用、弱引用和虚引用，针对不同的引用类型又有不同的回收策略：\n\n强引用：一个变量引用一个对象。只要是强引用，垃圾回收时绝对不会去回收这个对象。\n\npublic class Kafka &#123;    private static ReplicaManager replicaManager = new ReplicaManager();&#125;\n\n\n软引用：通过SoftReference软引用类型把ReplicaManager类的对象直接包裹起来，这时候replicaManager对ReplicaManager类的对象就是软引用。正常垃圾回收不会回收软引用对象，只有当垃圾回收之后，发现内存还是不够存放新对象时，内存要溢出时，才会去回收软引用的对象。\n\npublic class Kafka &#123;    private static SoftReference&lt;ReplicaManager&gt; replicaManager =             new SoftReference&lt;&gt;(new ReplicaManager());&#125;\n\n\n弱引用：通过WeakReference软引用类型把ReplicaManager类的对象直接包裹起来，这样静态变量持有的ReplicaManager类对象就是弱引用的了。弱引用就跟没有一样，垃圾回收直接回收掉。\n\npublic class Kafka &#123;    private static WeakReference&lt;ReplicaManager&gt; replicaManager =            new WeakReference&lt;&gt;(new ReplicaManager());&#125;\n\n\n\n\n虚引用：很少使用\n\n总结：有GC Roots引用的对象不能回收，没有引用的可以回收，强引用不能回收，对于软引用，如果回收后内存依旧不够放入新的对象，就回收软引用的对象了。当然，如果我们不想没有GC Roots的对象立即被回收，我们可与使用重写Object的finalize()方法来拯救一下，这东西很少用，知道一下即可。\n有下面这么一段代码，ReplicaFetcher的对象会被回收掉嘛？\npublic class Kafka &#123;    private static ReplicaManager replicaManager = new ReplicaManager();&#125;public class ReplicaManager &#123;    private ReplicaFetcher replicaFetcher = new ReplicaFetcher();&#125;\n\n肯定是不会的，ReplicaFetcher类的对象被ReplicaManager类的replicaFetcher强引用着，而ReplicaManager类的对象被可作为GC Root的静态变量replicaManager强引用着，所以ReplicaFetcher对象可以向上找到GC Root，因此不会被回收。\n二、针对新生代的垃圾回收算法——复制算法背景：对于新生代，一种不太好的垃圾回收思路是直接对新生代里的垃圾对象进行标记，然后直接对垃圾进行回收，这样的缺陷是引入了许多内存碎片，内存碎片导致了内存的浪费，我们没有了完整的连续的内存空间是很难受的一件事。在这改进一下，我们可以将新生代内存空间划分为两部分，对不回收的对象进行标记，转移到另一块区域中顺便整理下，然后把另一块区域里的垃圾干掉，这就是所谓的复制算法。如下图\n\n为什么标记不回收的呢？因为新生代里存放的对象大都是存活时间很短的，所以不回收的只是很少一部分，标记速度更快，如果标记回收的，就不合适了。\n但是复制算法有缺点，因为我们永远只有一半内存可以使用，另一半放垃圾，这样转移，使得内存使用效率太低了。所以对复制算法进行了优化。因为新生代放的都是存活时期非常短的对象，极端情况比如99%的垃圾1%有用的。实际上新生代内存区被划分为三部分：1块Eden区，2块Survivor区。\n初始对象都是优先被分配在Eden区的，如果Eden区快满了就触发Minor GC，把Eden中存活的对象全部转移到空的Survivor区，接着清空Eden中的垃圾，再次配分对象到Eden。由于存活的对象较少，所以给Survivor区域分配的内存就较少，当然看实际场景来分配。\n\n如果Survivor一个区域中都放满了，并且Eden区域中也占满了，但是垃圾回收后可能就只有10M对象活着，只要把那10MB对象转移到另一块Survivor区域中即可，之后把第一块Survivor区域和Eden区域中垃圾全部回收，这样始终保证着有一块Survivor区域是空的。\n\n三、针对老年代的垃圾回收算法——标记整理算法1、进入老年代的几种情况（1）躲过15次GC（当然我们可以自己设置次数）（2）大对象直接进入老年代通过-XX:PretenureSizeThreshold把值设置成字节数，创建的对象大于这个值就直接进入老年代，之所以这么做是避免新生代里的大对象屡次躲过GC还要在三个区域来回复制，耗费时间。\n（3）动态对象年龄判断比如当前放对象的Survivor区域里，一批对象的总大小，大于这块Survivor区域的内存大小的50%，那么此时大于等于这批对象年龄的对象就直接进入老年代\n\n假设100MB的Survivor中有俩对象，年龄都是2岁，但是俩对象加起来超过了50MB，也就是超过了一半了，这个时候，Survivor中大于等于2岁的对象都要进入老年代里去。\n避免动态年龄判断的方式：如果新生代内存有限，可以调整-XX:SurvivorRatio=8这个参数，默认是说Eden区比例为80%，也可以降低Eden区的比例，给两块Survivor区更多的内存空间，然后让每次Minor GC后的对象进入Survivor区中，还可以避免动态年龄判定规则直接把他们升入老年代。\n\n（4）空间分配担保规则Minor GC后发现对象太多，放不进Survivor区，就必须直接转移到老年代区的情况。在执行任何一次Micro GC前，JVM都会检查老年代的可用空间是否大于新生代所有对象的总大小，记住，是新生代所有对象总大小，因为极端情况下新生代可能所有对象都活下来了。下面就有两种情况了。\n\n第一种情况：老年代剩余内存大小大于新生代所有对象总大小，放心Minor GC吧！即使你的Survivor区域放不下也可以放老年代去；\n第二种情况：老年代剩余内存大小小于新生代所有对象总大小，此时就会看-XX:HandlePromotionFailure参数是否设置了，若设置了，则会看老年代可用内存大小是否大于之前每一次Minor GC后进入老年代的对象的平均大小，如果不是，只能Full GC,即对老年代里的对象进行回收，才能让剩余存活对象进入老年代。如果是，则可以冒险尝试下Minor GC，但这个尝试也是有三种可能：&emsp;可能一：Minor GC后，剩余存活对象比Survivor区还小，就直接放进Survivor中&emsp;可能二：Minor GC后，剩余存活对象大于Survivor区，小于老年代可用区，即直接进入老年代&emsp;可能三：Minor GC后，剩余存活对象大于老年代可用区，放不下了，这时候就会触发Full GC，要是Full GC后还是放不下，直接导致OOM内存溢出。\n\n&emsp;&emsp;简介：空间担保机制是看老年代可用空间是否大于新生代所有对象总大小的，如果成立了，那么Minor GC就是安全的，如果不成立，则看HandlerPromotionFailure是否设置为true，true则允许担保失败，如果允许，则检查老年代可用连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，则尝试Minor GC，如果小于，则Full GC。&emsp;&emsp;实际上-XX:HandlePromotionFailure参数在JDK 1.6以后就被废弃了，所以现在一般都不会在生产环境里设置这个参数了。JDK 1.6之前是把空间担保机制和HandlerPromotionFailure参数拆开了，JDK 1.6之后的空间担保机制只要满足”老年代可用连续空间 &gt; 新生代对象总大小或历次晋升到老年代对象的平均大小”其中一个就可，不满足就Full GC。\n\n2、老年代Full GC算法——标记整理算法&emsp;&emsp;顾名思义，标记整理就是把老年代里活着的对象整理，紧凑在一起，避免垃圾回收后出现内存碎片。注意Full GC的速度比Minor GC慢10多倍，如果频繁出现Full GC就影响了系统性能，出现卡顿，但是你多两次Minor GC无关紧要，反正速度很快。\n&emsp;&emsp;所以，所谓JVM优化，就是尽量能让对象在新生代里进行分配和回收，别让太多对象进入老年代，避免对老年代的频繁Full GC，同时要给系统足够的内存大小来避免新生代频繁的Minor GC。\n\n未回收前\n\n回收后\n为什么老年代不用复制算法？\n&emsp;&emsp;因为老年代存活的对象太多了，如果用复制算法，每次挪动90%的对象很不方便，所以采用标记回收，把有用的挪到一边，然后回收垃圾，是很好的一个方式。\n3、针对第三节面试会问的问题(1)、什么时候会尝试触发Minor GC？ 答：当新生代的Eden区和其中一个Survivor区空间不足时。(2)、什么时候会尝试触发Full GC？答：第一是老年代可用内存小于新生代全部对象的大小，如果没开启空间担保参数，会直接触发Full GC，所以一般空间担保参数都会打开；第二是老年代可用内存小于历次新生代GC后进入老年代的平均对象大小，此时会提前Full GC；第三是新生代Minor GC后的存活对象大于Survivor，那么就会进入老年代，此时老年代内存不足，就要Full GC；第四是是“-XX:CMSInitiatingOccupancyFaction”参数的设置，当老年代中的对象到达这个比例时就会GC；（老年代可用内存大于历次新生代GC后进入老年代的对象平均大小，但是老年代已经使用的内存空间超过了这个参数指定的比例，也会自动触发Full GC）(3)、触发Minor GC之前会如何检查老年代大小，涉及哪几个步骤和条件？ 答：1、先判断新生代中所有对象的大小是否 小于 老年代的可用区域 true 则 触发Minor GC，false则继续进行下面2中的判断 2、如果设置了-XX:HandlePromotionFailure这个参数，那么进入第3步 如果没有设置-XX:HandlePromotionFailure参数，那么触发Full GC (4)、什么时候在Minor GC之前就会提前触发一次Full GC？ 答：当判断 新生代历次进入老年代对象的平均大小 大于 老年代的可用区域就会触发一次Full GC，让老年代腾出一些空间，腾出空间后再进行Minor GC。 (5)、Minor GC过后可能对应哪几种情况？ 答： 情况1：Minor GC前先判断：存活的对象所占的内存空间 &lt; Survivor区域内存空间的大小，那么存活的对象进入Survivor区。 情况2：Minor GC前先判断：Survivor区域内存空间的大小 &lt; 存活的对象所占的内存空间 &lt; 老年代的可用空间大小。那么存活的对象，直接进入老年代。 情况3：Minor GC前先判断： (存活的对象所占的内存空间 &gt; Survivor区域内存空间的大小) &amp;&amp; (存活的对象所占的内存空间 &gt; 老年代的可用空间大小)。那么会触发Full GC，老年代腾出空间后，再进行Minor GC。如果腾出空间后还不能存放存活的对象，那么会导致OOM即堆内存空间不足、堆内存溢出。 \n\n四、垃圾回收容器简介1、抛出问题：垃圾回收的同时能创建对象吗？&emsp;&emsp;不能！垃圾回收的时候，尽可能要让垃圾收集器专心工作，此时JVM在后台直接进入Stop the World状态，停止我们写的Java系统的所有线程，让我们代码不再运行。一旦回收完毕，就可以恢复线程运行了。这里要注意的就是避免频繁GC，无论是新生代还是老年代，我们都不希望系统隔一段时间卡死一下，这是JVM最需要优化的地方。当然我们可以使用适当的垃圾回收容器来缩短回收的时间。\n\n2、垃圾回收容器&emsp;&emsp;不同的内存区域使用不同的垃圾回收容器，简单介绍下垃圾回收容器\n\nSerial和Serial Old：分别用来回收新生代和老年代对象。工作原理就是单线程运行，回收的时候会停止系统中其他工作线程，现在几乎不用。\n\nParNew和CMS：ParNew是用在新生代的回收容器，CMS是用在老年代的回收容器，他们都是多线程并发机制，性能较好，一般是线上系统标配组合。\n\nG1：统一收集新生代和老年代，采用了更优秀的算法和设计机制\n\n\n多线程回收\n五、捋清概念&emsp;&emsp;有很多GC名词需要捋一下：Minor GC、Young GC、Full GC、Old GC、Major GC、Mixed GC。\n1、Minor GC 与Young GC&emsp;&emsp;年轻代 = 新生代，新生代的回收就叫Minor GC或是Young GC\n2、Full GC与Old GC&emsp;&emsp;Full GC就是整体的意思，指的是针对新生代、老年代、永久代的全体内存空间的垃圾回收，所以称之为Full GC，但是说实话，平时习惯就是把Full GC等价为Old GC，也就是仅仅针对老年代的垃圾回收。\n3、Major GC&emsp;&emsp;有些人把Major GC跟Old GC等价起来，认为他就是针对老年代的GC，也有人把Major GC和Full GC等价起来，认为他是针对JVM全体内存区域的GC。这个概念少提，如果提了，就要问清楚你到底针对整体还是针对老年代。\n4、Mixed GC&emsp;&emsp;G1中的一个垃圾回收机制，一旦老年代占据堆内存的45%了，就要触发Mixed GC，此时对年轻代和老年代都会进行回收。\n","categories":["JAVA"],"tags":["JVM"]},{"title":"JVM新生代回收器之ParNew","url":"/2020/02/22/JVM4/","content":"新生代回收器——ParNew1、工作原理&emsp;&emsp;ParNew垃圾回收器如果一旦在合适的时机执行Minor GC的时候，就会把系统程序的工作线程全部停掉，禁止程序继续运行创建新的对象，然后自己就用多个垃圾回收线程去进行垃圾回收，回收的机制和算法就跟之前说的是一样的。我们启动系统的时候可以指定垃圾回收器，使用-XX:+UseParNewGC选项，只要加入这个选项，JVM启动之后对新生代进行垃圾回收的，就是ParNew垃圾回收器了。\n&emsp;&emsp;不管是老年代回收还是新生代回收，都要Stop the World，因为必须让程序停止创建新对象，才能回收垃圾对象，新生代只需要一次stop the world的时间，在此期间完成标记清除并把存活对象转到survivor或老年代。\n\n2、ParNew垃圾回收器默认情况下的线程数量&emsp;&emsp;产生跟CPU核数一样的线程数量，比如我们线上机器假设用的是4核CPU，或者8核CPU，或者16核CPU，那么此时ParNew的垃圾回收线程数就会分别是4个线程、8个线程、16个线程，这个东西一般不用我们手动去调节。\n\n3、到底是用单线程垃圾还是多线程垃圾回收好？到底是用Serial垃圾回收器还是用ParNew垃圾回收器好？&emsp;&emsp;启动系统的时候是可以区分服务器模式和客户端模式的，如果你启动系统的时候加入-server就是服务器模式，如果加入-cilent就是客户端模式。他们俩的区别就是，如果你的系统部署在比如4核8G的Linux服务器上，那么就应该用服务器模式，如果你的系统是运行在比如Windows上的客户端程序，那么就应该是客户端模式\n&emsp;&emsp;服务器模式通常运行我们的网站系统、电商系统、业务系统、APP后台系统之类的大型系统，一般都是多核CPU，所以此时如果要垃圾回收，那么肯定是用ParNew更好，因为多线程并行垃圾回收，充分利用多核CPU资源，可以提升性能。\n&emsp;&emsp;如果你的Java程序是一个客户端程序，比如类似百度云网盘的Windows客户端，或者是印象笔记的Windows客户端，运行在Windows个人操作系统上呢？这种操作系统很多都是单核CPU，此时你如果要是还是用ParNew来进行垃圾回收，就会导致一个CPU运行多个线程，反而加重了性能开销，因为单CPU运行多线程会导致频繁的线上上下文切换，有效率开销，可能最后效率还不如单线程好。所以如果是类似于那种运行在Windows上的客户端程序，建议采用Serial垃圾回收器。\n","categories":["JAVA"],"tags":["JVM"]},{"title":"JVM老年代回收容器之CMS","url":"/2020/02/23/JVM5/","content":"JVM 老年代回收容器——CMS1、CMS工作原理&emsp;&emsp;一般老年代我们选择的垃圾回收器是CMS，他采用的是标记清理算法（不是标记整理）。之前提到过Stop the World状态，就是垃圾回收时停止一切线程的工作，如果在这个状态下再去慢慢执行标记清理算法，会导致系统卡死时间过长，所以CMS垃圾回收器采取的是垃圾回收线程和系统工作线程尽量同时执行的模式来处理的。\n&emsp;&emsp;工作原理：为了避免长时间Stop the World，CMS采用了4个阶段来垃圾回收，分别是初始标记、并发标记、重新标记和并发清理。其中初始标记和重新标记，耗时很短，虽然会导致Stop the World，但是影响不大，然后并发标记和并发清理，两个阶段耗时最长，但是是可以跟系统的工作线程并发运行的，所以对系统没太大影响。\n2、CMS垃圾回收的四个阶段（1）初始标记——标记直接GC Roots（直接）&emsp;&emsp;在这个阶段让系统的工作线程全部停止，进入Stop the World状态。同时标记所有GC Roots直接引用的对象，是直接引用！比如下面这段代码，仅仅会通过replicaManager这个类的静态变量代表的GC Roots，去标记出来他直接引用的ReplicaManager对象，不会去管ReplicaFetcher这种对象，因为ReplicaFetcher对象是被ReplicaManager类的replicaFetcher实例变量引用的。（之前说过，方法的局部变量和类的静态变量是GC Roots。但是类的实例变量不是GC Roots。）\npublic class Kafka &#123;    private static ReplicaManager replicaManager = new ReplicaManager();&#125;public class ReplicaManager &#123;    private ReplicaFetcher replicaFetcher = new ReplicaFetcher();&#125;\n\n\n初识标记如图所示\n（2）并发标记——对老年代所有对象进行GC Roots追踪（最耗时）&emsp;&emsp;这个阶段会让系统线程可以随意创建各种新对象，继续运行。在运行期间可能会创建新的存活对象，也可能会让部分存活对象失去引用，变成垃圾对象。在这个过程中，垃圾回收线程，会尽可能的对已有的对象进行GC Roots追踪。GC Roots追踪，意思就是对类似ReplicaFetcher之类的全部老年代里的对象，他会去看他被谁引用了，认定为是被GC Roots间接引用后，就不需要回收它。因为老年代里存活对象是比较多的，这个过程会追踪大量的对象，所以耗时较高。\n\n这里我看的时候有一个问题，为什么要经过初始标记而不直接进入并发标记呢？\n\n因为初始标记是用来标记GC Roots直接关联的对象，如果不在初始标记时找到哪些是GC Roots直接关联的对象的话，并发标记的GC Root Tracing没办法进行啊\n\n（3）重新标记&emsp;&emsp;第二阶段里，你一边标记存活对象和垃圾对象，一边系统在不停运行创建新对象，让老对象变成垃圾，所以第二阶段结束之后，绝对会有很多存活对象和垃圾对象，是之前第二阶段没标记出来的。在这个阶段，要再次进入Stop the World阶段，重新标记下在第二阶段里新创建的一些对象，还有一些已有对象可能失去引用变成垃圾的情况。重新标记的阶段只是对变动过的少数对象进行标记，是速度很快的\n（4）并发清理&emsp;&emsp;这个阶段就是让系统程序随意运行，然后清理掉之前标记为垃圾的对象即可，也是很耗时的。\n\n3、CMS性能分析（1）好的方面&emsp;&emsp;CMS的第二阶段和第四阶段，都是很耗时的，但都和系统程序是并发执行的，所以基本这两个最耗时的阶段对性能影响不大。只有第一个阶段和第三个阶段是需要Stop the World的，但是这两个阶段都是简单的标记而已，速度非常的快，所以基本上对系统运行响应也不大。\n（2）坏的方面①并发回收导致CPU资源紧张。&emsp;&emsp;并发标记和并发清理两个最耗时的阶段，使垃圾回收线程和系统工作线程同时工作，导致有限的CPU资源被垃圾回收线程占用了一部分。在这两个阶段，CMS的垃圾回收线程是比较耗费CPU资源的。CMS默认启动的垃圾回收线程的数量是（CPU核数 + 3）/ 4，比如的2核4G机器，就会占用(2+3)/4 = 1个CPU被用来垃圾回收。\n②Concurrent Mode Failure问题&emsp;&emsp;在并发清理阶段，CMS只不过是回收之前标记好的垃圾对象，但这个时候系统一直在运行，先把某些对象分配在新生代，然后可能触发了一次Minor GC，一些对象进入了老年代，在短时间内又没人使用这些对象，这种垃圾对象就是浮动垃圾，虽然它是垃圾，但是不会回收他们，要等到下一次才能回收。\n&emsp;&emsp;CMS垃圾触发的时机是当老年代内存占用到达一定比例时，就会自动GC，-XX:CMSInitiatingOccupancyFaction这个参数可以设置老年代内存占用到多少比例时触发垃圾回收。JDK 1.6默认是92%。预留8%的空间给并发回收期间，系统程序把一些新对象放入老年代中。如果垃圾回收期间，要放入的对象大于可用内存空间，就会发生Concurrent Mode Failure，即并发垃圾回收失败了，我一边回收，你一边把对象放入老年代，内存都不够了。此时就会自动用Serial Old垃圾回收器替代CMS，就是直接强行把系统程序Stop the World，重新进行长时间的GC Roots追踪，标记出来全部垃圾对象，不允许新的对象产生。\n③内存碎片问题&emsp;&emsp;老年代的CMS采用标记清理算法（不是标记整理），每次都是标记出来垃圾对象，然后一次性回收掉，这样会导致大量的内存碎片产生，太多的内存碎片实际上会导致更加频繁的Full GC。\n&emsp;&emsp;CMS有一个参数是-XX:+UseCMSCompactAtFullCollection，默认是打开的，意思是在Full GC之后要再次进行Stop the World，停止工作线程，然后进行碎片整理，就是把存活对象挪到一起，空出来大片连续内存空间，避免内存碎片。\n&emsp;&emsp;还有一个参数是-XX:CMSFullGCsBeforeCompaction，这个意思是执行多少次Full GC之后再执行一次内存碎片整理的工作，默认是0，意思就是每次Full GC之后都会进行一次内存整理，存活对象都放在一起，然后空出来大片连续内存空间可供使用。\n\n","categories":["JAVA"],"tags":["JVM"]},{"title":"JVM新生代与老年代参数优化","url":"/2020/02/25/JVM6/","content":"JVM 新生代与老年代参数优化一、新生代JVM参数优化1、背景引入&emsp;&emsp;假设我们的背景是每日上亿请求量的一个订单系统，按照每个用户每日访问次数为20次来算，大致有500万个用户（1亿/20），对这五百万个用户，假设付费转化率为10%，也就是有50万人会去下单，我们把这50万订单集中在4个小时的高峰期内，平均每秒钟也就几十个订单，感觉也没什么大的压力，因为几十个订单根本不需要对JVM做太多关注。\n&emsp;&emsp;但是如果到了双十一这种活动，就会出问题了。硬件方面来说，如果我们部署到足够的机器上以及机器内存充裕，也不是问题，但就JVM的参数来说，如果我们不能合理的去设置这个参数，就会导致机器资源浪费，硬件成本的增加。\n&emsp;&emsp;为什么要去调JVM参数？我们的目的就是对JVM有限的内存资源做好合理分配和优化，当然包括垃圾回收的优化，要让GC次数尽可能的少。\n&emsp;&emsp;假设双十一期间一台机器1秒要处理300个订单（处理订单比较耗时，工作经验上是每秒处理100～300个订单），对于每个订单对象我们按1KB来算，那1秒就是300KB内存开销了，但是这时订单连带对象如库存、促销、优惠券等一系列业务对象，这些对象从经验上来讲好要比订单单个对象的开销再放大10倍，同时还有很多与订单相关操作，比如查询等，往大估算就再扩大十倍，所以1秒钟，我们要处理60MB（300KB x 20 x 10 = 60000KB）对象。每1秒过后，这个对象就变成垃圾了。\n&emsp;&emsp;假设我们使用4核8G的机器，JVM分配4G，其中3G给堆内存，1G给方法区和每个线程的虚拟机栈。虚拟机栈一般都是1MB，假设我们有几百个线程，就是几百MB，这里我们给永久代256MB，给虚拟机栈总共768MB。至于堆内存，我们给新生代1.5G，老年代1.5G。得到如下参数。（注意这里不写 -XX:HandlePromotionFailure，我们使用JDK 1.8）。每1秒有60MB的垃圾，1.5G的内存大概25秒就满了。此时就要Minor GC，明显老年代能够存放新生代所有对象，可以放心GC，由于最后一秒订单还在处理，假设存活的对象就100MB，这里来问题了，如果-XX:SurvivorRatio参数默认值为8，那么此时新生代里Eden区大概占据了1.2GB内存，每个Survivor区是150MB的内存，如下图。\n-Xms3072M -Xmx3072M -Xmn1536M -Xss1M -XX:PermSize=256M -XX:MaxPermSize=256M\n\n&emsp;&emsp;所以启动JVM后，大概20秒左右，Eden区就满了，然后Minor GC，把存活对象放在Survivor1中，再过20s，再次回收Eden和Survivor1中的对象，存活的如果还是100MB就放入Survivor2中。\n&emsp;&emsp;以上就是总体的背景，此时的JVM参数为：\n-Xms3072M -Xmx3072M -Xmn1536M -Xss1M -XX:PermSize=256M -XX:MaxPermSize=256M  -XX:SurvivorRatio=8\n\n2、参数优化（1）Survivor空间的设置&emsp;&emsp;JVM优化时，首先就得考虑Survivor空间够不够。就上述案例，一种情况是，Survivor中分配了150MB，如果来的对象大于150MB，就会频繁进入老年代，第二种情况是，即使100MB对象能够放入Survivor区，但是100/150 = 0.67，超过了Survivor区空间的50%，这样同一批年龄对象也进入老年代了，这种1秒就变成垃圾的短生命周期对象根本不需要进入老年代。我们得让它们留在新生代里。\n&emsp;&emsp;方案：给Survivor区更大的容量。如果你的业务都是这种短生命周期的，老年代可以分配少一点的内存，我们可以考虑把新生代调整为2G，老年代为1G，如果-XX:SurvivorRatio=8那么此时Eden为1.6G，每个Survivor为200MB，如图。这时候上述两个问题就同时解决了。\n&emsp;&emsp;针对任何系统，我们要预估内存并合理分配内存，首要做的就是尽量让每次Minor GC后的对象都留在Survivor里，不要进入老年代。此时参数如下\n-Xms3072M -Xmx3072M -Xmn2048M -Xss1M  -XX:PermSize=256M -XX:MaxPermSize=256M  -XX:SurvivorRatio=8\n\n\n（2）-XX:MaxTenuringThreshold参数的设置&emsp;&emsp;有些对象是可能躲过15次垃圾回收进入老年代的，就上述背景，有些对象在新生代躲了几分钟进入老年代很应该，那为了不让这种数据进入老年代要怎么做？我们需要调-XX:MaxTenuringThreshold这个参数。这个参数并不是一昧地去调高，一定要结合系统的运行模型，看看Minor GC频率，把这个参数从15调高到20、30，让一个垃圾多在Survivor中停留几分钟，根本没用，对于我们上述业务场景就要把这个参数调低，比如调到5.记住，一定要结合系统运行的模型。此时参数如下：\n-Xms3072M -Xmx3072M -Xmn2048M -Xss1M  -XX:PermSize=256M -XX:MaxPermSize=256M  -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=5\n\n（3）-XX:PretenureSizeThreshold参数设置&emsp;&emsp;大对象是可以直接进入老年代的，但是多大呢？一般来说很少有超过1MB的对象，如果有，那就是你提前分配了一个大数组、大List之类的来存放缓存数据，一般这种数据是要用一段时间的，所以我们可以放到老年代。我们一般把这个参数设置为1。此时JVM参数如下：\n-Xms3072M -Xmx3072M -Xmn2048M -Xss1M  -XX:PermSize=256M -XX:MaxPermSize=256M  -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=5 -XX:PretenureSizeThreshold=1M\n\n（4）指定垃圾回收器&emsp;&emsp;针对具体的客户端、服务端来设置垃圾回收器，之前讲过。我们这个系统新生代使用ParNew，老年代使用CMS。设置如下的参数：\n-Xms3072M -Xmx3072M -Xmn2048M -Xss1M  -XX:PermSize=256M -XX:MaxPermSize=256M  -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=5 -XX:PretenureSizeThreshold=1M -XX:+UseParNewGC -XX:+UseConcMarkSweepGC\n\n二、老年代JVM参数优化&emsp;&emsp;老年代参数优化主要就是减少Full GC的次数。首先我们得要分析对象进入老年代的几个原因\n1、对象进入老年代的原因第一种：就是-XX:MaxTenuringThreshold这个参数设置的太低了，就是之前新生代的案例，这种对象一般是@Service或Controller等注解标识的业务逻辑组件，这种对象一般全局有一个实例就行，是要一直用的，所以应该让他进。\n第二种：就是大对象，但是这种再上述案例中一般没有，可以忽略。\n第三种：就是Minor GC后存活的对象超过了Survivor区的50%，就直接进入了老年代\n2、大促销场景的Full GC多久出发一次？&emsp;&emsp;对于此案例触发Full GC的几个情况：\n情况一：没有打开 -XX:HandlePromotionFailure选项。我们知道如果老年代剩余内存大于新生代对象总大小就直接Minor GC的，但是老年代剩余内存总大小小于新生代对象总大小时，就要看这个参数了，如果没有打开这个参数，老年代空间小于新生代所有对象大小就直接Full GC，如果打开了，就看平均。这个参数就是看老年代剩余内存总大小是否大于之前每一次Minor GC进入老年代的对象的平均大小，按照之前项目案例，要很多次Minor GC之后才可能有一两次碰巧会有200MB对象升入老年代，所以这个“历次Minor GC后升入老年代的平均对象大小”，基本是很小的。（JDK 1.6之后就不看了）\n情况二：某次升入老年代的对象很大，但是老年代空间不够了。\n情况三：和-XX:CMSInitiatingOccupancyFaction参数有关，默认值是92%，超过这个值就会GC。\n&emsp;&emsp;针对大促销场景，由于我们之前在新生代优化了参数，所以对象进入老年代较慢，经验上来说，很可能是在系统运行半小时~1小时之后，才会有接近1GB的对象进入老年代。在大促期间，订单系统运行1小时之后，大促下单高峰期几乎都快过了，此时才可能会触发一次Full GC。这个高峰期过后，基本订单系统访问压力就很小了，那么GC的问题几乎就更不算什么了。\n&emsp;&emsp;当然老年代也会触发Concurrent Mode Failure问题。假设系统，运行1小时之后，老年代大概有900MB的对象了，剩余可用空间仅仅只有100MB了，然后CMS进行垃圾回收，垃圾回收期间是和系统程序并发的，如果系统此时还在创建对象，比如说很不巧有200MB对象要进来了，而老年代又放不下，那么此时就会进入Stop the World，然后切换CMS为Serial Old，直接禁止程序运行，然后单线程进行老年代垃圾回收，回收掉900MB对象过后，再让系统继续运行。当然这个概率非常的小，我们没必要特意去优化它。\n此时参数为:\n-Xms3072M -Xmx3072M -Xmn2048M -Xss1M  -XX:PermSize=256M -XX:MaxPermSize=256M  -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=5 -XX:PretenureSizeThreshold=1M -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFaction=9\n\n3、CMS后内存碎片整理频率&emsp;&emsp;没必要特意去修改这个频率，对于上述大促销场景，在大促高峰期，Full GC可能也就1小时执行一次，然后大促高峰期过去之后，就没那么多的订单了，此时可能几个小时才会有一次Full GC。所以就保持默认的设置，每次Full GC之后都执行一次内存碎片整理就可以。要针对特定的业务场景来设定。仅仅针对这个参数来说：\n\n如果Full GC相对频繁，就设置多次Full GC后进行碎片整理\n如果不是很频繁，可以设置每次Full GC后进行碎片整理\n\n三、面试题1、一个面试题：parnew+cms的gc，如何保证只做ygc，jvm参数如何配置？首先和垃圾收集器没什么关系，不同的垃圾收集器，只是它们的性能、吞吐量不同，并不影响垃圾回收的时机。只要在新生代根据对象的存活特征，合理的去分配Eden区和s1、s2区域的大小，尽量让垃圾在新生代被回收就好了，注意这边开启内存担保（jdk 1.6），如果eden区超过了老年代大小，不开担保的话每次MGC前都要FGC的。\n2、为什么老年代回收比新生代慢？新生代存活对象小，并且采用复制算法，速度很快，复制过去直接就删除，而老年代对象量较大，遍历标记、遍历清除，然后还要整理好腾出空间来，很耗时，耗时的就是步骤二和步骤四。初始标记是从GC Roots查找直接引用的对象，并发标记也是从GC Roots出发，通过每个对象的引用地址来看哪些对象活着的，活着的又很多，就很耗时。\n","categories":["JAVA"],"tags":["JVM"]},{"title":"G1垃圾回收器详解与回收性能优化","url":"/2020/02/26/JVM7/","content":"G1垃圾回收器详解与回收性能优化一、G1的引出1、G1与堆内存&emsp;&emsp;新生代还是老年代，Stop the World是最大的痛点，它们都会产生这个现象，影响系统的运行，所有垃圾回收器的优化都是朝着减少STW的目标去做的，G1便应运而生了。G1可以同时回收新生代和老年代，它的最大特点，就是把Java堆内存拆分为多个大小相等的Region，如图，所以G1的新生代老年代是一种逻辑上的概念了，新生代可能包含了某些Region，老年代可能包含了某些Reigon。另一个最大特点，就是允许我们设置一个垃圾回收的预期停顿时间，比如我们可以指定1小时内回收垃圾的时候产生的STW时间要小于1min\n&emsp;&emsp;G1相比之前的垃圾回收器，最大进步就是STW可控\n\n&emsp;&emsp;给整个堆内存设置了大小后，启动JVM，一旦发现你使用的是G1垃圾回收器（通过使用-XX:+UseG1GC这个参数来设置），那就会自动用堆内存大小除以2048（默认情况下是这个，当然我们可以通过-XX:G1HeapRegionSize参数来指定），因为最多可以有2048个Region，Region的大小为2的倍数，比如堆内存给2G，那Region可能是1MB、2MB、4MB这样的，堆内存给4G，那每个Region就是2MB。\n&emsp;&emsp;Region区域既有新生代，也有老年代，这时候就不需要去给他们分配内存了，这两个区域是由G1控制，不停变动的。默认新生代堆内存占比是5%，当然可以通过-XX:G1NewSizePercent参数来设置新生代初始占比，一般都是维持这个默认值，因为系统运行时会动态变化。\n&emsp;&emsp;此外，新生代还是有Eden和Survivor划分的，之前有个参数是-XX:SurvivorRatio=8，意思是说80%的Eden，20%的Survivor，在这里，比如新生代初始共100个Region，那就是80个Eden，两个Survivor各占十个。随着动态分配，比如新生代的Region不断增加，那么Eden和Survivor对应的Region也会不断增加。\n2、G1如果做到对于系统的停顿可控的？&emsp;&emsp;G1要做到这一点必须追踪每一个Region的回收价值，所谓回收价值就是根据设定的预期系统停顿时间，来选择最少回收时间和最多回收对象的Region进行垃圾回收，保证GC对系统停顿的影响在可控范围内，同时还能尽可能回收最多的对象。（有点类似贪心算法）。\n二、G1的垃圾回收机制1、G1新生代Region的垃圾回收前提：新生代占据了整个堆大小的60%。（比如我们划分了2000个Region，差不多有1200个新生代Region，其中Eden占1000个，每个Survivor各占100个，如图）\n\n这时候还是会触发Minor GC，使用复制算法，进入Stop the World，把Eden中活着的对象放进S1对应的Region，然后回收。看起来和ParNew没区别，其实是有区别的，因为我们给G1设定了停顿时间（参数-XX:MaxGCPauseMills,默认200ms），那么G1首先会对每个Region追踪回收的时间，再选择，来尽可能多回收掉一点对象。\n当然也有进入老年代的几种情况：\n\n第一种是超过我们设定的年龄阈值的对象，就会进入老年代Region；\n\n第二种是存活的对象超过了Survivor的50%（动态年龄判断规则）\n\n\n对于大对象的处理，不放入老年代!!G1提供了专门的Region来存放大对象（并不是60%新生代，40%老年代，动态变化的，G1会自己处理），只要一个对象超过了一个Region大小的50%，就会被放过去，这个对象如果太大，还可以横跨多个Region来存放。另外大对象的回收是跟着新生代老年代的回收一起进行的。\n2、G1混合垃圾回收——Mixed GC（1）Mixed GC的触发时机G1有一个参数，是-XX:InitiatingHeapOccupancyPercent，他的默认值是45%,这个参数的意思是如果老年代占据了堆内存的45%的Region的时候，此时就会尝试触发一个新生代+老年代一起回收的混合回收阶段。\n（2）Mixed GC的停止时机混合回收都是基于复制算法进行的，把要回收的Region区存活的对象放入其他Region，然后这个Region全部清理掉，这样就会不断空出来新的Region，有一个参数-XX:G1HeapWastePercent，默认值是5%，就是说空出来的区域大于整个堆的5%，就会立即停止混合回收了。正常默认回收次数是8次，但是可能到了4次，发现空闲Region大于整个堆的5%，就不会再进行后续回收了。\n（3）回收失败问题可以看出G1整体都是基于复制算法进行，不会出现内存碎片问题，但另一个问题是，Mixed GC中新生代、老年代都是复制算法，对象复制时候别的Region内存不够了咋办？那就是回收失败了！就会立即停止系统程序，然后采用单线程去标记、清理、压缩整理，再空闲出新的Region，这个过程极其缓慢！（采用的是Serial Old回收器）\n3、Mixed GC的四个阶段（1）初始标记阶段这个过程需要进入Stop the World的，仅仅只是标记一下GC  Roots直接能引用的对象，这个过程速度是很快的。如下图，先停止系统程序的运行，然后对各个线程栈内存中的局部变量代表的GC Roots，以及方法区中的类静态变量代表的GC Roots，进行扫描，标记出来他们直接引用的那些对象。\n\n（2）并发标记阶段这个阶段会允许系统程序的运行，同时进行GC Roots追踪，从GC Roots开始追踪所有的存活对象，并对这个过程对象的变化做记录，比如哪些对象失去了引用，哪些对象是新建的。如下图所示。（这个阶段也是很耗时的，要追踪全部存活的对象，但跟系统并发运行，影响不大）\n\n（3）最终标记阶段这个阶段会进入Stop the World，系统程序是禁止运行的，但是会根据并发标记阶段记录的那些对象修改，最终标记一下有哪些存活对象，有哪些是垃圾对象，如下图所示。\n\n（4）混合回收阶段&emsp;&emsp;基于复制算法，这个阶段会计算老年代中每个Region中的存活对象数量，存活对象的占比，还有执行垃圾回收的预期性能和效率。接着会停止系统程序，然后全力以赴尽快进行垃圾回收，此时会选择部分Region进行回收，因为必须让垃圾回收的停顿时间控制在我们指定的范围内。\n&emsp;&emsp;注意，这里到底回收哪些Region是G1自己选择的，这里的混合回收是指在我们指定的时间（比如200ms）内回收尽可能多的垃圾。\n&emsp;&emsp;另外，这个阶段G1允许多次执行混合回收，也就是说先停止系统工作，执行回收，恢复系统运行，再停止系统运行，再回收，再恢复…这么一个流程。每次回收的间隔是由G1自己控制的，回收执行次数可以通过参数-XX:G1MixedGCCountTarget来设置，这个参数默认回收次数是8次，同时有一个参数-XX:G1HeapWastePercent，默认值是5%，就是说空出来的区域大于整个堆的5%，就会立即停止混合回收了。正常默认回收次数是8次，但是可能到了4次，发现空闲Region大于整个堆的5%，就不会再进行后续回收了。这种多次回收的机制能够让系统停顿时间不要太长，可以在多次回收的间隙也运行一下。\n\n4、G1垃圾回收的参数\n-XX:+UseG1GC：设置使用G1垃圾回收器\n-XX:MaxGCPauseMills：设定系统停顿时间，默认200ms\n-XX:G1HeapRegionSize：设置区域划分的个数和大小，默认堆大小/2048\n-XX:G1NewSizePercent：用来设置新生代初始占比的，默认值为5%即可。\n-XX:G1MaxNewSizePercent：用来设置新生代最大占比的，默认值为60%即可。\n-XX:SurvivorRatio=8：设置新生代Region区域中Eden和Survivor的比例，默认8:1:1\n-XX:InitiatingHeapOccupancyPercent：设置Mixed GC的比例，默认45%\n-XX:G1MixedGCCountTarget：混合回收阶段最多允许G1执行回收的次数，默认是8次。\n-XX:G1HeapWastePercent：默认值5%，Mixed GC时空出来的Region大于5%，就停止混合回收。\n-XX:G1MixedGCLiveThresholdPercent：默认值是85%，确定要回收的Region的时候，必须是存活对象低于85%的Region才可以回收。\n\n三、G1性能优化1、背景引入&emsp;&emsp;百万级用户的在校教育平台，首先分析这个系统最高频的行为。作为用户，浏览课程详情、下单付费、选课排课，这些都是绝对的低频行为，我们几乎不用考虑到系统的运行中去，可以暂时忽略掉。对于这样的一个系统，他最关键的高频行为只有上课！就是每天晚上那两三小时的高峰时期，几乎你可以认为每天几十万日活用户（那些小孩儿）都会集中在这个时间段来平台上上在线课程。所以这个晚上两三小时的时间段里，将会是平台每天绝对的高峰期。那哪个功能最常用呢？除了上课学习，就是互动了。\n&emsp;&emsp;分析这个系统核心点就是搞明白在晚上两三小时高峰期内，每秒钟会有多少请求，每个请求会连带产生多少对象，占用多少内存，每个请求要处理多长时间。\n&emsp;&emsp;假设晚上3小时有60w活跃用户，按平均每个用户1小时上课，每小时20w用户，对于每个用户1分钟1次互动，1分钟60次，20万人1分钟就是1200万次互动，平均每秒3000次，也就是1秒承受3000次请求。假设我们使用的是4核8G的机器，差不多需要5台，每台1秒抗住600个请求。互动过程一般不会有复杂对象，算上连带对象也就占几KB，假设5KB，1秒就是3MB左右内存（5*600/1000）。\n&emsp;&emsp;分配4G给堆内存，其中新生代默认初始占比为5%，最大占比为60%，每个Java线程的栈内存为1MB，元数据区域（永久代）的内存为256M，新生代初始占比和最大新生代占比维持默认值即可，不用设置，分别为5%和60%，此时JVM参数如下：\n-Xms4096M -Xmx4096M  -Xss1M  -XX:PermSize=256M -XX:MaxPermSize=256M -XX:+UseG1GC\n\n&emsp;&emsp;此时每个Region大小为4G/2048 = 2MB，新生代占5%，算它100个Region，200MB，停顿时间我们先不设置，使用默认值200ms。此时大概不到1分钟就塞满这100个新生代Region了，此时你会觉得由于GC是很灵活的，他会根据你设定的gc停顿时间给你的新生代不停分配更多Region，然后到一定程度，感觉差不多了，就会触发新生代gc，保证新生代gc的时候导致的系统停顿时间在你预设范围内，这是它的一个原理，但事实不是这样的，具体情况要通过工具去查看。\n2、优化对于新生代，主要是避免短生命对象进入老年代\n\n预估每次Minor GC后存活下来对象的大小，合理的设置Survivor区，同时考虑高峰期间时，动态年龄判断条件的影响，不要让这种短生命周期对象侥幸逃脱进入老年代\n大对象有他自己的Region，不用操心\n\n对于老年代\n\n系统的停顿时间时关键！是核心，要预测停顿时间，并不是越小越好，过小则回收效果不大\n\n（1）-XX:MaxGCPauseMills 参数优化\n这个参数是核心点！如果参数设置的值很大，导致系统运行很久，新生代可能都占用了堆内存的60%了，此时才触发新生代GC，那么存活下来的对象可能就会很多，此时就会导致Survivor区域放不下那么多的对象（或是动态年龄判定规则），就会进入老年代中。如果参数设置过小，即使GC停顿时间很短，但GC频率太大，比如说30秒触发一次新生代gc，每次就停顿30毫秒，这样也是很影响系统性能的。至于到底如何优化这个参数，要结合工具的实战演练。\n（2）Mixed GC优化\n优化Mixed GC并不是优化它的参数，因为它的参数太多了，尽量避免对象过快进入老年代，尽量避免频繁触发Mixed GC，就可以做到根本上优化Mixed GC了。这边核心还是-XX:MaxGCPauseMills这个参数。如上所说\n四、G1的适用场景与总结1、适合超大内存机器&emsp;&emsp;如果内存是一个大堆，比如部署在有16G、32G的内存的机器上，比如类似Kafka、Elasticsearch之类的大数据相关的系统，都是部署在大内存的机器上的，此时如果你的系统负载非常的高，比如每秒几万的访问请求到Kafka、Elasticsearch上去。那么可能导致你Eden区的几十G内存频繁塞满要触发垃圾回收，假设1分钟会塞满一次。如果使用传统回收器（比如ParNew+CMS），不用G1，会导致新生代每次GC回收的次数太多了，STW一多，停顿时间太长，使用G1可以指定每次停顿的时间来回收一部分Region，这样就很合适。从上面停顿时间太长这个角度出发，G1就适合要求低延时的业务。\n&emsp;&emsp;另外G1压缩内存空间有优势，适合会产生大量碎片的应用。\nParNew+CMS适合内存小的\n2、总结（1）G1小结G1和ParNew+CMS的调优原则都是尽可能Minor GC，G1则更加智能，而PN+CMS更纯粹更直接，虽然G1在GC时没有碎片，但是由于每个Region有一个存活率大于85%不清理的机制，会导致内存没有充分释放。因此，对于cpu性能高的，内存容量大的，对应用响应度高的系统推荐使用g1。 而内存小，cpu性能比较低下的系统也可以使用pn+cms会更合适。\n（2）回收过程小结\n如果新生代未达60%，老年代未达45%，系统照常运行，不会触发回收 \n如果新生代达60%，此时如果有新对象生成，跑到新生代，就会触发Minor GC\n开启了空间担保机制，Minor GC前先判断是否需要Full GC,如果每次回收后对象小于老年代空闲大小，则不用Full,否则要。（JDK 1.6之前是把空间担保机制和HandlerPromotionFailure参数拆开了，JDK 1.6之后的空间担保机制只要满足”老年代可用连续空间&gt;新生代对象总大小或历次晋升到老年代对象的平均大小”其中一个就可，不满足就Full GC）\n不用触发Full GC，但Minor GC后的对象大于老年代空闲大小，无法直接进入老年代，触发Full GC\n\n\n老年代堆内存占了45%了，触发混合回收（四个阶段：先STW通过GC Root初始标记哪些是有直接引用的，然后并发标记追踪GC Roots所有对象，此时与系统并发执行，接着最终标记，STW，标记并发标记过程中心新来的对象和新产生的垃圾，最后混合回收，采用的是复制算法，不会产生垃圾碎片，G1按照我们给定时间去进行性价比高的回收，回收次数可以设置，默认是八次，如果回收过程中，空闲Region超过了堆内存的5%，会提前结束，当然可以修改这个参数，另外如果回收失败，转而使用Serial Old回收器，回收变得很慢）\n\n","categories":["JAVA"],"tags":["JVM"]},{"title":"OOM问题的分析与解决","url":"/2020/02/28/JVM9/","content":"OOM 问题的分析与解决一、OOM原因与场景模拟1、Metaspace内存溢出（1）原因首先来讲Metaspace的回收，当Metaspace快满了就要进行回收，但是这个回收条件比较苛刻，比如这个类的类加载器要先被回收、这个类的所有实例对象要被回收等等，所以即使Metaspace满了，未必能回收掉很多类，腾不出太多空间，又要放进入，就会导致OOM，一般来说，Metaspace的OOM有两个原因\n第一个原因是我们忘记去设置永久区的大小了，默认永久区大小只有几十MB，太小了，我们一般设置为256MB～512MB。有两个参数是来设置区域大小的：-XX:MetaspaceSize=512m 和-XX:MaxMetaspaceSize=512m。一般来说512MB足够！\n第二个原因是写系统的时候使用了cglib之类的技术，来动态的生成一些类，一旦没控制好生成类的个数就很容易把Metaspace塞满，引发内存溢出。\n\n示意图：内存溢出\n（2）场景模拟这里使用cglib来模拟Metaspace的OOM\n\n使用cglib来增强Car类的run方法，实质就是cglib的Enhancer能在系统运行期间动态的生成Car的子类。在JVM参数中动点手脚，把Metaspace的区域限制得小一点：\n-XX:MetaspaceSize=10m -XX:MaxMetaspaceSize=10m\n\n然后价格计数器来看它能生成多少个子类，得到日志\nException in thread &quot;main&quot; java.lang.IllegalStateException: Unable to load cache itemat net.sf.cglib.core.internal.LoadingCache.createEntry(LoadingCache.java:79)at net.sf.cglib.core.internal.LoadingCache.get(LoadingCache.java:34)at net.sf.cglib.core.AbstractClassGenerator$ClassLoaderData.get(AbstractClassGenerator.java:119)at net.sf.cglib.core.AbstractClassGenerator.create(AbstractClassGenerator.java:294)at net.sf.cglib.reflect.FastClass$Generator.create(FastClass.java:65)at net.sf.cglib.proxy.MethodProxy.helper(MethodProxy.java:121)at net.sf.cglib.proxy.MethodProxy.init(MethodProxy.java:75)at net.sf.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:226)at com.limao.demo.jvm.Demo1$1.intercept(Demo1.java:22)at com.limao.demo.jvm.Demo1$Car$$EnhancerByCGLIB$$7e5aa3a5_264.run(&lt;generated&gt;)at com.limao.demo.jvm.Demo1.main(Demo1.java:30)Caused by: java.lang.OutOfMemoryError: Metaspaceat java.lang.Class.forName0(Native Method)at java.lang.Class.forName(Class.java:348)at net.sf.cglib.core.ReflectUtils.defineClass(ReflectUtils.java:467)at net.sf.cglib.core.AbstractClassGenerator.generate(AbstractClassGenerator.java:339)at net.sf.cglib.core.AbstractClassGenerator$ClassLoaderData$3.apply(AbstractClassGenerator.java:96)at net.sf.cglib.core.AbstractClassGenerator$ClassLoaderData$3.apply(AbstractClassGenerator.java:94)at net.sf.cglib.core.internal.LoadingCache$2.call(LoadingCache.java:54)at java.util.concurrent.FutureTask.run(FutureTask.java:266)at net.sf.cglib.core.internal.LoadingCache.createEntry(LoadingCache.java:61)\n\n发送有一行就是OOM，明确告诉你溢出了。\n一般使用动态代理要记得用缓存！这个子类只要生成一次就可以了，下次能直接用，如果没有缓存这个动态生成的类，每次调用生成一个类，若线上负载很高，可能导致瞬间创建一大堆类，塞满元数据空间，直接OOM，系统崩溃。\n2、栈内存溢出（1）原因JVM把类加载进内存后，就通过main线程执行main方法，方法调用的栈帧不断压入虚拟机栈，这都是占栈内存的，每一个虚拟机栈的大小是固定的，比如1MB，虽然说一些变量和其他数据占卜了太多，但是这个栈帧是会占内存的，一个方法调用的栈帧要占个几百字节。如果我们不停的调用方法，不停的往栈里放入栈帧，就会导致OOM。\n（2）场景模拟代码设置\npublic class Demo &#123;    public static long counter = 0;    public static void main(String[] args) &#123;        work();    &#125;    public static void work() &#123;        System.out.println(&quot;目前是第&quot; + (++counter) + &quot;次调用方法&quot;);        work();    &#125;&#125;\n\nJVM参数设置\n-XX:ThreadStackSize=1m\n\n直接打印出结果\n目前是第5729次调用方法目前是第5730次调用方法Exception in thread &quot;main&quot; java.lang.StackOverflowError\n\n（3）处理思路在JVM参数中加入打印日志参数和内存快照参数，但是内存快照参数主要是分析堆内存的Metaspace的，对于栈内存而言不需要用。运行本地代码能够得到异常报错的调用栈，直接告诉你溢出问题来自哪个类的哪个方法，可以直接定位到。\nat com.demo.jvm.Demo2.work(Demo2.java:13)at com.demo.jvm.Demo2.work(Demo2.java:13)\n\n\n\n3、堆内存溢出（1）原因对象进来先进入Eden区，Eden区满了则Young GC，多次GC后S区也满了，S区放不下放进了老年代，慢慢的，老年代也满了，那就得等CMS进行回收，如果此时Full GC后，依然存活下来很多对象，而此时又有对象要放进老年代，如果老年代空间不足，就会再出发Full GC，触发后还是没足够空间，如果还坚持要放就会导致OOM。\n总的来说，就是有限的空间放了过多的对象，大多数都是存活的，即使GC后也有很多存活的，再放进新的对象就不行了，此时就引发OOM了。\n内存溢出的两个场景\n第一个场景：系统承载高并发请求，因为请求量过大，导致大量对象都是存活的，所以要继续放入新的对象实在是不行了，此时就会引发OOM。\n第二个场景：系统有内存泄漏的问题，莫名其妙弄了很多的对象，结果对象都是存活的，没有及时取消对他们的引用，导致触发GC还是无法回收，此时只能引发内存溢出\n总的来说，一般引发OOM不是系统负载过高就是有内存泄漏问题。\n（2）场景模拟代码\npublic class Demo &#123;    public static void main(String[] args) &#123;        long counter = 0;        ArrayList&lt;Object&gt; list = new ArrayList&lt;&gt;();        while (true) &#123;            list.add(new Object());            System.out.println(&quot;目前创建了第&quot; + (++counter) + &quot;个对象&quot;);        &#125;    &#125;&#125;\n\nJVM参数设置堆内存大小总共10MB，尽快触发溢出\n-XX:InitialHeapSize=10485760-XX:MaxHeapSize=10485760\n\n结果\n目前创建了第360145个对象Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space\n\n（3）处理思路添加打印日志参数和堆内存快照参数，得到日志文件，中有这么几行，告诉我们堆内存溢出了\njava.lang.OutOfMemoryError: Java heap spaceDumping heap to ./java_pid1023.hprof ...Heap dump file created [13409210 bytes in 0.033 secs]Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space\n\n接着我们用mat来分析\n\n第一句话，这个main线程的局部变量引用了7203536个字节对象（7MB），我测试时候给堆内存总共是10MB，所以7MB差不多极限。第二句话，表明内存被一个Object的实例对象占满了。点开下方的Details就真相大白了\n\n我们要知道这些对象是怎么创建的，就可以使用See stacktrace\n\n二、OOM时自动dump内存快照解决OOM首先就要知道是什么对象导致了OOM，获取dump内存快照，使用mat工具来分析，此时需要在JVM中加入两个参数\n-XX:+HeapDumpOnOutOfMemoryError  \t//在OOM的时候自动dump内存快照出来-XX:HeapDumpPath=/usr/local/app/oom\t\t//内存快照dump地址\n\nJVM参数模版\n-Xms4096M -Xmx4096M -Xmn3072M -Xss1M  -XX:MetaspaceSize=256M -XX:MaxMetaspaceSize=256M -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFaction=92 -XX:+UseCMSCompactAtFullCollection -XX:CMSFullGCsBeforeCompaction=0 -XX:+CMSParallelInitialMarkEnabled -XX:+CMSScavengeBeforeRemark -XX:+DisableExplicitGC -XX:+PrintGCDetails -Xloggc:gc.log -XX:+HeapDumpOnOutOfMemoryError  -XX:HeapDumpPath=/usr/local/app/oom”\n\n三、导致OOM的实例1、每秒仅上百请求的事故现场每秒仅100+请求的系统报警发生异常，第一件事就是登陆到线上机器去看日志文件。看到有这么一行\nException in thread &quot;http-nio-8080-exec-1089&quot; java.lang.OutOfMemoryError: Java heap space\n\n这里http-nio-8080-exec-1089说的其实就是Tomcat的工作线程。我们写的系统都是部署在Tomcat中的。最早我们会在IDE上写一堆的Servlet，然后打包之后放入Tomcat，再启动Tomcat，接着我们访问Tomcat监听的一个端口号（一般是8080），然后系统的功能就可以运行起来了。后来随着技术发展，我们不再写Servlet这么原始的东西了，有一些类似Spring MVC之类的框架把Servlet封装起来了，我们就基于Spring MVC之类的框架去开发。再到后来，越来越先进了，出现了Spring Boot，我们可以把Tomcat之类的Web容器都内嵌在系统里。再到后来甚至是基于Spring Cloud去开发分布式的系统。我们基于Spring Cloud、Spring Boot、Spring Web MVC等技术，写好一套系统，给打包之后，放入线上服务器中部署的Tomcat目录下，然后启动Tomcat就可以了。每当Tomcat间听到了请求，就会把请求交给框架去处理，框架会根据请求路径，找到代码中处理这个请求的Controller组件。如图。\n\nTomcat自己本身就是个JVM进程，我们写好的系统只不过是一些代码，一个个类被Tomcat加载到内存中，由Tomcat来执行。Tomcat有很多的线程，少则100来个，多则三四百个，从8080端口上收到的请求就交给这些线程去做，这些线程收到请求后就回去调用框架的代码，框架再调用我们写好的代码，这基本就是Tomcat的底层原理了。如图\n\n碰到事故，首先先看是三个区域中哪里溢出了，其次看是哪个线程溢出的（MAT可以看有哪些线程存在），可能是Tomcat的线程，也可能是我们自己的线程。每个系统上线务必设置-XX:+HeapDumpOnOutOfMemoryError以及导出内存快照，排查问题基本依靠内存快照。\n","categories":["JAVA"],"tags":["JVM"]},{"title":"J.U.C AQS 源码解读","url":"/2019/09/24/SourceCode-AQS/","content":"简介和属性\n整理的很垃圾，别看了会被误解的，后续会更新\n\n同步器AbstractQueuedSynchronizer，它是各种锁的底层，比如ReentrantLock、CountDownLatch。肯定要各种队列知识的，之前看过了。找了张很不错的图\n\naqs就两个队列，条件队列、同步队列，也就是sync queue 和condition queue，队列底层又是链表，1、2、3代表看的顺序，四种颜色代表四种不同的场景。aqs就是一套框架，定义了获得锁和释放锁的代码结构，你要新搞个锁，继承aqs就行。\n\n大概\n\n本身就是个抽象类，要让子类去实现一些东西，它只是定义了如何获得锁、释放锁的抽象方法，aqs继承了aos，为的是知道当前哪个线程拿到了锁，监控它\naqs首先定义了一个fifo的 sync queue，拿不到锁的线程就去队列中排队吧\n然后同步器有个状态字符，用的是atomic包里的，可以通过状态字段来判断能不能获得锁。aqs的子类是通过给状态赋值（cas操作）来决定能不能拿到锁，比如我定义0就是可以获得锁，1就是不能获得锁。\naqs提供了排他锁和共享锁的实现，readwritelock实现了两种模式。\naqs内部的条件队列是通过 new ConditionObject得到的\n\n\n简单属性\n\n state 属性，int类型，所有继承 aqs 的锁都是通过这个字段来判断能不能获得锁，能不能释放锁。比如当前同步器状态是 0，表示可以获得锁，当前同步器状态是 1，表示锁已经被其他线 程持有，当前线程无法获得锁，state是锁的状态，，下面还有个事waitStatus，它是队列中节点的状态，别搞混了\n\n\nsync queue 同步队列\n\n有俩重要属性，同步队列的头和同步队列的尾巴，多个线程竞争一把锁，只有一个线程能拿到，其他都跑到队列尾曲了，有人释放锁，是从同步队列头开始释放一个排队的线程，让线程重新去竞争锁，同步队列的作用很简单的，就是阻塞你们这些获得不到锁的线程，然后在合适的时候释放。同步队列底层是个双向链表\n\n\n\ncondition queue 条件队列\n\n条件队列也是管理那些获取不到锁的线程，但是它只是和锁配合着使用，底层是一个链表，firstwaiter是第一个等待的，lastwaiter是最后一个等待的node，使用时候直接new ConditionObject，它实现了Condition接口，Condition接口相当于各种监控方法，类似于Object的wait、notify\n\n\n\n同步队列和条件队列的节点Node\n\n一般是用Node把线程包装一下就放进队列中了\n\n```javastatic final class Node {\n    static final Node SHARED = new Node();        //共享的\n    static final Node EXCLUSIVE = null;        //排他的\n\n          //状态看这个https://www.jianshu.com/p/3a7e8c028dd8\n          //被取消状态\n    static final int CANCELLED =  1;        \n\n          //cur.next处于等待状态，如果cur释放锁（将cur状态置为-1），然后通知它的下一个\n    static final int SIGNAL    = -1;    \n\n          //节点处于等待队列中，节点线程等待在Condition上，当其他线程对Condition调用了signal()方法后，该节点从等待队列中转移到同步队列中，加入到对同步状态的获取中；\n    static final int CONDITION = -2;\n\n          //代表后续结点会传播唤醒的操作，共享模式下起作用\n    static final int PROPAGATE = -3;\n\n          //表示当前节点的状态，通过节点的状态来控制节点的行为\n          //普通同步节点，就是 0 ，条件节点是 CONDITION -2\n          //ws大于0，说明被取取消了\n    volatile int waitStatus;\n\n          //当前节点的前驱节点\n          //节点 acquire 成功后就会变成head，head 节点不能被 cancelled\n    volatile Node prev;\n\n    // 当前节点的下一个节点\n    volatile Node next;\n\n    //当前节点的线程\n    volatile Thread thread;\n\n    //等待节点的后继节点。\n          //在同步队列中，Node构建同步队列节点，nextWaiter标识同步锁是独占锁的还是共享锁\n          //在条件队列中，nextWaiter指向单向链表下一个节点\n           //这边特别要注意，看的时候给我带来了很大困扰\n    Node nextWaiter;\n\n    //是否被共享\n    final boolean isShared() {\n        return nextWaiter == SHARED;\n    }\n\n  - 特别特别注意，nextWaiter 是条件队列中下一个节 点的指向字段，但在同步队列中，nextWaiter 只是一个标识符，表示当前节点是共享还是排它模式。- 条件队列 ConditionObject  - ConditionObject它是实现了Condition接口的，所以这个接口很重要，细节如下    - 注释中说，当用lock代替synchronized的时候，Condition就能代替Object中相应的监控方法了，比如wait、notify、notifyAll等。Condition的实例它是绑定在锁上的，lock.newCondition就能获得实例了。    - 为什么需要条件队列，举个例子，我有put和take方法，put的时候，如果满了，就会阻塞，take的时候，如果空了，就会阻塞，这两种情况的线程其实都会去条件队列中阻塞，**如果仅仅依靠一个条件队列，那就只能执行一个操作，那在这种情况下，我可以新建两个条件队列，建几个具体还是看需求吧，这样就可以分别执行操作了。**  - condition中的一些方法    - ```java      // 唤醒条件队列中的一个线程，在被唤醒前必须先获得锁      void signal();            // 唤醒条件队列中的所有线程       void signalAll();            //使当前线程一直等待，直到被 signalled 或被打断。      //被唤醒时，特别注意:线程从条件队列中苏醒时，必须重新获得锁，才能真正被唤醒      //当然await方法还有待超时时间的 。。啊我懒得贴过来了      void await() throws InterruptedException;\n\n\n\n获取锁\n获取排他锁–acquire\n\n最直观的就是通过Lock.lock()获取，Lock 一般是 aqs 的子类，lock 方法底层也是根据情况来调用acquire或是tryAcquire。acquire这个方法aqs已经实现了，tryAcquire是交给子类去实现的，只要包含try的方法，都是交给子类去实现的，它在aqs中是直接抛了个异常。acquire方法先尝试用tryAcquire去获取锁，获取不到时，再去同步队列中等待锁。acquire也分为排他锁和共享锁。\n\nacquire运行流程是这样的，我先走一遍子类的tryAcquire，看看有米有实现咯，如果实现了，那就直接返回呗，否则线程就尝试进入同步队列，就会先调用addWaiter方法，也就是放进同步队列尾，然后外面包裹一层acquireQueued，其目的是阻塞节点，同时赋予节点被唤醒时，让它能够获得锁。如果上述操作也失败了，打断线程。\n\n```javapublic final void acquire(int arg) {  //tryAcquire是交给子类去实现的  if (!tryAcquire(arg) &amp;&amp;  //addWaiter代表是排他模式\n  acquireQueued(addWaiter(Node.EXCLUSIVE), arg))\nselfInterrupt();\n\n}//所以这个是排他的情况下去获取锁- **总的来说 acquire方法就是三步，我先tryAcquire，哦，失败了，我再把它封装成节点，具体是排他还是共享看传入的mode，然后我把它放到同步队列尾巴去，最后阻塞它，自旋，让同步队列中当的pre节点状态置为signal后，然后阻塞自己。**- 先看一下这个**addWaiter*8方法，也就是把它放到同步队列尾。入参mode，代表模式，排他，还是共享，首先就是去给同步队列新增一个节点，让队尾成为pre，前驱节点，这里也是cas。。。我先尝试放一下，成功立马返回，不成功，那就`enq`，通过**自旋**保证你这个node能加到队尾（这里不是马上自旋，大部分操作一次就能成功，自旋成本大）  - ```java    private Node addWaiter(Node mode) {        Node node = new Node(Thread.currentThread(), mode);        // Try the fast path of enq; backup to full enq on failure        Node pred = tail;        if (pred != null) {            node.prev = pred;            if (compareAndSetTail(pred, node)) {                pred.next = node;                return node;            }        }        enq(node);        return node;    }\n\n\n再看一下acquireQueued方法，用来阻塞节点（阻塞这个线程的），这个方法主要做了这么几件事，首先是通过不断自旋，尝试让自己的前一个节点的状态变为signal（就是前一个节点如果释放锁，就会通知它的下一个，也就是现在来的这个），然后阻塞自己。其次是它的前一个老兄执行完了，释放锁，会把这个node唤醒，node被唤醒会再次自旋。\n\n```java//返回false，表示获得锁了，true表示失败    final boolean acquireQueued(final Node node, int arg) {\n   boolean failed = true;\n   try {\n       boolean interrupted = false;\n       for (;;) {    //尝试自旋\n           final Node p = node.predecessor();\n           if (p == head &amp;&amp; tryAcquire(arg)) {\n               setHead(node);\n               p.next = null; // help GC\n               failed = false;\n               return interrupted;\n           }\n           if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;\n               parkAndCheckInterrupt())\n               interrupted = true;\n       }\n   } finally {\n       if (failed)\n           cancelAcquire(node);\n   }\n\n   }    - 这个方法的核心是shouldParkAfterFailedAcquire，主要目的就是把前一个节点的状态置为 SIGNAL，只要前一个节点的状态是 SIGNAL， 当前节点就可以阻塞了。- 获取共享锁--acquireShared  - 他的整体流程和acquire相同，代码也是相似的，只有一点小的区别，获取锁的时候，共享锁使用的是tryAcquireShared方法  - ```java    public final void acquireShared(int arg) {            if (tryAcquireShared(arg) &lt; 0)                doAcquireShared(arg);        }\n\n\n其次，节点获得排他锁时，是把它自己设置成同步队列头节点，但如果是共享锁的话，还会去唤醒自己后续的节点，一起来获得这把锁\n\n\n\n\n\n\n释放锁释放锁就是用Lock.unLock () 方法，释放锁也是分为两类，一类是排他锁的释放，另一类是共享锁的释放。\n\n排他锁的释放–release\n\n从队头开始，找它的下一个节点，如果下一个节点是空的，就会从 尾开始，一直找到状态不是取消的节点，然后释放该节点。\n\nrelease是unlock的基础方法，同样的，也是先tryRelease，先调用子类的，如果锁已经完全释放，返回true，那么就唤醒下一个节点。\n\n```javapublic final boolean release(int arg) {\n   if (tryRelease(arg)) {\n       Node h = head;\n         // 头节点不为空，并且非初始化状态\n       if (h != null &amp;&amp; h.waitStatus != 0)\n             // 从头开始唤醒等待锁的节点\n           unparkSuccessor(h);\n       return true;\n   }\n   return false;\n\n   }//当线程释放锁成功后，从 node 开始唤醒同步队列中的节点//通过唤醒机制,保证线程不会一直在同步队列中阻塞等待private void unparkSuccessor(Node node) {\n          //node节点是当前释放的节点，得到他的ws\n          //ws小于0，说明节点还没被取消，那就cas，重置它的状态\n    int ws = node.waitStatus;\n    if (ws &lt; 0)\n        compareAndSetWaitStatus(node, ws, 0);\n            //取出这个节点的下一个节点，如果是空的，或者ws&gt;0也就是被取消了\n          //遇到这种情况就从队尾开始向前遍历，找到第一个ws&lt;=0的，也就是没被取消的，为啥不是从头呢。。。我也找不到。。。\n    Node s = node.next;\n    if (s == null || s.waitStatus &gt; 0) {\n        s = null;\n        for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev)\n            if (t.waitStatus &lt;= 0)\n                s = t;\n    }\n    if (s != null)\n        LockSupport.unpark(s.thread);\n}\n\n- 共享锁的释放--releaseShared  - 他和排他锁的释放也是很相似的，首先tryReleaseShared尝试释放当前锁，然后唤醒当前节点的后续阻塞节点  - ```java    public final boolean releaseShared(int arg) {        if (tryReleaseShared(arg)) {            doReleaseShared();            return true;        }        return false;    }\n\n\n\n条件队列为啥有了同步队列要条件队列，因为不是所有场景都是可以用一个同步队列搞定的呀，如果遇到锁+队列的场景，就需要lock+condition的配合。先用lock来决定哪些线程能够获得锁，哪些线程要去同步队列中阻塞，但是有可能出现这种情况，同步队列容量&lt;获得锁的线程的个数，那么就有一部分线程获得了锁，但是进不了同步队列，那么可以用Condition来管理这些线程，让这些线程阻塞等待，在合适的时候唤醒他们。\n同步队列 + 条件队列联手使用的场景，最多被使用到锁 + 队列的场景中。\n\n入队列等待–await\n获得锁的线程，如果在碰到队列满或空的时候，就会阻塞住，这个阻塞就是用条件队列实现的， 这个动作我们叫做入条件队列，方法名称为 await\n\n\n\n先欠着，下次补\n","categories":["JAVA"],"tags":["Source Code"]},{"title":"ArrayList 源码解读","url":"/2019/09/10/SourceCode-ArrayList/","content":"ArrayListArrayList就是一个数组，源码中有几个重要概念\n\n\nindex：表示数组下标\nelementData：表示数组本身\nDEFAULT_CAPACITY：表示初始数组的大小，默认是10！！！（无参构造器初始化是0，10 是在第一次 add 的时候扩容的数组值。）\nsize：表示当前数组的大小，没有用volatile修饰，非线程安全\nmodCount：统计当前数组被修改的次数，数组结构有变动，就会+1\n\n\n一些重要注释\n\n\nArrayList允许put null值\nsize、isEmpty、get、set、add 等方法时间复杂度都是 O(1)\n是非线程安全的，多线程情况下，推荐使用线程安全类\n增强 for 循环，或者使用迭代器迭代过程中，如果数组大小被改变，会快速失败，抛出异常。\n\n\n1、 初始化有三种初始化办法:无参数直接初始化、指定大小初始化、指定初始数据初始化，源码如下:\n// 无参初始化，数组大小为空public ArrayList() &#123;    this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;&#125;// 指定初始数据来初始化public ArrayList(Collection&lt;? extends E&gt; c) &#123;  \t\t\t// elementData是保存数组的容器，默认为null        elementData = c.toArray();  \t\t\t// 如果初始集合c有值        if ((size = elementData.length) != 0) &#123;            // 如果集合元素不是Object类型，则转成Object类型            // c.toArray might (incorrectly) not return Object[] (see 6260652)            if (elementData.getClass() != Object[].class)                elementData = Arrays.copyOf(elementData, size, Object[].class);        &#125; else &#123;            // 如果初始集合c没值，则默认空数组            this.elementData = EMPTY_ELEMENTDATA;        &#125;    &#125;\n\n注意\n\nArrayList 无参构造器初始化时，默认大小是空数组，并不是10，10 是在第一次 add 的时候扩容的数组值。\n\n2、 新增与扩容新增就是往数组中添加元素，主要分为两步。\n\n\n首先看要不要扩容，如果需要就先扩容\n直接赋值\n\n新增源码如下\npublic boolean add(E e) &#123;    //确保数组大小是否足够，不够则直接扩容，size是当前数组的大小，+1就是增加后的大小    ensureCapacityInternal(size + 1);  // Increments modCount!!    //直接赋值，这是线程不安全的    elementData[size++] = e;    return true;&#125;\n\n扩容(ensureCapacityInternal)源码\n  private void ensureCapacityInternal(int minCapacity) &#123;    \t//确保容量足够      ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));  &#125;  private void ensureExplicitCapacity(int minCapacity) &#123;    \t// 记录数组被修改的次数      modCount++;      // 如果我们需要的最小容量 大于 当前数组的长度，那就需要扩容了      if (minCapacity - elementData.length &gt; 0)          grow(minCapacity);  &#125;//扩容，把现有数据拷贝到新的数组中  private void grow(int minCapacity) &#123;      int oldCapacity = elementData.length;   \t\t//新数组容量      int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1);    \t//如果扩容后的容量 &lt; 期望的容量，那就让期望容量成为新容量，因为至少需要这么多的      if (newCapacity - minCapacity &lt; 0)          newCapacity = minCapacity;          //如果扩容后的容量 &gt; jvm能分配的最大值，那么就用 Integer 的最大值，上界      if (newCapacity - MAX_ARRAY_SIZE &gt; 0)          newCapacity = hugeCapacity(minCapacity);          //通过复制进行扩容      elementData = Arrays.copyOf(elementData, newCapacity);  &#125;\n\n\n扩容成原来大小的1.5倍\nArrayList 中的数组的最大值是 Integer.MAX_VALUE，超过这个值，JVM 就不会给数组分配内存空间了。\n新增时，并没有对值进行严格的校验，所以 ArrayList 是允许 null 值的。\n\n扩容本质\n\n通过代码Arrays.copyOf(elementData, newCapacity);来实现扩容，就是数组的拷贝，新建一个符合预期容量的新数组，然后把老数据拷贝过去。Arrays.copyOf是通过System.arraycopy来实现的，这个方法是native方法，源码如下。\n\n3、 删除&emsp;&emsp;ArrayList 删除元素有很多种方式，比如根据数组索引删除、根据值删除或批量删除等等，原理和思路都差不多，这里选取根据值删除方式来进行源码说明：\npublic boolean remove(Object o) &#123;\t//如果要删除的是null，找到第一个为null的删除    if (o == null) &#123;        for (int index = 0; index &lt; size; index++)            if (elementData[index] == null) &#123;              \t//调用根据索引位置来删除                fastRemove(index);                return true;            &#125;    &#125; else &#123;      \t//如果要删除的值不为null，找到第一个和要删除的值相等的元素删除        for (int index = 0; index &lt; size; index++)          \t//！！注意！！这里是根据equals来判断值是否相等，然后根据索引位置来删除            if (o.equals(elementData[index])) &#123;                fastRemove(index);                return true;            &#125;    &#125;    return false;&#125;\n\n\n新增元素时可以增加null元素，所以删除时也是允许删除null元素的\n找到值在数组中的索引位置，通过equals来判断相不相等等。\n\n下面是fastRemove方法\nprivate void fastRemove(int index) &#123;  \t\t\t//记录修改次数        modCount++;  \t\t\t//numMoved表示删除index上的元素后，有多少个元素要移动到元素前面去（数据结构知识）        int numMoved = size - index - 1;        if (numMoved &gt; 0)          \t//把index后面的元素拷贝过去            System.arraycopy(elementData, index+1, elementData, index,numMoved);  \t\t\t\t\t//数组最后一个元素赋值null，帮助GC        \t\telementData[--size] = null; // clear to let GC do its work    &#125;\n\n4、 迭代器&emsp;&emsp;如果要自己实现迭代器，实现 java.util.Iterator 类就好了，ArrayList 也是这样做的，它里面的Itr实现了迭代器接口。迭代器有三个重要参数，如下：\nprivate class Itr implements Iterator&lt;E&gt; &#123;    int cursor;       // 迭代过程中下一个元素的位置，默认从0开始    int lastRet = -1; // add场景：表示上一次迭代过程中索引的位置，remove场景：-1    int expectedModCount = modCount;\t//迭代过程中期望的版本次数。\n\nArrayList迭代器的三个方法源码\nprivate class Itr implements Iterator&lt;E&gt; &#123;    int cursor;           int lastRet = -1;     int expectedModCount = modCount;    Itr() &#123;&#125;//有没有值可以迭代    public boolean hasNext() &#123;      \t//如果下一个元素位置和大小相等，说明已经迭代完了，不等则还可以继续迭代        return cursor != size;    &#125;    @SuppressWarnings(&quot;unchecked&quot;)    public E next() &#123;      \t//迭代过程中判断版本号有没有被修改，如果被修改了，抛出ConcurrentModificationException异常        checkForComodification();      \t//下一个元素位置        int i = cursor;        if (i &gt;= size)            throw new NoSuchElementException();        Object[] elementData = ArrayList.this.elementData;        if (i &gt;= elementData.length)            throw new ConcurrentModificationException();      \t//为下一次迭代做准备        cursor = i + 1;        //返回元素值        return (E) elementData[lastRet = i];    &#125;    public void remove() &#123;      \t//如果lastRet值为-1，说明数组已经被删完了        if (lastRet &lt; 0)            throw new IllegalStateException();      \t//迭代过程中判断版本号有没有被修改        checkForComodification();        try &#123;            ArrayList.this.remove(lastRet);            cursor = lastRet;          \t//-1表示元素已经被删除，写这一句是为了避免重复删除的操作            lastRet = -1;            //删除后modCount已经发生变化，要把它赋值给expectedModCount，下一次迭代两个值就一致了            expectedModCount = modCount;        &#125; catch (IndexOutOfBoundsException ex) &#123;            throw new ConcurrentModificationException();        &#125;    &#125;    //补上  final void checkForComodification() &#123;        if (modCount != expectedModCount)            throw new ConcurrentModificationException();  &#125;\n\n&emsp;&emsp;只有当 ArrayList 作为共享变量时，才会有线程安全问题，当 ArrayList 是方法内的局部变量时，是没有线程安全的问题的。ArrayList 有线程安全问题的本质，是因为 ArrayList 自身的 elementData、size、modConut 在进行各种操作时，都没有加锁，而且这些变量的类型是不可见(volatile)的，所以如果多个线程对这些变量进行操作时，可能会有值被覆盖的情况。\n&emsp;&emsp;类注释中推荐我们使用 Collections#synchronizedList 来保证线程安全，SynchronizedList 是通过在每个方法上面加上锁来实现，虽然实现了线程安全，但是性能大大降低。\n5、 面试问题（1）ArrayList 无参数构造器构造，现在 add 一个值进去，此时数组的大小是多少，下一次扩容前最大可用大小是多少?\n\n答:此处数组的实际大小是 1，但下一次扩容前最大可用大小是 10，因为 ArrayList 第一次扩容时， 是有默认值的，默认值是 10，在第一次 add 一个值进去时，数组的可用大小被扩容到 10 了。\n\n（2） 如果我连续往 list 里面新增值，增加到第 11 个的时候，数组的大小是多少?\n\n答:这里的考查点就是扩容的公式，当增加到 11 的时候，此时我们希望数组的大小为 11，但 实际上数组的最大容量只有 10，不够了就需要扩容，扩容的公式是:oldCapacity + (oldCapacity&gt;&gt; 1)，oldCapacity 表示数组现有大小，目前场景计算公式是:10 + 10 /2 = 15，然后我们发现 15 已经够用了，所以数组的大小会被扩容到 15。\n\n（3）数组初始化，被加入一个值后，如果我使用 addAll 方法，再一下子加入 15 个值，那么最终数组的大小是多少?\n\n答:第一题中我们已经计算出来数组在加入一个值后，实际大小是 1，最大可用大小是 10 ，现在需要一下子加入 15 个值，那我们期望数组的大小值就是 16，此时数组最大可用大小只有 10，明显不够，需要扩容，扩容后的大小是:10 + 10 /2 = 15，这时候发现扩容后的大小仍 然不到我们期望的值 16，这时候源码中有一种策略如下:\n// 如果扩容后的值 &lt; 我们的期望值，我们的期望值就等于本次扩容的大小 if (newCapacity - minCapacity &lt; 0)\t\tnewCapacity = minCapacity;\n\n所以最终数组扩容后的大小为 16。\n\n（4）现在我有一个很大的数组需要拷贝，原数组大小是 5k，请问如何快速拷贝?\n\n答:因为原数组比较大，如果新建新数组的时候，不指定数组大小的话，就会频繁扩容，频繁扩容就会有大量拷贝的工作，造成拷贝的性能低下，所以说新建数组时，指定新数组的大小为 5k 即可。\n\n（5）有一个 ArrayList，数据是 2、3、3、3、4，中间有三个 3，现在我通过 for 循环的方式想把3删除，可以删除干净吗？最终结果是什么？为什么\n\n答:不能删除干净，最终删除的结果是 2、3、4，有一个 3 删除不掉，原因我们看下图\n\n每次删除一个元素后，该元素后面的元素就会往前移动，而此时循环的 i 在不断地增长，最终会使每次删除 3 的后一个 3 被遗漏，导致删除不掉。\n\n（6）还是上面的 ArrayList 数组，我们通过增强 for 循环进行删除，可以么?\n\n答:不可以，会报错。因为增强 for 循环调用的就是迭代器的 next () 方法，当你调用 remove () 方法进行删除时，modCount 的值会 +1，而这时候迭代器中的 expectedModCount 的值却没有变，导致在迭代器下次执行 next () 方法时， expectedModCount != modCount 就会报 ConcurrentModificationException 的错误。\n\n（7）还是上面的数组，如果删除时使用list. Iterator 然后remove () 可以删除么，为什么?\n\n答：可以的，因为 Iterator.remove () 方法在执行的过程中，会把最新的 modCount 赋值给 expectedModCount，这样在下次循环过程中，modCount 和 expectedModCount 两者就会相等。\n\npublic static void main(String[] args) &#123;    ArrayList&lt;Integer&gt; list = new ArrayList&lt;&gt;();    list.add(1);    list.add(2);    list.add(3);    list.add(3);    list.add(3);    list.add(4);    // for (int i = 0; i &lt; list.size(); i++) &#123;    //     if (list.get(i) == 3) &#123;    //         list.remove(i);    //     &#125;    // &#125;  \t//增强型for循环调用的是迭代器的next，list.remove然后会调用fastRemove    //前面是迭代器的版本号，后面是list里面持有的版本号，list调用remove，版本号+1    //但是前面迭代器的版本号是没变的。    // for (Integer i : list) &#123;    //     if (i == 3) &#123;    //         list.remove(i);    //     &#125;    // &#125;    Iterator&lt;Integer&gt; it = list.iterator();    while (it.hasNext()) &#123;        Integer next = it.next();        if (next == 3) &#123;            it.remove();\t//迭代器的remove，而不是list的        &#125;    &#125;   //主要就是看这个迭代器是不是list自己的    System.out.println(list);&#125;\n\n","categories":["JAVA"],"tags":["Source Code"]},{"title":"J.U.C Collections 源码解读","url":"/2019/09/20/SourceCode-Collections/","content":"JUC.Collectionsjuc集合类，主要是cow（包括数组、set），然后是concurrenthashmap，然后queue占个大头，四个queue，都是非常重要的！\nCOW\n底层是一个数组，用transient和volatile修饰，表示可见的，对数组的修改有四个步骤\n1、加锁，保证只有一个线程对他操作\n2、拷贝数组\n3、操作\n4、解锁\n\n\n既然加锁了，为什么还要拷贝？因为拷贝保证了数组内部地址被修改了，这样才能触发volatile的可见性，直接在数组上修改值，没办法触发可见性，要修改内存地址。\n细说一下，单核cpu不拷贝肯定没问题，但是多核cpu。。必须要通过拷贝修改值，才能触发可见性，否则通知不了其他线程。\n\n\n插入细节是，先把元素填到位置上，再判断是不是最后一个，如果是最后一个，只需要把前面的拷贝过来即可，一次拷贝，否则，就是拷贝两次。\n删除元素的时候，如果是删除单个，就是上锁、在try中删除，和插入一样，如果删除的是最后一个，直接删除，如果不是，也是拷贝两次。这个加的锁被final修饰，保证加锁过程中，锁的内存地址不被改。如果是批量删除，并不是对要删除的元素判断一下是不是，然后再删，这样成本很大，我们是把不删除的挑出来放在数组中。\ncow的迭代，即使数组中原始值发生改变，也不会fast fail，因为，数组的每次变动，都不是在原数组上进行操作，而是使用新数组，不会影响老数组，迭代持有的是老数组的引用，而 CopyOnWriteArrayList 每次的数据变动，都会产生新的数组， 对老数组的值不会产生影响。\n\nConcurrentHashMap\n所有操作都是线程安全的，put、get、remove都能同时进行，不会阻塞，迭代过程中，即使map的结构发生改变，也不会抛出异常，map是数组+链表+红黑树，ConcurrentHashMap在这个基础上加了个转移节点，来保证扩容时线程安全。\nConcurrentHashMap和map的区别是，ConcurrentHashMap中的红黑树，TreeNode仅仅是维护属性和查找的功能，这里面加了个TreeBin来维护红黑树的结构，主要负责root的加锁、解锁。同时，ConcurrentHashMap中加了个转移节点，如果转移节点有值，表示正在扩容，那么put操作就要等待，等扩容完才能继续放，那么加入了这个转移节点，就是为了维护线程的安全\nput的步骤\n1、来了一个key value，先判断是不是null的，是null，直接抛出异常。\n2、不是null，那就继续，如果table是空的，先要初始化，然后先得到key的hash，找到它在哪个槽中，然后进入自旋死循环。\n3、进入自旋死循环后，如果这个位置上没有任何键值对，那就初始化，通过cas来创建，结束自旋，如果这个位置上有值了，我先看看当前索引位置是不是转移节点，如果是转移节点，表示正在扩容，继续自旋，等扩容完再操作，如果不是转移节点，我先把这个位置锁住，被我一个线程独占，然后，判断是链表结构还是红黑树结构，链表结构的新增就和map里的新增是一样的，遍历链表，碰到一样的值直接break，否则就插到尾部，退出自旋，红黑树的新增就和map的不一样了，它没有使用treenode，而是使用了TreeBin，TreeBin持有红黑树的引用，会对红黑树的根节点加锁，保证这棵树现在只有一个线程能旋转，保证线程的安全。在链表和红黑树的新增都会改变bitCount，链表新增会把bitCount改成1，红黑树会改成2，最后会判断一下bitCount是否为0，不为0就说明新增成功了，还要判断下要不要树化。最后一步就是检查要不要扩容。\n\n\nCHM保证线程安全的三个方面！\n第一个是刚进来，table还没初始化的时候。它先通过自旋来保证初始化一定成功。初始化的时候里面有个sizeCtl，也就是size的偏移量，初始尾0，如果小于0，说明有线程正在初始化，其他线程你放开时间片吧，yield一下，如果大于0，就说明已经初始化好了。sizectl的值也是通过cas来设置的，这样保证了同一时刻只有一个线程在设置这个值，。cas完后，还会再 double check一下，所以 初始化的时候它是通过 自旋+cas+double check来保证线程安全的。\n第二个是新增槽点的时候是这样的。它先看槽是不是空的，如果是空的，就通过cas新增（不能直接赋值，可能期间被人插队了，一定要通过cas）。如果槽点不是空的，它先会锁住槽点，再操作，如果是链表，就链表新增，如果是红黑树，就红黑树新增，红黑树新增也会通过TreeBin锁住根，保证这棵树现在只有一个线程能旋转。\n第三个是扩容时的时候。它的扩容时机和map是一样的，都是在put完的时候扩容，但是扩容过程有区别，map直接在老数组上扩容，而CHM通过addCount来扩容，里面有一个transfer方法，他就是主要的扩容方法。它要把老数组中的节点都拷贝到新的数组中去，拷贝的时候，先把原数组中的槽点锁住，这样原数组中的值就不能被操作了，然后这个槽拷贝完，它就成为了转移节点，继续扩容下一个。它是从链表尾部拷贝到头部的，每拷贝成功一次，这个节点就变为转移节点，直到全部拷贝完，那么就是得到新的容器。\n\n\nget操作\n整体思路和hashmap的思路就是很想的，先对得到key的hashcode，然后计算它在数组中的下标，得到在哪个槽中，然后去这个槽的节点开始遍历，如果是链表就链表方式找，否则就是红黑树的方式找，红黑树还是根据hashcode找吧，左小右大。\n\n\n\nLinkedBlockingQueue\n它是基于链表实现的阻塞队列，单向链表结构，范围是任意的，不指定容量，默认就是Integer.MAX_VALUE。新来的元素放在队列尾，拿从队头拿。他实现了Collection接口和Iterator接口，可以用它们的所有操作。\n内部结构就是链表+锁+迭代器，锁设计了两把，分别为take时的锁和put时的锁，方便两个操作同时进行。链表的节点可以是任意东西，比如用于线程池，节点就是线程，被用到消息队列，节点就是消息。\n初始化，可以指定容量，不指定就是最大值。\n关键是新增节点操作，它有三种操作，add、offer、put，啥区别呢，用add，如果阻塞队列满了，抛出异常，用offer 如果满了时返回false，用put，这个代表如果满了就一直阻塞，直到队列有容量了，并且被唤醒时，才会去执行。放的过程是这样的，先拿到putlock，设置可中断锁，锁设置好了进入下一步，链表满了则阻塞，否则追加到链表尾部，新增成功，唤醒一个put的等待线程，下一个继续put吧，putlock释放锁，然后告诉拿的take线程，我仓库又有东西了，你来拿吧。\n阻塞删除，和新增远离一样，上锁，操作，如果队列是空的，那就阻塞，直到有put线程唤醒take线程，说我有东西了你可以来拿了，最后释放锁\n\nSynchronousQueue\n这玩意也是阻塞队列，但是只能放一个元素，队列也没容量，put操作放元素进去了，不能马上返回，必须等它的东西被别人消费了才能走，反过来也是一样的。SynchronousQueue内部有两种实现，队列堆栈。队列先进先出的，所以是公平的，堆栈是先进后出的，是非公平的。\n初始化：这个SynchronousQueue阻塞队列初始化的时候，由于有两种实现方式，队列和堆栈，如果你不选择额，默认是 非公平的。\n非公平堆栈：放的时候放栈顶，拿的时候也是从栈顶拿，所以是不公平的。SynchronousQueue的transfer是核心方法，它把put和take两个操作糅合在一起了，因为1它只有一个元素且要满足那个要求，所以只能柔和再一起搞。过程大概是这样子的：判断你这个操作是put还收take，然后判断栈空不空，判断你的操作和栈的容量是否符合，比如你拿操作，但是栈是空的肯定不符合。然后下一步就是把当前操作设置在栈头，肯定对栈头操作呀，看看其他线程能不能满足自己，不能则阻塞，比如我一个put线程，放了元素，我要等别人来拿，如果来了个put的线程，不对，阻塞一会，来了个take线程，没错兄弟就是你。如果发现再阻塞自己之前，栈头已经阻塞了，看看能不能唤醒栈头。。能唤醒栈头，则把自己作为一个节点，赋值到栈头的 match 属性上，并唤醒栈头节点。\n公平队列：啥是公平的呢？公平是说，我每次put都put队尾，但是我拿，绝对不是从队头开始拿，而是找到第一个被阻塞住的线程，要按照顺序释放阻塞住的线程。比如现在队列是空的，我要往队列中去拿数据，没有数据，被阻塞住了，接下来来了个put线程，它会找到第一个被阻塞住的兄弟，然后把数据放到阻塞节点的item属性里面，然后唤醒它，被阻塞的兄弟被唤醒后，能够从它的item属性中拿到数据，开心的走了。。\n\nDelayQueue\n这是个无界的阻塞队列，只有延迟期满了才能拿，（比如设置延迟5秒后才能拿，那么线程就是沉睡5秒，然后再被唤醒）。该队列的头部是延迟期满后保存时间最长的 Delayed 元素。如果延迟都还没有期满，则队列没有头部。这玩意还用了很多优先队列的东西，可以根据过期时间排序，比如让先过期的先执行\n\nArrayBlockingQueue\n看名字就知道底层是数组了，队头就是数组头，队尾就是数组尾。它肯定是有界的，并且一旦创建，不能被修改容量，数组是也有序的，这都是数组的性质，对于take和put，它提供了takeIndex和putIndex。\n初始化，初始化的时候可以指定容量，也可以指定是否为公平、还是非公平的。如果是公平的，那就是顺序插入。。如果非公平，就随意插入了\n增加一个数据，新增，也就是put，会有一个putIndex，put的时候也是先上锁，看看队列满不满，满了，阻塞，直到自己被唤醒，没满就可以放，那要咋放呢？如果放在队列（也就是数组）中间，那就直接插入，插入之后，putIndex+1，比如我现在放在5的位置，下一个位置就是放6，另一个，如果现在放在队尾了，下一个位置就要从对头开始了！\n删除数据，也是先上锁，操作解锁，关键是中间这个操作，如果takeIndex和removeIndex相等，也就是我下次要拿的位置和你要删除的位置是一样的，那就直接吧这个要删除的位置设置为null，你takeIndex往后移，拿下一个吧，这个位置被我删了。还有一种情况，removeIndex != putIndex，我要删除的元素在我putIndex之前的之前，那么我删除元素之后，putIndex就要往前移动～，如果removeIndex +1 == putIndex，那就直接覆盖rmindex的值就可以了。。。自己画画图。\n\n下次再补\n","categories":["JAVA"],"tags":["Source Code"]},{"title":"FutureTask 源码解读","url":"/2019/09/19/SourceCode-FutureTask/","content":"FutureTaskJUC.Executor这个包里主要是Future接口、callable接口、executor接口、四个拒绝策略，TimeUnit，这里着重看一下这个Future接口，它有两个子类，RunnableFuture接口和ScheduleFuture接口。。下面再看吧，，Futuretask用的很多。然后再看一下Executor，因为ThreadPollExecutor也用的很多啊。\n\nFuture，有俩儿子，RunnableFuture接口和ScheduleFuture接口，RunnableFuture接口继承了Future和Runnable。我写了个demo\n\n``` javapublic static void main(String[] args) throws ExecutionException, InterruptedException {\n    //创建一个线程池\n    ThreadPoolExecutor executor = new ThreadPoolExecutor(3, 3, 0L,\n            TimeUnit.MILLISECONDS, new LinkedBlockingDeque&lt;&gt;());\n    //创建一个线程任务\n    FutureTask futureTask = new FutureTask&lt;&gt;(new Callable&lt;String&gt;() &#123;\n        @Override\n        public String call() throws Exception &#123;\n            Thread.sleep(3000);\n            return &quot;刘嘉警告：你数据库作业还没做&quot; + Thread.currentThread().getName();\n        &#125;\n    &#125;);\n    //执行任务\n    executor.submit(futureTask);\n    //得到任务的执行结果\n    String res = (String) futureTask.get();\n    System.out.println(res);\n&#125;\n\n- 从这个demo中 可以看出，callble是帮我们做事情的，future是一个线程任务，然后通过从线程池提交线程任务，可以通过futuretask来得到任务执行的结果，这就非常好，线程实现的两种方式 实现runnable接口和继承thread，都无法告知我们具体执行结果，但是我们可以通过futuretask得到执行的结果～～。- callable，他就是一个接口，在它的call方法中，定义了这个线程要做的各种事情，callable的返回值就写在callabl&lt;&gt;这里面，用callable都是和Future结合起来一起用的啦- Futuretask，他实现了RunnableFuture接口，他就是一个线程任务。自己看源码。。本身就是Runnable，然后又实现了Future，也就是说 FutureTask 具备对任务进行管 理的功能- RunnableFuture接口，继承了Runnable接口和Future接口。里面有个run方法，其目的是让Future能够管理Runnable，咋管理呢，就是可以取消Runnable，也可以查看你有没有完成了，有没有Done- Future接口。Callable接口就是得到子线程的运行结果，然后返回，那我们怎么get到callable返回的结果呢，就是通过future啦。当然future还能取消。。。如果完成了就不能取消了，它里面有这些方法- ``` java  //取消  boolean cancel(boolean mayInterruptIfRunning);     //判断有没有被取消  boolean isCancelled();     //干完了没  boolean isDone();     //得到结果，如果任务被取消了，抛前面的u一场，如果任务被打断了，抛出后面异常  V get() throws InterruptedException, ExecutionException;     V get(long timeout, TimeUnit unit)  \t\tthrows InterruptedException, ExecutionException, TimeoutException;\n\n\n\nFutureTask的初始化，它有两种方式初始化的，一种是传callable，不能传null，一种是传runnable，但是runnable是没有返回值的呀，所以他就要求你传个result，作为返回结果！但是这个返回结果没卵用，传个null即可。传参为runnable的构造器，会通过Executors.callable方法来把你这个runnable转成callable。但是runnable和callable都是接口，咋转化，适配器模式，它就搞了个RunnableAdapter 。。。\n\n\nFuture get操作源码：代码太长了自己看，首先会得到state，也就是状态，判断一下状态时啥，如果任务正在执行，那就要阻塞呗，底层用的是LockSupport.park，直接让线程进入waiting状态了，直到执行成功，返回结果。等待过程的源码太长了。。\n\nrun方法源码：这个方法没返回值的，你创建了futuretask这个任务，是可以直接run的，也可以开启新线程去跑，run的时候先判断当前任务有人有人在执行，如果有人在执行就直接返回了，run的过程中，会给outcome属性（看上上张图）赋值，赋值之后，get的时候就能从属性中拿结果了。\n\n取消。。没什么说的\n\n\n","categories":["JAVA"],"tags":["Source Code"]},{"title":"CopyOnWriteArrayList 源码解读","url":"/2019/09/19/SourceCode-CopyOnWriteArrayList/","content":"CopyOnWriteArrayList并发容器，是一种线程安全的list，它具有以下特征：\n\n线程安全的，多线程环境下可以直接使用，无需加锁\n\n通过锁 + 数组拷贝 + volatile 关键字保证了线程安全\n\n每次数组操作，都会把数组拷贝一份出来，在新数组上进行操作，操作成功之后再赋值回去 cas\n\n\n一、整体结构整体架构和ArrayList一致，底层是个数组，这个数组是被volatile修饰的，保证了可见性，一旦数组被修改，其他线程能立马感知到。数组虽然有拷贝的成本，但是比其他线程安全的代替方案效率更高（注释上这么说的）。并且在迭代过程中，也不会影响到原来的数组，不会抛出ConcurrentModificationException异常。\nprivate transient volatile Object[] array;\n\ntransient关键字是来防止对象被序列化：https://www.cnblogs.com/lanxuezaipiao/p/3369962.html\n在操作它时，大概有四步：\n\n加锁（保证同一时刻数组只有一个线程在操作数组）\n拷贝原数组，长度+1（拷贝是为了保证数组内存地址被修改，才能触发volatile的可见性）\n在新数组上进行操作，并把新数组赋值给数组容器\n解锁\n\n二、新增新增有很多种情况，比如说:新增到数组尾部、新增到数组某一个索引位置、批量新增等等\n// 添加元素到尾部public boolean add(E e) &#123;    final ReentrantLock lock = this.lock;  \t//加锁    lock.lock();    try &#123;      \t//获取原数组        Object[] elements = getArray();        int len = elements.length;      \t//拷贝        Object[] newElements = Arrays.copyOf(elements, len + 1);      \t//对最后一个位置赋值        newElements[len] = e;      \t//替换原数组        setArray(newElements);        return true;    &#125; finally &#123;      \t//解锁，保证即使 try 发生了异常，仍然能够释放锁        lock.unlock();    &#125;&#125;\n\n有一个问题是，既然都加锁了，为什么还需要创建新数组，再赋值，再替换呢，不能能直接在原数组上操作吗？原因是：\n\nvolatile 关键字修饰的是数组，简单的在原来数组上修改某几个元素的值，是无无法触发可见性的，必须通过改数组内存的地址，才能触发可见性，也就是说要对数组重新赋值。\n\n下面是在指定位置添加元素的源码：\n  // len:数组的长度、index:插入的位置public void add(int index, E element) &#123;      final ReentrantLock lock = this.lock;      lock.lock();      try &#123;          Object[] elements = getArray();          int len = elements.length;          if (index &gt; len || index &lt; 0)              throw new IndexOutOfBoundsException(&quot;Index: &quot;+index+                                                  &quot;, Size: &quot;+len);          Object[] newElements;          int numMoved = len - index;        \t// 如果要插入的位置正好等于数组的末尾，直接拷贝数组即可          if (numMoved == 0)              newElements = Arrays.copyOf(elements, len + 1);        \t// 如果要插入的位置在数组的中间，就需要拷贝 2 次        \t// 第一次从 0 拷贝到 index。        \t// 第二次从 index+1 拷贝到末尾。          else &#123;              newElements = new Object[len + 1];              System.arraycopy(elements, 0, newElements, 0, index);              System.arraycopy(elements, index, newElements, index + 1,                               numMoved);          &#125;          newElements[index] = element;          setArray(newElements);      &#125; finally &#123;          lock.unlock();      &#125;  &#125;\n\n从源码中可以看到，当插入的位置正好处于末尾时，只需要拷贝一次，当插入的位置处于中间时，此时我们会把原数组一分为二，进行两次拷贝操作。\nadd系列方法，加锁，拷贝（改变内存地址触发volatile可见性）\n三、删除根据index来删除\n  // 删除某个索引位置的数据public E remove(int index) &#123;      final ReentrantLock lock = this.lock;    \t// 加锁      lock.lock();      try &#123;        \t// 获取原数组及其长度          Object[] elements = getArray();          int len = elements.length;        \t// 要删除的值          E oldValue = get(elements, index);          int numMoved = len - index - 1;        \t// 如果要删除的数据正好是数组的尾部，直接删除          if (numMoved == 0)              setArray(Arrays.copyOf(elements, len - 1));        \t// 如果删除的数据在数组的中间，分三步走        \t// 1. 设置新数组的长度减一        \t// 2. 从 0 拷贝到数组新位置        \t// 3. 从新位置拷贝到数组尾部          else &#123;              Object[] newElements = new Object[len - 1];              System.arraycopy(elements, 0, newElements, 0, index);              System.arraycopy(elements, index + 1, newElements, index,                               numMoved);              setArray(newElements);          &#125;          return oldValue;      &#125; finally &#123;          lock.unlock();      &#125;  &#125;\n\n锁 + try finally +数组拷贝，锁被 final 修饰的，保证了在加锁过程中，锁的内存地址肯定不会被改，finally 保证锁一定能够被释放\n批量删除源码\n  // 批量删除包含在 c 中的元素public boolean retainAll(Collection&lt;?&gt; c) &#123;      if (c == null) throw new NullPointerException();      final ReentrantLock lock = this.lock;      lock.lock();      try &#123;          Object[] elements = getArray();          int len = elements.length;        \t// 说明数组有值，数组无值直接返回 false          if (len != 0) &#123;            \t// newlen 表示新数组的索引位置，新数组中存在不包含在 c 中的元素              int newlen = 0;              Object[] temp = new Object[len];            \t// 循环，把不包含在 c 里面的元素，放到新数组中              for (int i = 0; i &lt; len; ++i) &#123;                  Object element = elements[i];                  if (c.contains(element))                      temp[newlen++] = element;              &#125;            \t// 拷贝新数组，变相的删除了不包含在 c 中的元素              if (newlen != len) &#123;                  setArray(Arrays.copyOf(temp, newlen));                  return true;              &#125;          &#125;          return false;      &#125; finally &#123;          lock.unlock();      &#125;  &#125;\n\n我们并不会直接对数组中的元素进行挨个删除，而是先对数组中的值进行判断，把不需要删除的数据放到临时数组中，最后拷贝临时数组中的数据即可。ArrayList的批量删除也是这个思想，如果要删除多个元素，不要单个单个删除，单个删除每次都会进行一次拷贝，有性能损耗。（详细看11、集合源码、集合性能。）\n四、查找indexOf，查找元素在数组中的下标位置，如果元素存在就返回元素的下标位 置，元素不存在的话返回 -1，不但支持 null 值的搜索，还支持正向和反向的查找，以正向查找为例\n  // o:我们需要搜索的元素,elements:搜索的目标数组,index:搜索的开始位置,fence:搜索的结束位置private static int indexOf(Object o, Object[] elements, int index, int fence) &#123;    \t// 支持对 null 的搜索      if (o == null) &#123;          for (int i = index; i &lt; fence; i++)            \t// 找到第一个 null 值，返回下标索引的位置              if (elements[i] == null)                  return i;      &#125; else &#123;          for (int i = index; i &lt; fence; i++)            \t// 通过 equals 方法来判断元素是否相等            \t// 如果相等，返回元素的下标位置              if (o.equals(elements[i]))                  return i;      &#125;      return -1;  &#125;\n\n五、迭代在 CopyOnWriteArrayList 类注释中，明确说明了，在其迭代过程中，即使数组的原值被改变，也不会抛出 ConcurrentModificationException 异常，其根源在于数组的每次变动，都不是在原数组上进行操作，而是使用新数组，不会影响老数组（然后再拷贝，使得内存地址发生改变，触发了volatile可见性）这样的话，迭代过程中，根本就不会发生迭代数组的变动（因为老数组）没动。\n迭代持有的是老数组的引用，而 CopyOnWriteArrayList 每次的数据变动，都会产生新的数组， 对老数组的值不会产生影响。\n","categories":["JAVA"],"tags":["Source Code"]},{"title":"LinkedHashMap 源码解读","url":"/2019/09/13/SourceCode-LinkedHashMap/","content":"LinkedHashMapHashMap 是无序的，TreeMap 可以按照 key 进行排序，LinkedHashMap是可以维护插入顺序的，它本身继承HashMap，拥有HashMap的所有特性。除了可以维护插入顺序以外，实现了访问最少最先删除功能，其目的是把很久都没有访问的 key 自动删除。\n一、LinkedHashMap的新增属性//链表头与尾巴transient LinkedHashMap.Entry&lt;K,V&gt; head;transient LinkedHashMap.Entry&lt;K,V&gt; tail;    /**     * HashMap.Node subclass for normal LinkedHashMap entries.     * 继承了Node，为数组的每个元素添加了before与after属性     */    static class Entry&lt;K,V&gt; extends HashMap.Node&lt;K,V&gt; &#123;        Entry&lt;K,V&gt; before, after;        Entry(int hash, K key, V value, Node&lt;K,V&gt; next) &#123;            super(hash, key, value, next);        &#125;    &#125;//控制两种访问模式的字段//true是按照访问顺序，会把经常访问的key放到队尾//false 按照插入顺序提供访问（初始化时是false）final boolean accessOrder;\n\nLinkedHashMap 的数据结构很像是把 LinkedList 的每个元素换成了 HashMap 的 Node，像是两者的结合体，也正是因为增加了这些结构，从而能把 Map 的元素都串联起来，形成一个链表，而链表就可以保证顺序了，就可以维护元素插入进来 的顺序。\n二、如何按照顺序新增初始化时，默认 accessOrder 为 false，就是会按照插入顺序提供访问，插入方法使用的是父类HashMap 的 put 方法，不过覆盖了 put 方法执行中调用的 newNode/newTreeNode 和 afterNodeAccess 方。\nnewNode/newTreeNode 方法，控制新增节点追加到链表的尾部，这样每次新节点都追加到尾部，即可保证插入顺序了，要注意的是节点具有before与after属性，以 newNode 源码为例\nNode&lt;K,V&gt; newNode(int hash, K key, V value, Node&lt;K,V&gt; e) &#123;    LinkedHashMap.Entry&lt;K,V&gt; p =      \t//new一个新的节点出来        new LinkedHashMap.Entry&lt;K,V&gt;(hash, key, value, e);  \t//追加到链表的尾部    linkNodeLast(p);    return p;&#125;// link at the end of list p是新增节点private void linkNodeLast(LinkedHashMap.Entry&lt;K,V&gt; p) &#123;    LinkedHashMap.Entry&lt;K,V&gt; last = tail;  \t//让新增加点=尾节点    tail = p;  \t///如果尾节点是空的，说明链表是空的，首尾节点一样，否则就让它变成尾节点    if (last == null)        head = p;    else &#123;        p.before = last;        last.after = p;    &#125;&#125;\n\n三、如何按照顺序访问LinkedHashMap 只提供了单向访问，即按照插入的顺序从头到尾进行访问，不能像 LinkedList 那样可以双向访问。主要通过迭代器进行访问，迭代器初始化的时候，默认从头节点开始访问，在迭代的过程中，不断访问当前节点的 after 节点即可。\nMap 对 key、value 和 entity(节点) 都提供出了迭代的方法，假设我们需要迭代 entity，就可使 用 LinkedHashMap.entrySet().iterator()\nabstract class LinkedHashIterator &#123;      LinkedHashMap.Entry&lt;K,V&gt; next;      LinkedHashMap.Entry&lt;K,V&gt; current;      int expectedModCount;\t\t//初始化，默认从头节点开始访问      LinkedHashIterator() &#123;        \t//头节点作为第一个节点          next = head;          expectedModCount = modCount;          current = null;      &#125;      public final boolean hasNext() &#123;          return next != null;      &#125;    \t//nextNode      final LinkedHashMap.Entry&lt;K,V&gt; nextNode() &#123;          LinkedHashMap.Entry&lt;K,V&gt; e = next;        \t//校验版本号          if (modCount != expectedModCount)              throw new ConcurrentModificationException();        \t//如果下一个节点为空，抛出异常          if (e == null)              throw new NoSuchElementException();        \t//准备下一个节点          current = e;          next = e.after;          return e;      &#125;  &#125;\n\n四、LRU算法LinkedHashMap实现了访问最少最先删除功能，其目的是把很久都没有访问的 key 自动删除。这种策略叫做LRU（Least recently used，最近最少使用），其实现思路是，把经常访问的元素追到到队尾，这样不经常访问的就靠近了队头，我们可以设置删除的策略，比如map元素大于多少个时，就把头节点删除。\n  //这是removeEldestEntry方法protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) &#123;      return false;  &#125;\n\n我们可以自定义实现\n//构造方法，初始化容量，负载因子，是否按照插入顺序访问，true则是实现lru算法，false则按照插入顺序访问\t\tpublic static void main(String[] args) &#123;        LinkedHashMap&lt;Integer, Integer&gt; map = new LinkedHashMap&lt;Integer, Integer&gt;(4, 0.75f, true) &#123;            &#123;                put(10, 10);                put(9, 9);                put(20, 20);                put(1, 1);            &#125;            //重写removeEldestEntry            @Override            protected boolean removeEldestEntry(Map.Entry&lt;Integer, Integer&gt; eldest) &#123;                //我们设定当节点个数大于 3 时，就开始删除头节点                return size() &gt; 3;            &#125;        &#125;;        Iterator&lt;Map.Entry&lt;Integer, Integer&gt;&gt; it = map.entrySet().iterator();        while (it.hasNext()) &#123;            Map.Entry&lt;Integer, Integer&gt; next = it.next();            System.out.println(next.getKey() + &quot;:&quot; + next.getValue());        &#125;        //调用map.get(9),9就被放到了链表尾        Integer integer = map.get(9);        Iterator&lt;Map.Entry&lt;Integer, Integer&gt;&gt; it2 = map.entrySet().iterator();        while (it2.hasNext()) &#123;            Map.Entry&lt;Integer, Integer&gt; next = it2.next();            System.out.println(next.getKey() + &quot;:&quot; + next.getValue());        &#125;    &#125;初始化结果，只有三个了9:920:201:1  调用map.get(9),9就被放到了链表尾20:201:19:9\n\n我们放进去四个元素，但结果只有三个元素，10 不见了，这 个主要是因为我们覆写了 removeEldestEntry 方法，我们实现了如果 map 中元素个数大于 3 时，我们就把队头的元素删除，当 put(1, 1) 执行的时候，正好把队头的 10 删除。\n为什么调用get，元素会被移动到队尾，看下源码\npublic V get(Object key) &#123;      Node&lt;K,V&gt; e;      if ((e = getNode(hash(key), key)) == null)          return null;    \t//如果为true，也就是启用LRU策略      if (accessOrder)        \t//就把这个key移动到队尾          afterNodeAccess(e);      return e.value;  &#125;void afterNodeAccess(Node&lt;K,V&gt; e) &#123; // move node to last      LinkedHashMap.Entry&lt;K,V&gt; last;      if (accessOrder &amp;&amp; (last = tail) != e) &#123;          LinkedHashMap.Entry&lt;K,V&gt; p =              (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after;          p.after = null;          if (b == null)              head = a;          else              b.after = a;          if (a != null)              a.before = b;          else              last = b;          if (last == null)              head = p;          else &#123;              p.before = last;              last.after = p;          &#125;          tail = p;          ++modCount;      &#125;  &#125;\n\n五、删除策略我们选择使用LRU算法，在9.4中去执行put时，发现队头的元素被删除了，由于LinkedHashMap调用的是HashMap的put方法，它自己是没有put的，队头能够删除是因为LinkedHashMap实现了put方法中的 afterNodeInsertion 这个方法，通过自己的afterNodeInsertion来实现删除，源码如下：\n// 删除很少被访问的元素，被 HashMap 的 put 方法所调用void afterNodeInsertion(boolean evict) &#123; // possibly remove eldest  \t\t\t// 得到元素头节点        LinkedHashMap.Entry&lt;K,V&gt; first;  \t\t\t//如果链表不为空，且用removeEldestEntry来控制删除策略        if (evict &amp;&amp; (first = head) != null &amp;&amp; removeEldestEntry(first)) &#123;            K key = first.key;          \t//删除头节点            removeNode(hash(key), key, null, false, true);        &#125;    &#125;\n\n","categories":["JAVA"],"tags":["Source Code"]},{"title":"LinkedList 源码解读","url":"/2019/09/11/SourceCode-LinkedList/","content":"LinkedList&emsp;&emsp;底层数据结构是双向链表，如图。链表中没数据时，first和last是同一个结点，前后指向null。因为是个双向链表，只要机器内存足够大，没有大小限制。\n内部有一个Node类\nprivate static class Node&lt;E&gt; &#123;        E item;\t\t//节点值        Node&lt;E&gt; next;\t\t//指向后继        Node&lt;E&gt; prev;\t\t//指向前驱        Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123;            this.item = element;            this.next = next;            this.prev = prev;        &#125;    &#125;\n\n1、 新增&emsp;&emsp;追加节点时，我们可以选择追加到链表头部，还是追加到链表尾部，add 方法默认是从尾部开始追加，通过移动尾节点的 next 指向，addFirst 方法是从头部开始追加，通过移动头节点的 prev 指向。\n  //从尾部增加public boolean add(E e) &#123;      linkLast(e);      return true;  &#125;  void linkLast(E e) &#123;    \t//把尾节点数据暂存      final Node&lt;E&gt; l = last;    \t//新建节点，l是新节点的前驱，e为要新增的节点，新增节点的后一个节点为null      final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); //（前驱、本身、后继）    \t//把newNode追加到尾部      last = newNode;    \t//链表空与不空两种情况      if (l == null)          first = newNode;      else          l.next = newNode;    \t//大小与版本的修改      size++;      modCount++;  &#125;\t//从头部增加  public void addFirst(E e) &#123;      linkFirst(e);  &#125;  private void linkFirst(E e) &#123;    \t//头节点赋给临时变量      final Node&lt;E&gt; f = first;    \t//新建节点，新节点前驱为null，e是新建节点，f为后继      final Node&lt;E&gt; newNode = new Node&lt;&gt;(null, e, f); //（前驱、本身、后继）      first = newNode;    \t//判断链表空不空      if (f == null)          last = newNode;      else          f.prev = newNode;    \t//修改大小与版本      size++;      modCount++;  &#125;\n\n2、 删除&emsp;&emsp;节点删除的方式和追加类似，我们可以选择从头部删除，也可以选择从尾部删除，删除操作会把节点的值，前后指向节点都置为 null，帮助 GC 进行回收。贴一个从头部删除\npublic E remove() &#123;    return removeFirst();&#125;public E removeFirst() &#123;    final Node&lt;E&gt; f = first;    if (f == null)        throw new NoSuchElementException();    return unlinkFirst(f);&#125;private E unlinkFirst(Node&lt;E&gt; f) &#123;    //拿出头节点的值作为方法的返回值    final E element = f.item;  \t//拿出头节点的下一个节点    final Node&lt;E&gt; next = f.next;  \t//帮助GC回收    f.item = null;    f.next = null; // help GC  \t//头节点的下一个节点成为头节点    first = next;  \t//如果 next 为空，表明链表为空    if (next == null)        last = null;    else      \t//链表不为空，头节点的前一个节点指向 null        next.prev = null;  \t//修改大小与版本    size--;    modCount++;    return element;&#125;\n\n3、 查询&emsp;&emsp;链表查询某一个节点是比较慢的，需要挨个循环查找才行。\nNode&lt;E&gt; node(int index) &#123;//如果 index 处于队列的前半部分，从头开始找，否则从后面开始找    if (index &lt; (size &gt;&gt; 1)) &#123;        Node&lt;E&gt; x = first;        for (int i = 0; i &lt; index; i++)            x = x.next;        return x;    &#125; else &#123;        Node&lt;E&gt; x = last;        for (int i = size - 1; i &gt; index; i--)            x = x.prev;        return x;    &#125;\n\n&emsp;&emsp;LinkedList 并没有采用从头循环到尾的做法，而是采取了简单二分 法，首先看看 index 是在链表的前半部分，还是后半部分。如果是前半部分，就从头开始寻 找，反之亦然。通过这种方式，使循环的次数至少降低了一半，提高了查找的性能。\n4、 方法对比\n\n\n方法含义\n返回异常\n返回特殊值\n底层实现\n\n\n\n新增节点\nadd(e)\noffer(e)\n底层实现相同\n\n\n删除节点\nremove(e)\npoll(e)\n链表为空时，remove 会抛出异常，poll 返回 null。\n\n\n查找节点\nelement(e)\npeek()\n链表为空时，element 会抛出异常，peek 返回 null。\n\n\npublic class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt;   implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable\n\n&emsp;&emsp;LinkedList 也实现了 Deque 接口，对新增、删除和查找都提供从头开始，还是从尾开始两种方向的方法，比如 remove 方法，Deque 提供了 removeFirst 和 removeLast 两种方向的使用方式，但当链表为空时的表现都和 remove 方法一样，都会抛出异常。\n5、 迭代器&emsp;&emsp;因为 LinkedList 要实现双向的迭代访问，所以我们使用 Iterator 接口肯定不行了，因为 Iterator 只支持从头到尾的访问。Java 新增了一个迭代接口，叫做ListIterator，这个接口提供了向前和向后的迭代方法。\n\n\n\n迭代顺序\n方法\n\n\n\n从头到尾迭代方法\nhasNext、next、nextIndex\n\n\n从尾到头迭代方法\nhasPrevious、previous、previousIndex\n\n\nprivate class ListItr implements ListIterator&lt;E&gt; &#123;    private Node&lt;E&gt; lastReturned;\t//上一次执行 next() 或者 previos() 方法时的节点位置    private Node&lt;E&gt; next;\t//下一个节点    private int nextIndex;\t//下一个节点的位置    private int expectedModCount = modCount;\t//期望版本号与目标版本号      public boolean hasNext() &#123;        return nextIndex &lt; size;\t// 下一个节点的索引小于链表的大小，就有    &#125;    public E next() &#123;      \t//检查期望版本号有无发生变化        checkForComodificaction();      \t//再次检查        if (!hasNext())            throw new NoSuchElementException();\t\t//把上一个节点位置改为当前节点        lastReturned = next;      \t// next 是下一个节点了，为下次迭代做准备        next = next.next;        nextIndex++;      \t//返回节点值        return lastReturned.item;    &#125;   //从尾到头迭代\t    public boolean hasPrevious() &#123;        return nextIndex &gt; 0;\t// 如果上次节点索引位置大于 0，就还有节点可以迭代    &#125;// 取前一个节点    public E previous() &#123;        checkForComodification();        if (!hasPrevious())            throw new NoSuchElementException();\t\t// next 为空场景:1:说明是第一次迭代，取尾节点(last);2:上一次操作把尾节点删除掉了      \t// next 不为空场景:说明已经发生过迭代了，直接取前一个节点即可(next.prev)        lastReturned = next = (next == null) ? last : next.prev;      \t// 索引位置变化        nextIndex--;        return lastReturned.item;    &#125;    \t//迭代器删除    public void remove() &#123;        checkForComodification();      \t// lastReturned 是本次迭代需要删除的值，分以下空和非空两种情况:\t\t// lastReturned 为空，说明调用者没有主动执行过 next() 或者 previos()，直接报错      \t// lastReturned 不为空，是在上次执行 next() 或者 previos()方法时赋的值        if (lastReturned == null)            throw new IllegalStateException();        Node&lt;E&gt; lastNext = lastReturned.next;      \t//删除当前节点        unlink(lastReturned);        if (next == lastReturned)            next = lastNext;        else            nextIndex--;        lastReturned = null;        expectedModCount++;    &#125;\n\n6、 面试问题（1）ArrayList 和 LinkedList 有何不同?\n\n答:先从底层数据结构开始说起，然后以某一个方法为突破口深入，比如:最大的不同是两者底层的数据结构不同，ArrayList 底层是数组，LinkedList 底层是双向链表，两者的数据结构不同也导致了操作的 API 实现有所差异，拿新增实现来说，ArrayList 会先计算并决定是否扩容，然后把新增的数据直接赋值到数组上，而 LinkedList 仅仅只需要改变插入节点和其前后节点的指向位置关系即可。\n\n（2）ArrayList 和 LinkedList 应用场景有何不同\n\n答:ArrayList 更适合于快速的查找匹配，不适合频繁新增删除，像工作中经常会对元素进行匹 配查询的场景比较合适，LinkedList 更适合于经常新增和删除，对查询反而很少的场景。\n\n（3）ArrayList 和 LinkedList 两者有没有最大容量\n\n答:ArrayList 有最大容量的，为 Integer 的最大值，LinkedList 底层是双向链表，理论上可以无限大,但源码中，LinkedList 实际大小用 的是 int 类型，这也说明了 LinkedList 不能超过 Integer 的最大值，不然会溢出。\n\n（4）ArrayList 和 LinkedList 是如何对 null 值进行处理的\n\n答:ArrayList 允许 null 值新增，也允许 null 值删除。删除 null 值时，是从头开始，找到第一个值是 null 的元素删除，LinkedList 也是允许null值的新增和删除的。\n\n（5）ArrayList 和 LinedList 是线程安全的么，为什么?\n\n答:当两者作为非共享变量时，比如说仅仅是在方法里面的局部变量时，是没有线程安全问题 的，只有当两者是共享变量时，才会有线程安全问题。\n\n","categories":["JAVA"],"tags":["Source Code"]},{"title":"HashSet&TreeSet 源码解读","url":"/2019/09/20/SourceCode-Set/","content":"HashSet与TreeSetHashSet、TreeSet 两个类是在 Map 的基础上组装起来的类，学习的侧重点，主要在于 Set 是如何利用 Map 现有的功能，来达成自己的目标的。\n一、HashSet1、类注释看源码先看类注释上，我们可以得到的信息有:\n\n底层实现基于 HashMap，所以迭代时不能保证按照插入顺序，或者其它顺序进行迭代\nadd、remove、contanins、size 等方法的耗时性能，是不会随着数据量的增加而增加的，这是和HashMap的底层数据结构有关，不管数据量有多大，不考虑hash冲突情况，时间复杂度都是O(1)\n线程不安全的\n迭代过程中，如果数据结构被改变，会快速失败的，会抛出ConcurrentModificationException 异常。\n\n后面3点是List、Map、Set的共同点。\n2、HashSet如何利用HashMapHashSet 的实现是基于 HashMap 的，在 Java 中，要基于基础类进行创新实现，有两种办法\n\n继承基础类，覆写基础类的方法\n组合基础类，通过调用基础类的方法，来复用基础类的能力。\n\nHashSet是把HashMap组合进来的\n// 把 HashMap 组合进来，key 是 Hashset 的 key，value 是下面的 PRESENTprivate transient HashMap&lt;E,Object&gt; map;// HashMap 中的 valueprivate static final Object PRESENT = new Object();\n\n为什么要用组合呢？（从继承和组合两个角度回答）\n\n继承表示父子类是同一个事物，而 Set 和 Map 本来就是想表达两种事物，所以继承不妥，并且java只能单继承，后续很难扩展\n组合更加灵活，可以任意的组合现有的基础类，并且可以在基础类方法的基础上进行扩展\n工作中也是多用组合，少用继承\n\n从代码中可以得到的信息是\n\n使用 HashSet 时，比如 add 方法，只有一个入参，但组合的 Map 的 add 方法却有 key，value 两个入参，相对应上 Map 的 key 就是我们 add 的入参，value 就是第二行代码，中的 PRESENT，此处设计非常巧妙，用一个默认值 PRESENT 来代替 Map 的 Value；看下面代码，set的add方法实际上就是添加key的过程，而value使用的是自定义的默认值。\n\npublic boolean add(E e) &#123;    return map.put(e, PRESENT)==null;&#125;\n\n\n\n3、初始化HashSet 的初始化就是直接 new HashMap ，比较有意思的是，当有原始集合数据进行初始化的情况下，会对 HashMap 的初始容量进行计算，源码如下：\npublic HashSet(Collection&lt;? extends E&gt; c) &#123;      map = new HashMap&lt;&gt;(Math.max((int) (c.size()/.75f) + 1, 16));      addAll(c);  &#125;\n\nMath.max ((int) (c.size ()/.75f) + 1, 16)，就是对 HashMap 的容量进行了计 算，翻译成中文就是取括号中两个数的最大值(期望的值 / 0.75+1，默认值 16)\n\n如果给定 HashMap 初始容量小于 16 ，就按照 HashMap 默 认的 16 初始化好了，如果大于 16，就按照给定值初始化。\nHashMap 扩容的伐值的计算公式是:Map 的容量 * 0.75f，一旦达到阀值就会扩容\n\n同时这种写法，也提供了一种思路给我们，如果有人问你，往 HashMap 拷贝大集合时，如何给 HashMap 初始化大小时，完全可以借鉴这种写法:取最大值(期望的值 / 0.75 + 1，默认 值 16)。\n二、TreeSetTreeSet 底层组合的是 TreeMap，所以有 TreeMap key 能够排序的功能，迭代的时候，也可以按照 key 的排序顺序进行迭代\npublic TreeSet() &#123;    this(new TreeMap&lt;E,Object&gt;());&#125;\n\n复用 TreeMap 时，复用有两种思路：\n思路一：TreeSet 的 add 方法，底层直接使用的是 HashMap 的 put 的能力\npublic boolean add(E e) &#123;    return m.put(e, PRESENT)==null;&#125;\n\n思路二：需要迭代 TreeSet 中的元素，那应该也是像 add 那样，直接使用 HashMap 已有的迭 代能力，比如像下面这样:\n// 模仿思路一的方式实现public Iterator&lt;E&gt; descendingIterator() &#123;   // 直接使用 HashMap.keySet 的迭代能力   return m.keySet().iterator();&#125;\n\n这种是思路一的实现方式，TreeSet 组合 TreeMap，直接选择 TreeMap 的底层能力进行包 装，但 TreeSet 实际执行的思路却完全相反，TreeSet 本身已经定义了迭代的规范，源码如下\n// NavigableSet 接口，定义了迭代的一些规范，和一些取值的特殊方法 // TreeSet 实现了该方法，也就是说 TreeSet 本身已经定义了迭代的规范 public interface NavigableSet&lt;E&gt; extends SortedSet&lt;E&gt; &#123;\t\tIterator&lt;E&gt; iterator();\t\tE lower(E e); &#125;// m.navigableKeySet() 是 TreeMap 写了一个子类实现了 NavigableSet接口，实现了 TreeSet 定义的迭代规范public Iterator&lt;E&gt; iterator() &#123;  \t//，让 TreeMap 去实现自己定义的规范\t\treturn m.navigableKeySet().iterator(); &#125;\n\n\n\n\n总结下 TreeSet 组合 TreeMap 实现的两种思路：\n\n TreeSet 直接使用 TreeMap 的某些功能，自己包装成新的 api，自己实现\n TreeSet 定义自己想要的 api，自己定义接口规范，让 TreeMap 去实现。\n\n这两个方式都是TreeSet调用TreeMap，第一种是功能的定义和实现都在 TreeMap，TreeSet 只是简单的调用而已，第二种是TreeSet把规范结构定义出来了，让让 TreeMap 去实现，TreeSet只要往外吐出结果就可以，都不用包装。\n为什么要有这两种复用思路？\n\n像 add 这些简单的方法，没有复杂逻辑，直接调用TreeMap的自己实现\n另一种是复杂场景下，TreeSet不太清楚TreeMap的底层逻辑是什么，这时候不如让TreeSet定义接口规范，让TreeMap来负责实现，因为TreeMap对底层比较清楚。\n\n","categories":["JAVA"],"tags":["Source Code"]},{"title":"ThreadPool 源码解读","url":"/2019/01/14/SourceCode-ThreadPool/","content":"线程池源码整体架构\n\n首先来了一个任务，先判断下核心线程池里的线程数有没有达到设定的值，如果没有，就可以新建个Worker出来处理任务，处理任务的时候如果这个任务为空，那这个worker就阻塞住，因为这个任务不需要处理，如果这个任务不为空，就会准备执行任务，这个Worker实现了Runnable接口，并且继承了AQS，那么它就会重写run方法，它重写的run方法里面调用了runWorker()，这个是真正执行任务的，执行任务时，那么首先就会所在执行任务前看看你有没有重写beforeExecute，如果重写了，那就会执行下，然后再执行任务，执行完也会看下有没有重写afterExecute。\n如果来了一个任务，队列没满，就尝试放进阻塞队列，在尝试放入阻塞队列的时候，如果线程池状态异常，那就会拒绝任务，如果队列满了，那就要看此时你设置的maxinumPoolSize，看线程池里的线程有没有达到这个最大值，如果没有，那就可以创建线程出来执行任务，如果达到了，没有线程了，那就只能采取拒绝策略，常用的拒绝策略是 abortpolicy（抛异常），还有discardPolicy（直接丢弃任务），还有discardOldestPolicy（直接丢弃队列中最老的任务），还有个忘了\n\n1、Executor这个是多线程的顶级接口，只有一个execute方法\n2、ExecutorServiceExecutor 的功能太弱，只有一个execute，ExecutorService接口 丰富了对任务的执行和管理的功能，它继承了Executor接口\n\n// 线程池关闭，不会接受新的任务，也不会等待未完成的任务void shutdown();// executor 是否已经关闭了，返回值 true 表示已关闭boolean isShutdown();// 所有的任务是否都已经终止，是的话，返回 trueboolean isTerminated();// 在超时时间内，等待剩余的任务终止boolean awaitTermination(long timeout, TimeUnit unit)  // 提交有返回值的任务，使用 get 方法可以阻塞等待任务的执行结果返回&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);//传入Runnable就没有返回结果了Future&lt;?&gt; submit(Runnable task);//还有其他一些方法，这里只是举例\n\n\n\n3、AbstractExecutorService这个是个一个抽象类，封装ExecutorService里的功能\n4、注释得到的信息\n线程池可以使用Executors进行配置\nExecutors.newCachedThreadPool 无界的线程池，并且可以自动回收;\nExecutors#newFixedThreadPool 固定大小线程池;\nExecutors#newSingleThreadExecutor 单个线程的线程池;\n\n\n线程池提供可供扩展的参数设置,corsSize和maxSize，一般来说这两个值初始化时候就设定了，当然我们可以自己set，来修改这两个值\n线程池创建时有多种队列可供选择，有四种队列，可见我另一篇博客\nLinkedBlockingQueue，无界阻塞队列\nArrayBlockingQueue，有界阻塞队列\nDelayBlockingQueue，延迟队列\nSynchronousQueue，同步阻塞队列\n\n\n线程池用了模版方法模式，提供了很多hook函数，比如beforeExecute()、afterExecute()，在线程执行前后需要做什么\n还有很多信息就不写了\n\n5、ThreadPoolExecutor的重要属性\nctl：线程池状态字段，它是由两部分构成的\nworkerCount，wc 工作线程数， workerCount 最大到(2^29)-1，大概 5 亿个线程\nrunState，rs 线程池的状态\n\n\nRUNNING：值为-536870912，表示线程池正在接受新任务或者处理队列里的任务\nSHUTDOWN：值为0，表示不接受新任务，但仍在处理已经在队列里面的任务\nSTOP：值为-536870912，不接受新任务，也不处理队列中的任务，有正在执行的任务就中断\nTIDYING：值为1073741824，它是整理状态，所有任务都被中断，此时wc是0\nTERMINATED：terminated() 已经完成的时候\nThreadFactory threadFactory：使用 threadFactory 创建 thread\nRejectedExecutionHandler handler：拒绝任务的 handler 处理类\ncorePoolSize：线程池线程核心数\nmaximumPoolSize：线程池最大线程数\n\nWorker是线程池中运行任务的最小单元，Worker实现了Runnable接口，继承了AQS类。Worker本身就是一个Runnable，在它的构造方法中，getThreadFactory().newThread(this)这是话是说它是把自己作为任务传递给了thread\nWorker(Runnable firstTask) &#123;  setState(-1); // inhibit interrupts until runWorker  this.firstTask = firstTask;  this.thread = getThreadFactory().newThread(this);&#125;\n\nWorker就像是任务的一个代理，Worker实现了Runnable，所以要重写run方法，这个run方法调用了runWorker()，\npublic void run() &#123;  runWorker(this);&#125;\n\nWorker继承了AQS，那么它本身就是一个锁，在执行任务的时候，它会锁住它自己，执行完任务然后再释放自己，Worker里面也是重写了tryAcquire()和tryRelease（）\n创建线程池及一些线上问题第一种线程池的创建方式是利用线程池的工具类Executors来new一个这个线程池\nExecutorService threadPool = Executors.newFixedThreadPool(3) //3就是corePoolSize，核心线程数量\n\n第二线程池的创建方式是直接new一个ThreadPollExecutor()，下面这种方式更推荐\n\n这边有几个参数\n\ncorePollSize：指定核心线程数量，这个就是线程池里\nmaximumPoolSize：这个是假设我线程池里已经有corePollSize个线程了，但是它们处理任务很慢，然后阻塞队列也满了，如果此时maximumPoolSize它是大于这个核心线程数的，那就会再创建这个线程出来执行任务，那么这个maximumPoolSize创建出来的线程什么时候被回收呢，就用到了下面这个参数\nkeepAliveTime：这个也就是说，我maximumPoolSize里面的线程空闲时间达到keepAliveTime，那就可以回收了\n还有一种情况是这个corePollSize满了，队列满了，maximumPoolSize也满了，那就不能再创建额外的线程出来了，所以这边就有拒绝策略，常见的拒绝策略是 AbortPolicy，就直接丢弃任务，还有DiscardPolicy、DiscardOldestPolicy等等\n一般用的是fixed线程池，它的corePollSize和maximumPoolSize是一样大的，然后默认的阻塞队列是无界阻塞队列，可以无限制放任务，如果用无界阻塞队列不设置上限，然后处理任务也很慢，队列积压很多，那么内存飙升，回收也没法回收，就可能导致OOM\n针对上面的解决策略是，我可以自定义一个拒绝策略，队列满了，来任务了，我就持久化到磁盘上去，等我任务处理的差不多了，再从磁盘上读进来再处理任务。\n当然线程机器可能宕机，那么这个任务不就没了吗，所以一种处理措施是，我在提交任务的时候，往数据库里写上这个任务的信息，然后给他设置个状态，是未提交、提交了、已完成，提交成功后更改状态，如果此时系统宕机也没关系，系统重启再去扫描数据库里面未提交和已提交的任务，再执行\n\nsubmit()和execute()首先看一下结构\nExecutor是线程池最顶级的接口，它的一个子接口是ExecutorService，然后是有一个抽象类AbstractExecutorService实现了ExecutorService这个接口，最后才是这个ThreadPoolExecutor来继承这个抽象类。\n\npublic interface ExecutorService（二级接口） extends Executor（线程顶级接口）abstract class AbstractExecutorService（第三级） implements ExecutorServiceclass ThreadPoolExecutor（第四级） extends AbstractExecutorService\n\n但是我们new一个ThreadPoolExecutor出来后，既可以执行submit()，也可以执行execute()，实际上这两个是有区别的\n\n顶级接口Executor这个接口它只有一个execute()方法\n\npublic interface Executor &#123;    void execute(Runnable command);&#125;\n\n\n\n\n二级接口ExecutorService，在这一层，添加了submit()方法\n\n\n\n到了第三层AbstractExecutorService，它实现了ExecutorService这个接口，自然有submit和execute这两个方法\n到了第四层ThreadPoolExecutor这个实现类，它没有 submit这个方法，但是有execute方法，那么实际上ThreadPoolExecutor的实例调用的是AbstractExecutorService的submit方法\n\n//AbstractExecutorService的submit方法，举例两个public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123;    if (task == null) throw new NullPointerException();    RunnableFuture&lt;T&gt; ftask = newTaskFor(task);    execute(ftask);    return ftask;&#125;public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) &#123;    if (task == null) throw new NullPointerException();    RunnableFuture&lt;T&gt; ftask = newTaskFor(task, result);    execute(ftask);    return ftask;&#125;\n\n可以看到这个AbstractExecutorService的submit方法本质上还是调用了Executor的execute方法\n注意submit的返回值是 Future 类的，而execute的返回值是void\nsubmit做了两件事情\n\nsubmit的参数可以是实现了runnable接口的，也可以是实现了callable接口的，第一件事情就是把Runnable接口和Callable都转化成FutureTask\n第二件事情就是让execute方法执行FutureTask\n\nexecute()那么ThreadPoolExecutor的execute()这个方法的实现是怎样的呢？\n\n这一道这边有个，这个意思是说，并发的时候，可能线程还没启动，任务已经跑起来了，所以会预先搞个非核心线程出来\nelse if (workerCountOf(recheck) == 0)      addWorker(null, false);\n\naddWorker()与runWorker()接着看一下addWorker()方法，它就是结合线程池的情况看要不要添加Worker\n\n注意addWorker方法传进来的参数是firstTask， 在初始化的过程中，会把 worker自己作为任务传给 thread 去初始化，上文说了 Worker 在初始化时的关键代码，this.thread = getThreadFactory ().newThread (this)，Worker(this) 是作为新建线程的构造器入参的，所以 t.start () 会执行到 Worker 的 run 方法上\n\n这个worker的run调用了一个runWorker\n\n这个runWorker才是真正去执行run方法的，也是比较重要的方法\n\n通过w.firstTask拿到的task，此时的task是FutureTask类（Future接口的子接口又个RunnableFuture，这个RunnableFuture的父接口是Future和Runnable，然后FutureTask实现了RunnableFuture这个接口，所以FutureTask里面也有run方法），直接看FutureTask的run的源码，它是没有返回值的\n\n执行完任务之后呢上面代码也看到了，在runWorker()方法中是一个while循环，如果队列中有任务就继续执行\n\n那么关键就是这个getTask方法\n\n","categories":["JAVA"],"tags":["Source Code"]},{"title":"TreeMap 源码解读","url":"/2019/09/13/SourceCode-TreeMap/","content":"TreeMapTreeMap 底层的数据结构就是红黑树。TreeMap 利用了红黑树左节点小，右节点大的性质，根据 key 进行排序，使每个元素能够插入到红黑树大小适当的位置，维护了 key 的大小关系，适用于 key 需要排序的场景。因为底层使用的是红黑树的结构（平衡树），所以 containsKey、get、put、remove 等方法的时间 复杂度都是 log(n)。\n在讲TreeMap之前，了解下Comperable接口与Comparator比较器这两种排序方式。Comperable接口中有一个CompareTo方法，需要排序的类要实现这个接口重写这个方法。\npublic int compareTo(T o);\n\n另一个是比较器Comparator，可以自定义比较器来比较。\n一、常见属性//自带的比较器，如果外部有传进来比较器，优先用外部的private final Comparator&lt;? super K&gt; comparator;//红黑树的根private transient Entry&lt;K,V&gt; root;//红黑树已有元素个数private transient int size = 0;//版本号修改次数private transient int modCount = 0;//红黑树的节点static final class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123;        K key;        V value;        Entry&lt;K,V&gt; left;        Entry&lt;K,V&gt; right;        Entry&lt;K,V&gt; parent;        boolean color = BLACK;\n\n二、新增节点\n第一步，判断红黑树的根节点是不是空的，是空的则要创建根节点，并且key不能为null\n第二步，根据红黑树左小右大的特性，找到新增节点的父节点（这边要判断有没有外部比较器），如果已经存在，就是值相等，就直接覆盖\n第三步，找到父节点之后就是插入，相等的情况就在第二步中处理\n第四步，对红黑树进行着色旋转，达到平衡\n\npublic V put(K key, V value) &#123;    Entry&lt;K,V&gt; t = root;  \t//1、如果根是空的，就new一个出来，size++，修改版本号（这边限制了key不能为null）    if (t == null) &#123;        compare(key, key); // type (and possibly null) check        root = new Entry&lt;&gt;(key, value, null);        size = 1;        modCount++;        return null;    &#125;    int cmp;    Entry&lt;K,V&gt; parent;    // 根据红黑树左小右大的特性，找到新增节点的父节点    Comparator&lt;? super K&gt; cpr = comparator;  \t//如果有外部比较器    if (cpr != null) &#123;      \t// 自旋找到key应该新增的位置        do &#123;            //一次循环结束时，parent 就是上次比过的对象            parent = t;            // 通过 compare 来比较 key 的大小            cmp = cpr.compare(key, t.key);            //key 小于 t，把 t 左边的值赋予 t，因为红黑树左边的值比较小，循环再比            if (cmp &lt; 0)                t = t.left;            //key 大于 t，把 t 右边的值赋予 t，因为红黑树右边的值比较大，循环再比            else if (cmp &gt; 0)                t = t.right;            //如果相等的话，直接覆盖原值            else                return t.setValue(value);        &#125; while (t != null);  // t 为空，说明已经到叶子节点了    &#125;  \t//如果没有外部比较器    else &#123;        if (key == null)            throw new NullPointerException();        @SuppressWarnings(&quot;unchecked&quot;)            Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key;        do &#123;            parent = t;            cmp = k.compareTo(t.key);            if (cmp &lt; 0)                t = t.left;            else if (cmp &gt; 0)                t = t.right;            else                return t.setValue(value);        &#125; while (t != null);    &#125;    Entry&lt;K,V&gt; e = new Entry&lt;&gt;(key, value, parent);    // cmp 代表最后一次对比的大小，小于 0 ，代表 e 在上一节点的左边    if (cmp &lt; 0)        parent.left = e;  \t// 代表 e 在上一节点的右边，相等的情况第二步已经处理    else        parent.right = e;    fixAfterInsertion(e);    size++;    modCount++;    return null;&#125;\n\nTreeMap的查找与HashMap类似\n","categories":["JAVA"],"tags":["Source Code"]},{"title":"背包型动态规划","url":"/2019/12/02/dp-bag/","content":"动态规划：背包型数组开n+1，背包关键就是看最后一步。\n1、01背包–求maxLintCode 92: Backpack\n【问题】在n个物品中挑选若干物品装入背包，最多能装多满？假设背包的大小为m，每个物品的大小为A[i]\n【分析】从最后一步出发，最后一个物品放还是不放。有两种情况\n\n前n-1个物品能拼出重量 w，那么n个物品也能拼出重量w\n前n-1个物品能拼出重量 w - A[n-1]，再加上最后一个物品 A[n-1] 拼出w\n\n【状态转移】\n\ndp[i][w]表示能否用前i个物品拼出重点w，可以用int数组，也可以用boolean数组，\ndp[i][j] = max{dp[i-1][j], dp[i-1][j - A[n-1]] + A[i-1]}（int数组）放还是不放\ndp[i][j] = dp[i-1][w] or dp[i-1][j - A[i-1]]（boolean数组）\n\n//int型写法\tpublic static int backPack2(int m, int[] A) {        int n = A.length;        int[][] dp = new int[n + 1][m + 1];        for (int i = 1; i &lt;= n; i++) {            for (int j = 0; j &lt;= m; j++) {                //不放                dp[i][j] = dp[i - 1][j];                //放                if (j &gt;= A[i - 1]) {                    dp[i][j] = Math.max(dp[i][j], dp[i - 1][j - A[i - 1]] + A[i - 1]);                }            }        }        return dp[n][m];    }//boolean型写法public int backPack(int m, int[] A) {        int n = A.length;   //物品个数        boolean[][] dp = new boolean[n + 1][m + 1];        dp[0][0] = true;        for (int i = 1; i &lt;= m; i++) {            dp[0][i] = false;        }        for (int i = 1; i &lt;= n; i++) {            //首先初始化dp[i][0]            for (int j = 0; j &lt;= m; j++) {                //不放                dp[i][j] = dp[i - 1][j];                //放                if (j &gt;= A[i - 1]) {                    // |=,只要有一个为true就是true                    // 放入A[i-1]的情况就是看j-A[i-1]这个容量下是不是为true，如果为true，那么就是dp[i][j]为true，否则就是看dp[i-1][j]是否为true                    dp[i][j] |= dp[i - 1][j - A[i - 1]];                }            }        }        int res = 0;        for (int i = m; i &gt;= 0; i--) {            if (dp[n][i] == true) {                res = i;                break;            }        }        return res;    }\n\n优化成一维\npublic int backPack(int m, int[] A) {       int f[] = new int[m + 1];       for (int i = 0; i &lt; A.length; i++) {        \t//从后往前更新         //下面的f[j - A[i]]，j - A[i]严格小于j，j是从小到大枚举的         //也就是在第i层已经算过了，等价于f[i][j-A[i]]         //那么我们从大到小更新，算f[j],f[j - A[i]]其实是还没有被更新过，它存的是第i-1层的，这就对了           for (int j = m; j &gt;= A[i]; j--) {             \t//不放和放，不放就是它自身               f[j] = Math.max(f[j], f[j - A[i]] + A[i]);           }        }       return f[m];   }\n\n2、01背包–求数量LintCode 563: Backpack V\n【问题】给出 n 个物品, 以及一个数组, nums[i] 代表第i个物品的大小, 保证大小均为正数, 正整数 target 表示背包的大小, 找到能填满背包的方案数。注意：每一个物品只能使用一次。\n【分析】需要求出有多少种组合能组合成target，对于最后一个物品，有放和不放两种选择。\n\n第一种：使用前n-1个物品拼出target\n第二种：前n-1个物品能拼出target - nums[i]，再加上nums[i]，拼出target\n拼出target的方式 = 不放+放,即dp[i][j] = dp[i-1][j] + dp[i-1][j - nums[i-1]] \n如果知道有多少种方式拼出0、1、2…对于有多少种方式拼出target也就知道答案了。\n\n常规写法，时间复杂度O(n*Target)\npublic static int backPackV1(int[] nums, int target) {       int n = nums.length;       if (n == 0) {           return 0;       }       int[][] dp = new int[n + 1][target + 1];    //dp[i][j]表示前i个数字有多少种方式拼出数字j       dp[0][0] = 1;   //0个物品有一种方式拼出重量0       //初始化       for (int i = 1; i &lt;= target; i++) {           dp[0][i] = 0;       }       for (int i = 1; i &lt;= n; i++) {           //拼出几           for (int j = 0; j &lt;= target; j++) {               //不放               dp[i][j] = dp[i - 1][j];               //放               if (j &gt;= nums[i - 1]) {                        dp[i][j] += dp[i - 1][j - nums[i - 1]];               }           }       }       return dp[n][target];   }\n\n第一步优化：利用滚动数组\npublic static int backPackV3(int[] nums, int target) {       int n = nums.length;       if (n == 0) {           return 0;       }       int[][] dp = new int[2][target + 1];       dp[0][0] = 1;       for (int i = 1; i &lt;= target; i++) {           dp[0][i] = 0;       }       int old = 0, now = 0;       for (int i = 1; i &lt;= n; i++) {           old = now;;           now = 1 - now;           for (int j = 0; j &lt;= target; j++) {               //不放               dp[now][j] = dp[old][j];               //放               if (j &gt;= nums[i - 1]) {                   dp[now][j] += dp[old][j - nums[i - 1]];               }           }       }       return dp[now][target];   }\n\n第二步优化：优化成一行。原本是 老值 + 老值 = 新值，如果正着更新，可能会出现 老值 + 新值，所以需要倒着更新\ndp[i][j] = dp[i-1][j] + dp[i-1][j - nums[i-1]]，新值 = 两个老值加起来\npublic static int backPackV2(int[] nums, int target) {       int n = nums.length;       if (n == 0) {           return 0;       }       int[] dp = new int[target + 1]; //和总称重有关       //init：相当于dp[0][0] = 1       dp[0] = 1;       //init：dp[0][1] = dp[0][2] = ... = 0       for (int i = 1; i &lt;= target; i++) {           dp[i] = 0;       }       for (int i = 1; i &lt;= n; i++) {           //reverse           for (int j = target; j &gt;= 0; j--) {               if (j &gt;= nums[i - 1]) {                   //old + old ==&gt; new old1 = dp[j],old2 = dp[j - nums[i - 1]],new就是直接覆盖                   dp[j] += dp[j - nums[i - 1]];               }           }       }       return dp[target];   }\n\n3、LintCode 564: Backpack VI【问题】给出一个都是正整数的数组 nums，其中没有重复的数。从中找出所有的和为 target 的组合个数。注意一个数可以在组合中出现多次，数的顺序不同则会被认为是不同的组合。\n【分析】这个题和Backpack V的区别是每个物品可以使用多次，且组合中数字可以按照不同顺序，比如1+1+2与1+2+1算是两种情况，这就导致不能按照物品顺序来处理。依旧是关注最后一步，最后一步物品重量是K，那么前面物品构成重量target-K，需要关注最后一个加进来的是谁。\n\n如果最后一个物品重量是A0, 则要求有多少种组合能拼成 Target – A0\n如果最后一个物品重量是A1, 则要求有多少种组合能拼成 Target – A1\n……\n如果最后一个物品重量是An-1, 则要求有多少种组合能拼成 Target – An-1\n\n【状态转移方程】dp[i]代表有多少种组合能拼出重量i，则dp[i] = dp[i-A[0]] + dp[i-A[1]] +...+ dp[i-A[n-1]]\n【初始条件】dp[0] = 1，有1种组合能拼出0\npublic int backPackVI(int[] nums, int target) {       int n = nums.length;       int[] dp = new int[target + 1];       dp[0] = 1;       //对于能拼出的i       for (int i = 1; i &lt;= target; i++) {           //初始化能拼出i的情况为0种           dp[i] = 0;             //遍历所有数字           for (int j = 0; j &lt; n; j++) {               if (i &gt;= nums[j]) {                   dp[i] += dp[i - nums[j]];               }           }       }       return dp[target];   }\n\n4、LintCode 125: Backpack II【问题】有 n 个物品和一个大小为 m 的背包. 给定数组 A 表示每个物品的大小和数组 V 表示每个物品的价值。问最多能装入背包的总价值是多大？注意：每个物品只能取一次，物品不能切分。\npublic int backPackII(int m, int[] A, int[] V) {       int n = A.length;       int[][] dp = new int[n + 1][m + 1];       //初始化       for (int i = 0; i &lt;= m; i++) {           dp[0][i] = 0;       }       int res = Integer.MIN_VALUE;       for (int i = 1; i &lt;= n; i++) {           for (int j = 0; j &lt;= m; j++) {               //不放               dp[i][j] = dp[i - 1][j];             \t//放               if (j &gt;= A[i - 1]) {                   dp[i][j] = Math.max(dp[i][j], dp[i - 1][j - A[i - 1]] + V[i - 1]);               }               res = Math.max(res, dp[i][j]);           }       }       return res;   }\n\n5、完全背包LintCode 440: Backpack III\n【问题】将Backpack II的物品改为无穷多个，背包最大承重m，求能带走的最大价值。\n\n输入:4个物品，重量为2, 3, 5, 7，价值为1, 5, 2, 4. 背包最大承重是10\n输出:15\n\n【分析】Ai-1有无穷多个，可以用1个、2个…在这里可以把物品变为种类，这边状态转移方程变为\n\nf[i] [w] = maxk&gt;=0{f[i-1] [w-kAi-1] + kVi-1}，表示用前i种物品拼出重量w时的最大总价值，等于用前i-1种物品拼出重量w-kAi-1 时最大总价值，加上k个第i种物品，当k = 0和1时，就可以直接用在Backpack II 中了。\n\n把这个式子展开，如下\n\n可以优化\n\n什么意思呢\n\n假设Ai-1 = 2,Vi-1 = x\nf[i] [5] = max{ f[i-1] [5], f[i-1] [3] + x, f[i-1] [1] + 2x }\nf[i] [7] = max{ f[i-1] [7], f[i-1] [5] + x, f[i-1] [3] + 2x, f[i-1] [1] + 3x }\n\n这样算了重合的部分，不是我们想要的\n// 只需要把Backpack II中关键一行改为// dp[i][j] = Math.max(dp[i][j],dp[i][j - A[i-1]] + V[i-1])    public int backPackII(int m, int[] A, int[] V) {        int n = A.length;        int[][] dp = new int[n + 1][m + 1];        //初始化        for (int i = 0; i &lt;= m; i++) {            dp[0][i] = 0;        }        int res = Integer.MIN_VALUE;        for (int i = 1; i &lt;= n; i++) {            for (int j = 0; j &lt;= m; j++) {                //不放                dp[i][j] = dp[i - 1][j];              \t//放                if (j &gt;= A[i - 1]) {                    dp[i][j] = Math.max(dp[i][j],dp[i][j - A[i-1]] + V[i-1]);                }                res = Math.max(res, dp[i][j]);            }        }        return res;    }\n\n可以优化到一维，这边的细节是：用的不是两个old值，而是old+new，可以只开一个数组，old+new去覆盖本来的old，这就需要时从前往后来，而不是逆序，如图\n\npublic int backPackIII(int m, int[] A, int[] V) {       int n = A.length;       int[] dp = new int[m + 1];       dp[0] = 0;       int res = Integer.MIN_VALUE;       for (int i = 1; i &lt;= n; i++) {           for (int j = 0; j &lt;= m; j++) {               if (j &gt;= A[i - 1]) {\t//上面改成j直接从A[i-1]出发更好                 //old = dp[j],new = dp[j - A[i - 1] + V[i - 1]],加起来覆盖本来的old                 //old相当于原来的dp[i-1][j],dp[j - A[i - 1]相当于dp[i][j - A[i - 1]                 //这边就不需要倒着更新，因为和二维的状态转移方程是一致的，我们需要的就是第i层的                 //这里不动看下01背包那边的注释就懂了                   dp[j] = Math.max(dp[j], dp[j - A[i - 1] + V[i - 1]]);               }               res = Math.max(res, dp[j]);           }       }       return res;   }\n\n\n\nTBD：多重背包（这个优化思想比较巧妙）、分组背包 \n","categories":["Algorithm"],"tags":["Dynamic programming"]},{"title":"坐标型动态规划","url":"/2019/12/01/dp-coordinate/","content":"动态规划解题模版：：坐标型坐标型dp一般都是给定网格、序列，来求满足某种性质的最大值、最小值。开数组时，f[i]代表以ai 结尾的满足条件的子序列，f[i][j]代表以i、j结尾的满足条件的某种情况。\n做题思路：\n\n从最后一步出发思考，确定状态\n分析子问题是什么\n得到状态转移方程\n确定初始条件与边界条件\n编程\n\n1、Lintcode 114 UniquePaths【问题】有一个机器人的位于一个 m × n 个网格左上角。机器人每一时刻只能向下或者向右移动一步。机器人试图达到网格的右下角。问有多少条不同的路径？\n【分析】最后一步：要么从左边来，要么从上边来，故dp[i][j] = dp[i][j-1] + dp[i-1][j]\npublic int uniquePaths(int m, int n) {        int[][] dp = new int[m][n];        //初始化        dp[0][0] = 1;        //初始化第一行        for (int j = 0; j &lt; n; j++) {            dp[0][j] = 1;        }        //初始化第一列        for (int i = 0; i &lt; m; i++) {            dp[i][0] = 1;        }        //处理其他        for (int i = 1; i &lt; m; i++) {            for (int j = 1; j &lt; n; j++) {                dp[i][j] = dp[i - 1][j] + dp[i][j - 1];            }        }        return dp[m - 1][n - 1];    }\n\n2、Lintcode 115 UniquePathsWithObstacles【问题】上一题的跟进问题，现在考虑网格中有障碍物，那样将会有多少条不同的路径？网格中的障碍和空位置分别用 1 和 0 来表示。\n【分析】从最后一步出发，要选一条没有障碍的路径到达右下角，当前位置i,j所有可能路径依然是 dp[i] [j] = dp[i] [j-1] + dp[i-1] [j]，但必须是没有障碍的\n\n起点和终点若有障碍，直接返回0\n初始化第一行和第一列，也要考虑有障碍的情况\n起点和终点没有障碍，若途中碰到障碍了，令dp[i][j] = 0，表示不可达\n\npublic int uniquePathsWithObstacles(int[][] A) {        int n = A.length;        int m = A[0].length;        //判断起点和终点有没有障碍，有障碍直接返回0        if (A[0][0] == 1 || A[n - 1][m - 1] == 1) {            return 0;        }        int[][] dp = new int[n][m];        //初始化        dp[0][0] = 1;        int i, j;        //初始化第一行        for (j = 1; j &lt; m; j++) {            if (A[0][j] == 1) {                dp[0][j] = 0;            } else {                dp[0][j] = dp[0][j - 1];            }        }        //初始化第一列        for (i = 1; i &lt; n; i++) {            if (A[i][0] == 1) {                dp[i][0] = 0;            } else {                dp[i][0] = dp[i - 1][0];            }        }        //处理其他        for (i = 1; i &lt; n; i++) {            for (j = 1; j &lt; m; j++) {                if (A[i][j] == 1) {                    dp[i][j] = 0;                    continue;                } else {                    dp[i][j] = dp[i - 1][j] + dp[i][j - 1];                }             }        }        return dp[n - 1][m - 1];    }\n\n3、Lintcode 397 Longest Increasing Continuous Subsequence【问题】给定一个整数数组（下标从 0 到 n-1， n 表示整个数组的规模），请找出该数组中的最长上升连续子序列。（最长上升连续子序列可以定义为从右到左或从左到右的序列。）\n【分析】也就是求“最长连续单调子序列”，也就是LIS+LDS。实际上只要求个LIS再倒过来求一遍。\npublic int longestIncreasingContinuousSubsequence(int[] A) {        int res = LIS(A);        //倒过来求一遍        int i = 0;        int j = A.length - 1;        while (i &lt; j) {            int temp = A[i];            A[i] = A[j];            A[j] = temp;            i++;            j--;        }        return Math.max(res, LIS(A));    }    public int LIS(int[] A) {        int n = A.length;        if (n == 0) {            return 0;        }        int[] dp = new int[n];        int res = 1;        //最少长度是1        dp[0] = 1;          for (int i = 1; i &lt; n; i++) {            //长度至少是1，它本身            dp[i] = 1;            if (A[i] &gt; A[i - 1]) {                dp[i] = dp[i - 1] + 1;            }            res = Math.max(res, dp[i]);        }        return res;    }\n\n4、LintCode 110 Minimum Path Sum【问题】给定一个只含非负整数的m x n网格，找到一条从左上角到右下角的可以使数字和最小的路径。简而言之求最小路径和。\n//普通方式public int minPathSum(int[][] A) {        int n = A.length;        int m = A[0].length;        int[][] dp = new int[n][m];        for (int i = 0; i &lt; n; i++) {            for (int j = 0; j &lt; m; j++) {                if (i == 0 &amp;&amp; j == 0) {                    dp[i][j] = A[0][0];                    continue;                }                dp[i][j] = Integer.MAX_VALUE;                //来自上方的情况                if (i &gt; 0) {                    dp[i][j] = Math.min(dp[i][j], dp[i - 1][j] + A[i][j]);                }                //来自左侧的情况                if (j &gt; 0) {                    dp[i][j] = Math.min(dp[i][j], dp[i][j - 1] + A[i][j]);                }            }        }        return dp[n-1][m - 1];    }\n\n使用滚动数组进行优化，当前行只和上面一行有关系，实际上只需要开两行，使用old和new指针，old存放i-1行，new存放当前第i行，关键语句在于old和now进行交换\n\nold = now;\nnow = 1 - now\n\n//滚动数组优化//只需要把i变为now，i-1变为old即可public int minPathSum(int[][] A) {        int n = A.length;        int m = A[0].length;        int[][] dp = new int[2][m];        int old = 0, now = 0;        for (int i = 0; i &lt; n; i++) {            old = now;            now = 1 - now;            for (int j = 0; j &lt; m; j++) {                if (i == 0 &amp;&amp; j == 0) {                    dp[now][j] = A[0][0];                    continue;                }                dp[now][j] = Integer.MAX_VALUE;                //来自上方                if (i &gt; 0) {                    dp[now][j] = Math.min(dp[now][j], dp[old][j] + A[i][j]);                }                //来自左侧                if (j &gt; 0) {                    dp[now][j] = Math.min(dp[now][j], dp[now][j - 1] + A[i][j]);                }            }        }        return dp[now][m - 1];    }\n\n5、LintCode 553 Bomb Enemy【问题】给定一个二维矩阵, 每一个格子可能是一堵墙 W,或者 一个敌人 E 或者空 0 (数字 ‘0’), 返回你可以用一个炸弹杀死的最大敌人数. 炸弹会杀死所有在同一行和同一列没有墙阻隔的敌人。 由于墙比较坚固，所以墙不会被摧毁。\n【分析】原本只能在空地放炸弹，现在假设有敌人和有墙的地方也能放炸弹，有敌人的地方，格子里的敌人能被炸死，再加上其他炸死的人，有墙的地方，炸死人数为0。现在分析一个方向，比如向上，有三种情况：\n\n（i,j）是空地：结果就是从（i-1,j）格开始向上能炸死的敌人数\n（i,j）是敌人：结果就是从（i-1,j）格开始向上能炸死的敌人数 + 1\n（i,j）是墙：0\n\n原来要求（i,j）格子放炸弹向上能炸死的敌人数，子问题就转化为（i-1,j）格向上能炸死的敌人数，上述三种情况就如下：\n\nUp[i][j] = Up[i-1][j]，(i,j)是空地的情况\nUp[i][j] = Up[i-1][j] + 1，(i,j)是敌人的情况\nUp[i][j] = 0，(i,j)是墙的情况\n\n初始条件就是第0行，如果是敌人，向上炸死人数为1，如果是空地或墙，向上炸死人数为0。\n另外三个方向Down[i][j], Left[i][j], Right[i][j]也是一样考虑。炸死的敌人数就是四个方向加起来，每次更新一下最大值。\npublic static int maxKilledEnemies(char[][] grid) {        if (grid == null || grid.length == 0 || grid[0].length == 0) {            return 0;        }        int m = grid.length;        int n = grid[0].length;        int[][] up = new int[m][n];        int[][] down = new int[m][n];        int[][] left = new int[m][n];        int[][] right = new int[m][n];        int[][] dp = new int[m][n];        for (int i = 0; i &lt; m; i++) {            for (int j = 0; j &lt; n; j++) {                //i,j处为炸弹放置的位置                //如果是墙,其实四种情况都是0                if (grid[i][j] == 'W') {                    up[i][j] = 0;                    continue;                }                up[i][j] = grid[i][j] == 'E' ? 1 : 0;                if (i &gt; 0) {                    up[i][j] += up[i - 1][j];                }            }        }        //down应该从下往上算，自底向上        for (int i = m - 1; i &gt;= 0; i--) {            for (int j = 0; j &lt; n; j++) {                if (grid[i][j] == 'W') {                    down[i][j] = 0;                    continue;                }                down[i][j] = grid[i][j] == 'E' ? 1 : 0;                if (i &lt; m - 1) {                    down[i][j] += down[i + 1][j];                }            }        }        //left，从左往右算        for (int i = 0; i &lt; m; i++) {            for (int j = 0; j &lt; n; j++) {                if (grid[i][j] == 'W') {                    left[i][j] = 0;                    continue;                }                left[i][j] = grid[i][j] == 'E' ? 1 : 0;                if (j &gt; 0) {                    left[i][j] += left[i][j - 1];                }            }        }        //right，从右往左算        for (int i = 0; i &lt; m; i++) {            for (int j = n - 1; j &gt;= 0; j--) {                if (grid[i][j] == 'W') {                    right[i][j] = 0;                    continue;                }                right[i][j] = grid[i][j] == 'E' ? 1 : 0;                if (j &lt; n - 1) {                    right[i][j] += right[i][j + 1];                }            }        }        //结果填充dp        int res = Integer.MIN_VALUE;        for (int i = 0; i &lt; m; i++) {            for (int j = 0; j &lt; n; j++) {                //只有在空地能放炸弹                if (grid[i][j] == '0') {                    dp[i][j] = up[i][j] + down[i][j] + left[i][j] + right[i][j];                    if (dp[i][j] &gt; res) {                        res = dp[i][j];                    }                }            }        }        if (res != Integer.MIN_VALUE) {            return res;        } else {            return 0;        }    }\n\n","categories":["Algorithm"],"tags":["Dynamic programming"]},{"title":"博弈型动态规划","url":"/2019/12/02/dp-game/","content":"动态规划：博弈型博弈型dp一般从第一步分析，而不是最后一步，需要开n+1\n1、LintCode 394 Coins in a Line【问题】有 n 个硬币排成一条线。两个参赛者轮流从右边依次拿走 1 或 2 个硬币，直到没有硬币为止。拿到最后一枚硬币的人获胜。请判定 先手玩家必胜还是必败?\n【分析】从第一步开始，一开始有n个硬币，A可以拿一个或两个硬币，这样B则对应拿n-1个或n-2个硬币，A肯定会采取策略让自己获胜。然后不断拿。假设一开始有5个硬币，可以画出如果所示的树形结构，必败就是自己无路可逃，必胜就是有赢的可能。\n\n【状态】设dp[i]表示面对i个硬币，是否先手必胜则有下面几种情况\n\ndp[i] = true，f[i-1]==false || f[i-2]==false（对手拿1个或2个都是必败的情况）\ndp[i] = false，f[i-1]==true &amp;&amp; f[i-2]==true（对手拿1个或2个都是必胜的情况）\n\n【初始情况与边界】\n\ndp[0] = 0，面对0个硬币，必败\ndp[1] = dp[2] = true\n\npublic boolean firstWillWin(int n) {        if (n == 0) {            return false;        }        if (n &lt;= 2) {            return true;        }        boolean[] dp = new boolean[n + 1];        dp[0] = false;        dp[1] = true;        for (int i = 2; i &lt;= n; i++) {            // if (dp[i - 1] == true &amp;&amp; dp[i - 2] == true) {            //     dp[i] = false;            // } else {            //     dp[i] = true;            // }            dp[i] = !dp[i - 1] || !dp[i - 2];        }        return dp[n];    }\n\n","categories":["Algorithm"],"tags":["Dynamic programming"]},{"title":"区间型动态规划","url":"/2019/12/10/dp-interval/","content":"动态规划：区间型背景：给定一个序列或字符串要进行一些操作，最后一步要将序列或字符串去头、去尾，区间[i,j]变为区间[i+1,j-1]，力扣上面的最长回文子串就是这样子操作。区间型dp一般用dp[i] [j]，i代表左端点，j代表右端点，若有其他维度可再添加，若两个端点之间存在联系，则可再压缩空间。\n区间型dp不开n+1，开n，区间型dp要按照长度去算。不能按照i，要按照j-i。\n1、LintCode 667 Longest Palindromic Subsequence【问题】给一字符串 s,，找出在 s 中的最长回文子序列的长度.。你可以假设 s 的最大长度为 1000。\n【分析】注意区分子串和子序列，子串是连续的，子序列可以不连续，这个题是子序列，可以不连续。从最后一步出发，假设S是最长回文子序列，长度为len，分析这个子序列有两种情况\n\n子序列长度为1，只有一个字母\n子序列长度大于1，必有S[0] = S[len-1]\n\nS是在区间[i,j]中的最长回文子串，对于最长子序列S去头去尾后S[1..len-2]仍然是一个回文串，并且是在区间[i+1,j-1]中的最长回文子序列（应该说是在在长度为j-i+1 - 2时的最长回文子序列），并且可以得出S[i,j] = S[i+1,j-1] + 2\n【转移方程】头尾不想等，去头、去尾各一种情况；头尾相等，同时去头去尾\n\ndp[i][j] = max{dp[i+1][j],dp[i][j-1],dp[i+1][j-1]+2 &amp;&amp; chs[i] == chs[j]}\n\n【初始条件】\n\ndp[0][0] = dp[1][1] = ...=dp[n-1][n-1] = 1，每个字母都是长度为1的回文串\n不能按照i去算，要按照长度len去算\n\n【答案】dp[0][n-1] 两个端点,画出图来就是右上三角\npublic int longestPalindromeSubseq(String s) {        int n = s.length();        char[] chs = s.toCharArray();        if (n &lt;= 1) {            return n;        }        int[][] dp = new int[n][n];        for (int i = 0; i &lt; n; i++) {            dp[i][i] = 1;        }        //region length : 2 &lt;= len &lt;= n        for (int len = 2; len &lt;= n; len++) {            //startIndex i &lt;= n - len            for (int i = 0; i &lt;= n - len; i++) {                int j = i + len - 1;                dp[i][j] = Math.max(dp[i + 1][j], dp[i][j - 1]);                if (chs[i] == chs[j]) {                    dp[i][j] = Math.max(dp[i][j], dp[i + 1][j - 1] + 2);                }            }        }        return dp[0][n - 1];    }\n\n要求打印路径\n//要求打印出路径    public int LPS(String s) {        char[] chs = s.toCharArray();        int n = chs.length;        if (n == 0) {            return 0;        }        if (n == 1) {            return 1;        }        int[][] dp = new int[n][n];        int[][] path = new int[n][n];   //路径数组        for (int i = 0; i &lt; n; i++) {            dp[i][i] = 1;        }        for (int len = 2; len &lt;= n; len++) {            for (int i = 0; i &lt;= n - len; i++) {                int j = i + len - 1;                dp[i][j] = Math.max(dp[i + 1][j], dp[i][j - 1]);                //去头记为0                if (dp[i][j] == dp[i + 1][j]) {                    path[i][j] = 0;                }                //去尾记为1                if (dp[i][j] == dp[i][j - 1]) {                    path[i][j] = 1;                }                //相等记为2                if (chs[i] == chs[j]) {                    dp[i][j] = Math.max(dp[i][j], dp[i + 1][j - 1] + 2);                    if (dp[i][j] == dp[i + 1][j - 1] + 2) {                        path[i][j] = 2;                    }                }            }        }        //最长的长度为dp[0][n - 1]        char[] res = new char[dp[0][n - 1]];        //开始与结束两个指针        int p = 0, q = dp[0][n - 1] - 1;        //chs数组的两个指针        int i = 0, j = n - 1;        //从两头分别往中间去走        while (i &lt;= j) {            //如果字符串长度为1            if (i == j) {                res[p] = chs[i];                break;            }            //如果字符串长度为2            if (i + 1 == j) {                res[p] = chs[i];                res[q] = chs[j];                break;            }            //其他情况,如果来自去头的情况            if (path[i][j] == 0) {                i++;            } else {                if (path[i][j] == 1) {  //如果来自去尾的情况                    --j;                } else {                    res[p++] = chs[i++];                    res[q--] = chs[j--];                }            }        }        for (int k = 0; k &lt; res.length; k++) {            System.out.print(res[k]);        }        return dp[0][n - 1];    }\n\n使用记忆化搜索优化，记忆化搜索使用递归，自上而下，递推是自下而上。\nint[][] dp = null;    char[] chs = null;    int n;    private void compute(int i, int j) {        //如果算过了就直接返回        if (dp[i][j] != -1) {            return;        }        if (i == j) {            dp[i][j] = 1;            return;        }        //first recursion        compute(i + 1, j);        compute(i, j - 1);        compute(i + 1, j - 1);        //then dp        dp[i][j] = Math.max(dp[i + 1][j], dp[i][j - 1]);        if (chs[i] == chs[j]) {            dp[i][j] = Math.max(dp[i][j], dp[i + 1][j - 1] + 2);        }    }    public int longestPalindromeSubseq(String s) {        chs = s.toCharArray();        n = chs.length;        if (n == 0) {            return 0;        }        dp = new int[n][n];        //初始化所有格子标记为没有被访问过        for (int i = 0; i &lt; n; i++) {            for (int j = i; j &lt; n; j++) {                dp[i][j] = -1;            }        }        compute(0, n - 1);      //通过递归的方式来填充f数组        return dp[0][n - 1];    }\n\n2、LintCode 200 Longest Palindromic Substring【问题】给出一个字符串（假设长度最长为1000），求出它的最长回文子串，你可以假定只有一个满足条件的最长回文串。\n【分析】一种方法是中心扩展法，另一种以区间型dp来做，假设最长回文字串是s(i,j),那么它的去头去尾的子串s'(i+1..j-1)也是在这个区间内的最长回文子串。假设最长回文子串的长度为len，len的范围是0 &lt;= len &lt;= n，枚举len，只需要记录最长的长度以及起点，就能得到子串。\npublic static String longestPalindrome2(String s) {        int n = s.length();        char[] chs = s.toCharArray();        boolean[][] dp = new boolean[n][n];        int start = 0;        int longest = 1;        //初始化        for (int i = 0; i &lt; n; i++) {            dp[i][i] = true;        }        //要单独处理下相邻的        for (int i = 0; i &lt; n - 1; i++) {            dp[i][i + 1] = chs[i] == chs[i + 1];            if (dp[i][i + 1]) {                longest = 2;                start = i;            }        }        //长度从3开始        for (int len = 3; len &lt;= n; len++) {            for (int i = 0; i &lt;= n - len; i++) {                int j = i + len - 1;                if (dp[i + 1][j - 1] &amp;&amp; chs[i] == chs[j]) {                    dp[i][j] = true;                }                if (dp[i][j] &amp;&amp; len &gt; longest) {                    longest = len;                    start = i;                }            }        }        return s.substring(start, start + longest);    }\n\n3、LintCode 396 Coins In A Line III——博弈+区间【问题】给定一个序列a[0], a[1], …, a[N-1]，两个玩家Alice和Bob轮流取数，每个人每次只能取第一个数或最后一个数，双方都用最优策略，使得自己的数字和尽量比对手大，问先手是否必胜。（如果数字和一样，也算是先手胜）\n【分析】不需要存己方数字和与对方数字和，只需记录差。两个人都记录着自己与对方的数字之差：SA = A - B，SB = B - A。A取走一个数字m后，B就变为先手，他想要最大化SB = B-A，对于A来说，此时SA = -SB+m，m就是当前这步的数字，m可能是头也可能是尾，选择能最大化SA的即可。取走之后对手也同样采取最优策略去拿。\n【转移方程】\n\n状态：A先手取头，a[0],B此时最大数字差为SB，此时最大数字差为-SB+a[0]\n\n状态：A先手取尾，a[n-1],B此时最大数字差为SB，此时最大数字差为-SB+a[n-1]\n\n方程：dp[i][j] = max{a[i] - dp[i+1][j],a[j] - dp[i][j-1]}\n\n\n【答案】dp[0][n-1] &gt;= 0 则先生胜  \npublic boolean firstWillWin(int[] A) {        int n = A.length;        int[][] dp = new int[n][n];        for (int i = 0; i &lt; n; i++) {            dp[i][i] = A[i];        }        //枚举长度        for (int len = 2; len &lt;= n; len++) {            for (int i = 0; i &lt;= n - len; i++) {                int j = i + len - 1;                dp[i][j] = Math.max(A[i] - dp[i + 1][j], A[j] - dp[i][j - 1]);            }        }        return dp[0][n - 1] &gt;= 0;    }\n\n4、LintCode 430 Scramble String【问题】攀爬字符串。给定一个字符串S，按照树结构每次二分成左右两个部分，直至单个字符，在树上某些节点交换左右儿子，可以形成新的字符串，判断一个字符串T是否由S经过这样的变换而成。\n下面是 s1 = \"great\" 可能得到的一棵二叉树:\n    great   /    \\  gr    eat / \\    /  \\g   r  e   at           / \\          a   t\n\n在攀爬字符串的过程中, 我们可以选择其中任意一个非叶节点, 交换该节点的两个子节点.\n例如，我们选择了 \"gr\" 节点,，并将该节点的两个子节点进行交换，并且将祖先节点对应的子串部分也交换,，最终得到了 \"rgeat\"。 我们认为 \"rgeat\" 是 \"great\" 的一个攀爬字符串。\n    rgeat   /    \\  rg    eat / \\    /  \\r   g  e   at           / \\          a   t\n\n类似地, 如果我们继续将其节点 \"eat\" 和 \"at\" 的子节点交换， 又可以得到 \"great\" 的一个攀爬字符串 \"rgtae\"。\n   rgtae   /    \\  rg    tae / \\    /  \\r   g  ta   e       / \\      t   a\n\n给定两个相同长度的字符串 s1 和 s2，判断 s2 是否为 s1 的攀爬字符串。\n【分析】给定两个字符串T和S，假设T是由S变换而来\n\n如果T和S长度不一样，必定不能变来\n如果长度一样，顶层字符串S能够划分为S1和S2，同样字符串T也能够划分为T1和T2\n情况一：没交换，S1 ==&gt; T1，S2 ==&gt; T2\n情况二：交换了，S1 ==&gt; T2，S2 ==&gt; T1\n\n\n子问题就是分别讨论两种情况，T1是否由S1变来，T2是否由S2变来，或 T1是否由S2变来，T2是否由S1变来。\n\n\n【状态】dp[i][j][k][h]表示T[k..h]是否由S[i..j]变来。由于变换必须长度是一样的，因此这边有个关系j - i = h - k，可以把四维数组降成三维。dp[i][j][len]  表示从字符串S中i开始长度为len的字符串是否能变换为从字符串T中j开始长度为len的字符串\n\ndp[i] [j] [k] = OR1&lt;=w&lt;=k-1{dp[i] [j] [w] AND dp[i+w] [j+w] [k-w]}  或 OR1&lt;=w&lt;=k-1{dp[i] [j+k-w] [w] AND dp[i+w] [j] [k-w]}\n枚举S1长度w（1～k-1，因为要划分），f[i] [j] [w]表示S1能变成T1，f[i+w] [j+w] [k-w]表示S2能变成T2，或者是S1能变成T2，S2能变成T1。\n\n【初始条件】对于长度是1的子串，只有相等才能变过去，相等为true，不相等为false。\n【答案】dp[0][0][n]\npublic boolean isScramble(String s1, String s2) {        char[] chs1 = s1.toCharArray();        char[] chs2 = s2.toCharArray();        int n = s1.length();        int m = s2.length();        if (n != m) {            return false;        }        boolean[][][] dp = new boolean[n][n][n + 1];        //初始化单个字符的情况        for (int i = 0; i &lt; n; i++) {            for (int j = 0; j &lt; n; j++) {                dp[i][j][1] = chs1[i] == chs2[j];            }        }        //枚举长度2～n        for (int len = 2; len &lt;= n; len++) {            //枚举S中的起点位置            for (int i = 0; i &lt;= n - len; i++) {                //枚举T中的起点位置                for (int j = 0; j &lt;= n - len; j++) {                    //枚举划分位置                    for (int k = 1; k &lt;= len - 1; k++) {                        //第一种情况：S1-&gt;T1,S2-&gt;T2                        if (dp[i][j][k] &amp;&amp; dp[i + k][j + k][len - k]) {                            dp[i][j][len] = true;                            break;                        }                        //第二种情况：S1-&gt;T2,S2-&gt;T1                        if (dp[i][j + len - k][k] &amp;&amp; dp[i + k][j][len - k]) {                            dp[i][j][len] = true;                            break;                        }                    }                }            }        }        return dp[0][0][n];    }`\n\n5、LintCode 168 Burst Balloons【问题】有n个气球，编号为0到n-1，每个气球都有一个分数，存在nums数组中。每次吹气球i可以得到的分数为 nums[left] * nums[i] * nums[right]，left和right分别表示i气球相邻的两个气球。当i气球被吹爆后，其左右两气球即为相邻。要求吹爆所有气球，得到最多的分数。（最后一个气球被扎破即它本身，算作1 * nums[i] * 1）\n【分析】区间型dp，从最后一步出发，最后一步必定扎破一个气球，编号为i，这一步获得金币1*  nums[i] * 1，此时i前面的气球1～i-1以及i后面的气球i+1～n都被扎破了，需要知道两边最多能获得多少个金币，再加上最后一步，就是结果。\n【状态转移方程】由于最后一步是1 * nums[i] * 1，我们可以认为两端有两个不能扎破的气球，值为1，dp[i] [j]代表扎破i+1号气球～j-1号气球能获得的金币数，i和j是不能被扎破的，因为是两端，并且当前气球k不能被扎破，要分别考虑k的左侧（i～k-1）和右侧（k+1～j），状态转移方程为：\n\ndp[i][j] = max{dp[i][k] + dp[k][j] + a[i] * a[k] * a[j]},k∈(i,j)\ndp[i] [k]代表扎破i+1～k-1号气球，dp[k] [j]代表扎破k+1～j-1号气球，再加上扎破这个气球获得的金币数\n\n【初始条件】没有气球要扎破就获得0个金币\n\ndp[0][1] = dp[1][2] = ... = dp[n-2][n-1] = 0\n\npublic static int maxCoins(int[] nums) {        int n = nums.length;        int[] A = new int[n + 2];   //左右两个不能扎破的        A[0] = A[n + 1] = 1;        for (int i = 0; i &lt; n; i++) {            A[i + 1] = nums[i];        }        n += 2;        int[][] dp = new int[n][n];        //初始化没有气球要扎破的情况        for (int i = 0; i &lt; n - 1; i++) {            dp[i][i + 1] = 0;        }                //从长度为3开始        for (int len = 3; len &lt;= n; len++) {            //开头            for (int i = 0; i &lt;= n - len; i++) {                //结尾                int j = i + len - 1;                dp[i][j] = Integer.MIN_VALUE;                //枚举中间的气球 作为不扎破的气球                for (int k = i + 1; k &lt;= j - 1; k++) {                    dp[i][j] = Math.max(dp[i][j], dp[i][k] + dp[k][j] + A[i] * A[k] * A[j]);                }            }        }        return dp[0][n-1];    }\n\n\n\n","categories":["Algorithm"],"tags":["Dynamic programming"]},{"title":"划分型动态规划","url":"/2019/12/02/dp-split/","content":"动态规划：划分型划分型动态规划就是给定长度为N的字符串，需要划分成若干段，段数不限，每一段满足一定的性质。在学校oj中做过的书本分发、漆狗屋这种就属于划分型。开数组也是开n+1\n1、Lintcode 512 解码方法【问题】有一个消息包含A-Z通过以下规则编码：’A’ -&gt; 1，’B’ -&gt; 2…’Z’ -&gt; 26，现在给你一个加密过后的消息，问有几种解码的方式。\n输入: \"12\"输出: 2解释: 它可以被解码为 AB (1 2) 或 L (12).\n\n【分析】从最后一步出发，最后一个或两个数字对应一个字母。给定字符串长度为N，需要球它的解密方式有多少种，那就需要知道前N-1个数字有多少种解密方式，以及前N-2个数字有多少种解密方式，这就是子问题。\n【状态转移方程】dp[i] = dp[i-1] + dp[i-2] (最后两个字母范围为10~26) \npublic static int numDecodings(String s) {        char[] chs = s.toCharArray();        int n = chs.length;        if (n == 0) {            return 0;        }        int[] dp = new int[n + 1];        dp[0] = 1;  //空串也算一种        for (int i = 1; i &lt;= n; i++) {            //一位数必须要在1～9，0是不算的            if (chs[i - 1] != '0') {                dp[i] += dp[i - 1];            }            if (i &gt;= 2) {                int num = (chs[i - 2] - '0') * 10 + (chs[i - 1] - '0');                if (num &gt;= 10 &amp;&amp; num &lt;= 26) {                    dp[i] += dp[i - 2];                }            }        }        return dp[n];    }\n\n2、Lintcode 513 Perfect Squares【问题】给一个正整数 n, 请问最少多少个完全平方数(比如1, 4, 9…)的和等于n。\n【分析】重点关注最后一个完全平方数 j^2^，n - j^2^ 也是被分成最少的完全平方数之和，这就是子问题\n\ndp[i] 就代表i最少被分成几个完全平方数之和，dp[i] = min{dp[i - j^2]+1}\n\npublic int numSquares(int n) {        int[] dp = new int[n + 1];        dp[0] = 0;        for (int i = 1; i &lt;= n; i++) {            dp[i] = Integer.MAX_VALUE;            //j必须从1开始，如果不从1开始，dp[i],dp[i]+1会越界            for (int j = 1; j * j &lt;= i; j++) {                dp[i] = Math.min(dp[i], dp[i - j * j] + 1);            }        }        return dp[n];    }\n\n3、Lintcode 108 Palindrome Partitioning II【问题】给定字符串 s, 需要将它分割成一些子串， 使得每个子串都是回文串，最少需要分割几次?\n【分析】从最后一步出发，假设最后一段回文串为s[j…n-1]，需要知道s中前j个字符[0…j-1]最少可以划分成多少个回文串，这就是子问题。\n\ndp[i] = min{dp[j]} + 1(0 &lt;= j &lt; i &amp;&amp; s[j…i-1]为回文串的情况下)\n初始条件：空串可以被划分为0个回文串\n\n下面这么写，超时\npublic int minCut(String s) {        int n = s.length();        if (n == 0) {            return 0;        }        int[] dp = new int[n + 1];        dp[0] = 0;        for (int i = 1; i &lt;= n; i++) {            dp[i] = Integer.MAX_VALUE;            for (int j = 0; j &lt; i; j++) {                //如果最后一段是回文串                if (isPalindrome(s.substring(j, i))) {                    dp[i] = Math.min(dp[i], dp[j] + 1);                }            }        }        //问的是切几刀，刀数 = 段数 - 1，比如aab，分两段，切1刀        return dp[n] - 1;    }    public boolean isPalindrome(String s) {        return new StringBuilder(s).reverse().toString().equals(s);    }\n\n需要把所有的回文串保存在二维数组中，这样不用每次再去判断是否为回文串\n时间复杂度O(N^2^)，空间复杂度O(N^2^)\npublic int minCut(String s) {        char[] chs = s.toCharArray();        int n = chs.length;        if (n == 0) {            return 0;        }        boolean[][] isPalindrome = calcPalindrome(chs);   //判断是否为回文串        int[] dp = new int[n + 1];        dp[0] = 0;  //前0个回文串分割0个        for (int i = 1; i &lt;= n; i++) {            dp[i] = Integer.MAX_VALUE;            for (int j = 0; j &lt; i; j++) {                //如果j到i-1是回文串，就更新                if (isPalindrome[j][i - 1]) {                    dp[i] = Math.min(dp[i], dp[j] + 1);                }            }        }        //aab，分成两段回文串只要切一刀，段数 - 1        return dp[n] - 1;    }    //利用二维数组，不用每次去判断是不是回文串    public boolean[][] calcPalindrome(char[] chs) {        int n = chs.length;        boolean[][] f = new boolean[n][n];                //初始化        for (int i = 0; i &lt; n; i++) {            for (int j = i; j &lt; n; j++) {       //从i到j是否为回文串，所以j是从i开始                f[i][j] = false;            }        }        //生成回文串的过程，如果回文串长度是奇数，那就是由中心点向两边生成，如果回文串长度是偶数，那就是由中心线向两边生成        //奇数的情况，c为中心center,共n个中心点        for (int c = 0; c &lt; n; c++) {            int i = c, j = c;            while (i &gt;= 0 &amp;&amp; j &lt; n &amp;&amp; chs[i] == chs[j]) {                f[i][j] = true;                i--;                j++;            }        }        //偶数的情况，共n-1条中心线        for (int c = 0; c &lt; n; c++) {            int i = c, j = c + 1;            while (i &gt;= 0 &amp;&amp; j &lt; n &amp;&amp; chs[i] == chs[j]) {                f[i][j] = true;                i--;                j++;            }        }        return f;    }\n\n4、LintCode 437 Copy Books书本分发、漆狗屋这类题，在学校OJ做烂掉了。这个题也能二分法做。\n【问题】给定 n 本书, 第 i 本书的页数为 pages[i]。 现在有 k 个人来复印这些书籍,，而每个人只能复印编号连续的一段的书, 比如一个人可以复印 pages[0], pages[1], pages[2], 但是不可以只复印 pages[0], pages[2], pages[3]而不复印 pages[1]。所有人复印的速度是一样的,，复印一页需要花费一分钟, 并且所有人同时开始复印. 怎样分配这 k 个人的任务, 使得这 n 本书能够被尽快复印完?返回完成复印任务最少需要的分钟数。\n【分析】当有i个抄写员的时候，一共n本书，从最后一步出发，第i个抄写员抄几本书，可能是0～n本，假设第i个抄写员抄写j本，前i-1个抄写员一共抄写n-j本书。前i-1个抄写员抄写完耗时T1，第i个抄写员抄写完耗时T2，i个人抄完n本书，花费的时间是max(T1,T2)，我们要求所有分配情况下，抄完书的最小时间花费。\n![\n//k个抄写员    private static int solve(int[] nums, int k) {        int n = nums.length;    //一共几本书        if (n == 0) {            return 0;        }        int[][] dp = new int[k + 1][n + 1];        //初始化：k个抄写员抄写0本书，花费时间都是0        for (int i = 0; i &lt;= k; i++) {            dp[i][0] = 0;        }        //初始化：0个抄写员抄写0本书，花费时间是0，0个抄写员抄写1本、2本。。。花费时间无穷大        for (int i = 1; i &lt;= n; i++) {            dp[0][i] = Integer.MAX_VALUE;        }        //一共前i个抄写员        for (int i = 1; i &lt;= k; i++) {            //前i个抄写员一共抄写j本书            for (int j = 1; j &lt;= n; j++) {                dp[i][j] = Integer.MAX_VALUE;                int sum = 0;                //前i-1个抄写员抄写l本书，l从j开始，也就是先让最后一个人从0本开始，然后累加，这样就不用额外去计算这个人抄写花费的时间                for (int l = j; l &gt;= 0; l--) {                    dp[i][j] = Math.min(dp[i][j], Math.max(dp[i - 1][l], sum));                    if (l &gt; 0) {                        sum += nums[l-1];                    }                }            }        }        return dp[k][n];    }\n二分法，二分可能的答案。每次判断什么呢？判断k个人能不能在这个时间（mid）里搞定\n//二分，时间复杂度O(nlogm), n:书本数目, m:总页数。public static int copyBooks(int[] pages, int k) {    // 假设的做二分查找的区间是 0 ～ max    int start = 0, end = 0; //end为所有书都由一个人抄    for (int i = 0; i &lt; pages.length; i++) {        end += pages[i];    }    //log page，N本书for检查一遍,O(n)    while (start + 1 &lt; end) {        int mid = start + (end - start) / 2;        //如果k个人能在mid时间内搞定，说明我们可以继续 【缩短】 时间，而不是提高时间！！！        if (check(pages, mid, k)) {            end = mid;        } else {            start = mid;        }    }    //double check start    if (check(pages, start, k)) {        return start;    } else {        return end;    }}private static boolean check(int[] pages, int limit, int k) {    int num = 1;    //所需人数    int count = 0;  //每个人工作了多久    for (int page : pages) {        if (page &gt; limit) {     //一定要判断一下！！！            return false;        }        if (count + page &gt; limit) {            num++;            count = 0;        }        count += page;    }    return num &lt;= k;}\n\n","categories":["Algorithm"],"tags":["Dynamic programming"]},{"title":"前缀和","url":"/2019/12/02/prefixsum/","content":"前缀和最近刷了几个前缀和的题，也都是板子题，记录一下\nLeetCode 560. 和为K的子数组\n给定一个整数数组和一个整数 k，你需要找到该数组中和为 k 的连续的子数组的个数。\n示例 1 :\n输入:nums = [1,1,1], k = 2输出: 2 , [1,1] 与 [1,1] 为两种不同的情况。\n\n说明 :\n\n数组的长度为 [1, 20,000]。\n数组中元素的范围是 [-1000, 1000] ，且整数 k 的范围是 [-1e7, 1e7]。\n\n\n这个题直接前缀和就能过，下面一种不好的暴力求法，虽然能过，但是巨慢\npublic static int subarraySum(int[] nums, int k) {       int n = nums.length;       int[] ps = new int[n + 1];       for (int i = 1; i &lt;= n; i++) {           ps[i] = nums[i - 1] + ps[i - 1];       }       int res = 0;;       for (int s = 0; s &lt; n; s++) {           for (int e = s + 1; e &lt;= n; e++) {               if (ps[e] - ps[s] == k) {                   res++;               }           }       }       return res;   }\n\n但实际上，我们要看ps[j] - ps[i] = k，那么[i,j]就是我们需要的区间，所以我们对于每个j，我们只要计算有多少个 i 使得 ps[j] - ps[i] = k，这样我们就得到了以 P[j] 作为右区间并且和为 k的区间数。这里用个 hashmap 统计  ps[i] 即可。但是要注意初始化map的细节，要放一个 {0:1}进去，当 ps[j]==k 时，ps[i]=0 ，此时是要算进结果的\npublic static int subarraySum(int[] nums, int k) {       int res = 0;       int curSum = 0;       HashMap&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;();       map.put(0, 1);       for (int i = 0; i &lt; nums.length; i++) {           curSum += nums[i];           if (map.containsKey(curSum - k)) {               res += map.get(curSum - k);           }           map.put(curSum, map.getOrDefault(curSum, 0) + 1);       }       return res;   }\n\n\n\nLeetCode 974. 和可被 K 整除的子数组\n给定一个整数数组 A，返回其中元素之和可被 K 整除的（连续、非空）子数组的数目。\n示例：\n输入：A = [4,5,0,-2,-3,1], K = 5输出：7解释：有 7 个子数组满足其元素之和可被 K = 5 整除：[4, 5, 0, -2, -3, 1], [5], [5, 0], [5, 0, -2, -3], [0], [0, -2, -3], [-2, -3]\n\n这个题，暴力前缀和就不合适了，有什么好的方法呢？\n我们要判断的是(ps[j] - ps[i]) % K是否等于0。那么根据取余的性质，(ps[j] - ps[i]) % K = ps[j] % K - ps[i] % K，所以，若要(ps[j] - ps[i] )% K = 0只要 ps[j] % K = ps[i] % K，以ps[i] % K作为键值统计其出现的频率，从而对于每个下标 j 我们可以立即获得能和它组成满足要求的子数组的开始下标 i 的数量。生成前缀和数组的过程中，将 key = ps[j]% k 出现的频率加入结果数组， 同时将 key = ps[j] % k 的出现频率加1。\n由于数组中有可能出现负数，需要将其加 K ，使其 %K 之后的值为正数。\npublic int subarraysDivByK(int[] A, int k){       int n = A.length, res = 0, sum = 0;       int[] map = new int[k];       map[0] = 1;       for (int i = 0; i &lt; n; i++) {           sum += A[i];           int key = (sum % k + k) % k;           //在加进去前先统计下数量           res += map[key];           map[key]++;       }       return res;   }\n\nclass Solution:    def subarraysDivByK(self, A: List[int], K: int) -&gt; int:        n, res, sum, dict = len(A), 0, 0, collections.defaultdict(int)        dict[0] = 1        for i in range(n):            sum += A[i]            key = (sum % K + K) % K            res += dict[key]            dict[key] += 1        return res\n\n\n\nLeetCode 1074. 元素和为目标值的子矩阵数量\n给出矩阵 matrix 和目标值 target，返回元素总和等于目标值的非空子矩阵的数量。\n子矩阵 x1, y1, x2, y2 是满足 x1 &lt;= x &lt;= x2 且 y1 &lt;= y &lt;= y2 的所有单元 matrix[x][y] 的集合。\n如果 (x1, y1, x2, y2) 和 (x1’, y1’, x2’, y2’) 两个子矩阵中部分坐标不同（如：x1 != x1’），那么这两个子矩阵也不同。\n示例 1：\n输入：matrix = [[0,1,0],[1,1,1],[0,1,0]], target = 0输出：4解释：四个只含 0 的 1x1 子矩阵。\n\n示例 2：\n输入：matrix = [[1,-1],[-1,1]], target = 0输出：5解释：两个 1x2 子矩阵，加上两个 2x1 子矩阵，再加上一个 2x2 子矩阵。\n\n提示：\n1 &lt;= matrix.length &lt;= 3001 &lt;= matrix[0].length &lt;= 300-1000 &lt;= matrix[i] &lt;= 1000-10^8 &lt;= target &lt;= 10^8\n\n这个题，一看就是二维前缀和，所谓二维前缀和就是，对于每一行从前向后累加，对于每一列从前向后累加，得到的矩阵就是前缀和矩阵。\n当我们构建好了二维前缀和，想要求 (i1,j1) 为左上角，(i2,j2) 为右下角的矩阵的内部和的时候，是这么一张图。要求 S4，实际上就是（S1+S2+S3+S4），也就是 S(0,0,i2,j2)，这么一整块大的，减去 S2+S1 ，减去 S3+S1 ，再加上 S1。因为单个的 S2 和 S3 我们是不好算的，但是S1+S2、S1+S3是很好算的。\n\n如果直接莽，那时间复杂度是 ，需要继续优化，这个题和 560题 差不多吧，之前是一维问题，现在是二维问题，但是处理思想是一样的。要将二维转化为一维，此时我们只要计算每一行的前缀和，而不是整个矩阵的前缀和。然后可以取不同的两个列 (j1,j2)，以这两个列为边界，计算每一行的前缀和，这就是二维前缀和。\n那么我们固定好左右边界后，遍历每一行，记录每一行的前缀和，以及它出现的次数，放在map中，那么对于当前行的前缀和，我们只要看map里有没有curSum - target，有的话加上它的出现次数即可。\n注意，map初始化也要放入{0:1}\njava 代码\npublic int numSubmatrixSumTarget(int[][] mat, int target) {       int n = mat.length;       int m = mat[0].length;       for (int i = 0; i &lt; n; i++) {           for (int j = 1; j &lt; m; j++) {               mat[i][j] += mat[i][j - 1];           }       }       int res = 0;       int cur = 0;       Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;();       //枚举两列       //第i列       for (int j1 = 0; j1 &lt; m; j1++) {            //第j列           for (int j2 = j1; j2 &lt; m; j2++) {               map.clear();               //矩阵为空的情况               map.put(0, 1);               cur = 0;               //枚举行数               for (int i = 0; i &lt; n; i++) {                   cur += mat[i][j2] - (j1 &gt; 0 ? mat[i][j1 - 1] : 0);                   res += map.getOrDefault(cur - target, 0);                   map.put(cur, map.getOrDefault(cur, 0) + 1);               }           }       }       return res;   }\n\npython 代码\nclass Solution:    def numSubmatrixSumTarget(self, mat: List[List[int]], target: int) -&gt; int:        res, n, m = 0, len(mat), len(mat[0])        # 首先计算每行的前缀和        for i in range(n):            for j in range(1, m):                mat[i][j] += mat[i][j - 1]        # 枚举两列        for j1 in range(m):            for j2 in range(j1,m):                dict = collections.defaultdict(int)                dict[0] = 1                cur_sum = 0                # 枚举每一行                for i in range(n):                    cur_sum += mat[i][j2] - (mat[i][j1 - 1] if j1 &gt; 0 else 0)                    res += dict[cur_sum - target]                    dict[cur_sum] += 1        return res\n\n\n\nLeetCode 363. 矩形区域不超过 K 的最大数值和\n给定一个非空二维矩阵 matrix 和一个整数 k，找到这个矩阵内部不大于 k 的最大矩形和。\n示例:\n输入: matrix = [[1,0,1],[0,-2,3]], k = 2输出: 2 解释: 矩形区域 [[0, 1], [-2, 3]] 的数值和是 2，且 2 是不超过 k 的最大数字（k = 2）。\n\n说明：\n\n矩阵内的矩形区域面积必须大于 0。\n如果行数远大于列数，你将如何解答呢？\n\n\n这个题就和上一个题太像了，几乎一致，1074 是找面积等于 k 的，这个题是找小于等于 k 的最大矩形和，但是也没给数据范围，直接莽的话 吧，不太合适，还是要转成先求行的前缀和，再枚举两列、枚举行来求，固定左右边界，只考虑行，在哪两个行之间组成矩形的面积最大。如果是和1074一样用map的话，我怎么找到当前情况下，某个值 + curSum &lt;= k？直接遍历，那就不好了，为了加快查找！那么这里就要用到 TreeSet 的 ceiling() 了，之前在 300 题也用过，ceiling()  方法返回的是大于这个值的最小值，如果不存在返回null。\n用 set 保存之前的子矩阵的和 sum，然后在 set 中找出大于等于（sum - k）的最小值。set中都是存放的是起始列和中止列相同的矩阵的和，求出 set 中大于等于（curSum - k）最小值，设找到的数为 c，则 c &gt;= cur-k，必有 cur - c &lt;= k，所有最小的 c，使得 cur-c的值最大，且该值小于等于k，妙啊\njava 代码\npublic int maxSumSubmatrix(int[][] mat, int k) {       int n = mat.length;       int m = mat[0].length;       //首先计算每一行的前缀和       for (int i = 0; i &lt; n; i++) {           for (int j = 1; j &lt; m; j++) {               mat[i][j] += mat[i][j - 1];           }       }       int res = 0x80000000;       TreeSet&lt;Integer&gt; set = new TreeSet&lt;&gt;();       // 枚举j1列       for (int j1 = 0; j1 &lt; m; j1++) {           // 枚举j2列           for (int j2 = j1; j2 &lt; m; j2++) {               set.clear();               set.add(0);               int curSum = 0;               int curMax = 0x80000000;               // 枚举每一行               for (int i = 0; i &lt; n; i++) {                   curSum += mat[i][j2] - (j1 &gt; 0 ? mat[i][j1 - 1] : 0);                   System.out.println(curSum);                   Integer c = set.ceiling(curSum - k);                   if (c != null) {                       curMax = Math.max(curMax, curSum - c);                   }                   set.add(curSum);               }               res = Math.max(res, curMax);               System.out.println();           }           System.out.println();       }       return res;   }\n\npython 代码\nclass Solution:    def maxSumSubmatrix(self, mat: List[List[int]], k: int) -&gt; int:        import bisect        n, m, res = len(mat), len(mat[0]), float('-inf')        # 首先计算每一行前缀和        for i in range(n):            for j in range(1, m):                mat[i][j] += mat[i][j - 1]        # 枚举列1        for j1 in range(m):            # 枚举列2            for j2 in range(j1,m):                cur_sum,arr = 0,[0]                # 枚举每一行                for i in range(n):                    cur_sum += mat[i][j2] - (mat[i][j1 - 1] if j1 &gt; 0 else 0)                    loc = bisect.bisect_left(arr,cur_sum - k)                    # 如果能找到                    if loc &lt; len(arr):                        res = max(res,cur_sum - arr[loc])                    bisect.insort(arr,cur_sum)        return res\n\n\n\n1292. 元素和小于等于阈值的正方形的最大边长\n给你一个大小为 m x n 的矩阵 mat 和一个整数阈值 threshold。请你返回元素总和小于或等于阈值的正方形区域的最大边长；如果没有这样的正方形区域，则返回 0 。\n示例 1：\n\n输入：mat = [[1,1,3,2,4,3,2],[1,1,3,2,4,3,2],[1,1,3,2,4,3,2]], threshold = 4输出：2解释：总和小于 4 的正方形的最大边长为 2，如图所示。\n\n提示：\n1 &lt;= m, n &lt;= 300m == mat.lengthn == mat[i].length0 &lt;= mat[i][j] &lt;= 100000 &lt;= threshold &lt;= 10^5\n\n第167场周赛题，和前面题基本上一样，只不过这里不是矩形，变成了正方形。依然是利用前缀和+二分的思想。直接算二维前缀和。\n比如我现在要计算坐标为(i,j)的二维前缀和，就要利用到它左边的前缀和和上边的前缀和，如图所示，左边那块  （粉色）和上面那块  （紫色），这两个前缀和加起来，再减去共同区域  ，最后加上这个点的值 （这里开的都是n+1，下标从1开始） ，那就是 \n\nsum[i][j] = sum[i][j-1] + sum[i-1][j] - sum[i-1][j-1] + A[i-1][j-1] （sum比A的行和列都多开一维）\n\n当我们要计算某块区域元素内的和\nint val = sum[i][j] - sum[i][j-k] - sum[i-k][j] +sum[i-k][j-k]，k代表区间的长度（以正方形为例）\n\n\nJava 代码\npublic int maxSideLength(int[][] mat, int threshold) {        int n = mat.length;        int m = mat[0].length;        int[][] sum = new int[n + 1][m + 1];        //计算二维前缀和        for (int i = 1; i &lt;= n; i++) {            for (int j = 1; j &lt;= m; j++) {                sum[i][j] = sum[i - 1][j] + sum[i][j - 1] - sum[i - 1][j - 1] + mat[i - 1][j - 1];            }        }        // for (int i = 0; i &lt;= n; i++) {        //     for (int j = 0; j &lt;= m; j++) {        //         System.out.print(sum[i][j] +\" \");        //     }        //     System.out.println();        // }        //二分找答案        int start = 0;        int end = Math.min(n, m) ;        while (start + 1 &lt; end) {            int mid = start + (end - start) / 2;            if (valid(sum, mid, threshold)) {                start = mid;            } else {                end = mid;            }        }        //double check        if (valid(sum, end, threshold)) {            return end;        } else {            return start;        }    }    private static boolean valid(int[][] sum, int len, int threshold) {        // 枚举正方形右下角        for (int i = len; i &lt; sum.length; i++) {            for (int j = len; j &lt; sum[0].length; j++) {                int temp = sum[i][j] - sum[i - len][j] - sum[i][j - len] + sum[i - len][j - len];                if (temp &lt;= threshold) {                    return true;                }            }        }        return false;    }\n\n","categories":["Algorithm"],"tags":["PrefixSum"]},{"title":"最短路算法","url":"/2019/12/10/shortest-path-algorithm/","content":"最短路算法这篇博客主要是记一下最短路板子，板子三天不练就忘（x\n回到正题，图的最短路算法有很多，在此记录一下非常常用的三个算法\n\n单源最短路\n不带负权边：\n带负权边：、\n\n\n多源最短路\n\n\n\n\n假设图中顶点V个，边E条，有如下结论：\n\n\n本质是贪心+广搜\n朴素写法，时间复杂度，可以认为是，这个一般不怎么写，需要松弛，太蠢啦\n堆优化（小堆），时间复杂度\n 算法更适合稠密图（边多的图）\n无论图有没有环， 算法都是可以用的，它只是不能处理负权边，因为它本质上是贪心策略，每个点选择之后就不再更新，如果碰到了负边的存在就会破坏这个贪心的策略就无法处理了\n一般堆优化+邻接矩阵用起来贼爽\n\n\n\n它是  的优化，的时间复杂度为 ，效率太低了，SPFA是  的队列优化，但是算法时间效率不稳定，时间复杂度为，最好情况下，每个节点只入队一次，就是 ，最坏情况下，每一个节点都要入队  次，这时候就退化成 了\n时间复杂度某种情况下略高于 ， 适合稀疏图\n 是可以用于带有负权图的，在  中每一个点松弛过后说明这个点距离更近了，所以有可能通过这个点会再次优化其他点，所以它的策略是将  位置为 ，把这个点入队再判断一次！这就和  的贪心策略不同了！\n 还有个用处是可以判断图是否存在负环，我们只要用一个  数组来存放经过这个点的次数，上面提到过，最坏情况下每个节点入队 次，如果  为  的个数，那就说明存在负环了。\n\n\n\n本质是动态规划，能解决任意两点间的最短路径，时间复杂度 \n看了  大佬的一个回复，它是可以判断有没有负权边环的，走N-1步，如果再走一步，更短了，那么就说明有环。另外  是不能处理带有负权的最短路的，因为本质是一个动态规划算法，有了负边，最优子结构的性质就不满足了。由此可见，它能够判断是否存在负环，但是不能够处理带有负权的额最短路\n 有个神奇的特性，这个是其他算法没有的，第  轮算的结果，是每个源点到每个汇点经过前  个点的最短路，这一点可以出题。\n\n\n\n743. 网络延迟时间Dijkstra（堆优化）\n\ntimes中的数组 a a[0]代表源，a[1]代表目标，a[2]代表权值，单向的\n\n一般堆优化的都用邻接表， map&lt; Integer,List&lt; int[]&gt;&gt;来存放源到目的节点及权值，而朴素dijkstra直接用数组就可以了\n\ndijkstra 需要 dis数组和vis数组，都开N+1，dis的初始化要当心，具体是初始化为-1还是INF看情况，其次不要忘记初始化之后再重置dis[源]和dis{0}为0\n\n\n\npublic int networkDelayTime(int[][] times, int N, int K) {       Map&lt;Integer, List&lt;int[]&gt;&gt; map = new HashMap&lt;&gt;();       // 初始化邻接表       for (int[] t : times) {           map.computeIfAbsent(t[0], k -&gt; new ArrayList&lt;&gt;()).add(new int[]{t[1], t[2]});       }       // 初始化dis数组和vis数组       int[] dis = new int[N + 1];       Arrays.fill(dis, 0x3f3f3f3f);       boolean[] vis = new boolean[N + 1];       // 起点的dis为0，但是别忘记0也要搞一下，因为它是不参与的，我计算结果的时候直接用了stream，所以这个0也就要初始化下了       dis[K] = 0;       dis[0] = 0;       // new一个小堆出来，按照dis升序排，一定要让它从小到大排，省去了松弛工作       PriorityQueue&lt;Integer&gt; queue = new PriorityQueue&lt;&gt;((o1, o2) -&gt; dis[o1] - dis[o2]);       // 把起点放进去       queue.offer(K);       while (!queue.isEmpty()) {           // 当队列不空，拿出一个源出来           Integer poll = queue.poll();        \t\tif(vis[poll]) continue;           // 把它标记为访问过           vis[poll] = true;           // 遍历它的邻居们，当然可能没邻居，这里用getOrDefault处理就很方便           List&lt;int[]&gt; list = map.getOrDefault(poll, Collections.emptyList());           for (int[] arr : list) {               int next = arr[0];               // 如果这个邻居访问过了，继续               if (vis[next]) continue;               // 更新到这个邻居的最短距离，看看是不是当前poll出来的节点到它更近一点               dis[next] = Math.min(dis[next], dis[poll] + arr[1]);               queue.offer(next);           }       }       // 拿到数组中的最大值比较下，返回结果       int res = Arrays.stream(dis).max().getAsInt();       return res == 0x3f3f3f3f ? -1 : res;   }\n\n\n\nSPFA\n\nSPFA是一种用队列优化的B-F算法，在稀疏图中，采用类似邻接链表储存比较节省空间。\n也需要用到dis和vis数组，开N+1，初始化也要看情况\n\n【算法思想】\n\n初始时，只有把起点放入队列中。\n遍历与起点相连的边，如果可以松弛就更新距离dis[],然后判断如果这个点没有在队列中就入队标记。\n出队队首，取消标记，循环2-3步，直至队为空。\n所有能更新的点都更新完毕，dis[]数组中的距离就是，起点到其他点的最短距离。\n\nps：这边我犯的一个错误是这样的\nInteger poll = queue.poll()；if(判断是否是poll的邻居){  \tif(判断是否需要更新){    \t\t// 更新代码    }  \tif(!vis[next]){      queue.offer(next);      vis[next] = true;    }}...\n\n这样写是错的，如果图中有环，在不需要更新的情况下，就能重复入队，所以应该改为\nInteger poll = queue.poll()；if(判断是否是poll的邻居 &amp;&amp; 判断是否需要更新){    // 更新代码  \t// ...  \tif(!vis[next]){      queue.offer(next);      vis[next] = true;    }}...\n\n邻接表写法// SPFA：用邻接表写public int networkDelayTime(int[][] times, int N, int K) {    Map&lt;Integer, List&lt;int[]&gt;&gt; map = new HashMap&lt;&gt;();    // 构建邻接表    for (int[] arr : times) {        List&lt;int[]&gt; list = map.getOrDefault(arr[0], new ArrayList&lt;&gt;());        list.add(new int[]{arr[1], arr[2]});        map.put(arr[0], list);    }    // 初始化dis数组和vis数组    int[] dis = new int[N + 1];    int INF = 0x3f3f3f3f;    Arrays.fill(dis, INF);      boolean[] vis = new boolean[N + 1];    dis[K] = dis[0] = 0;    Queue&lt;Integer&gt; queue = new LinkedList&lt;&gt;();    queue.offer(K);    while (!queue.isEmpty()) {        // 取出队首节点        Integer poll = queue.poll();        // 可以重复入队        vis[poll] = false;        // 遍历起点的邻居,更新距离        List&lt;int[]&gt; list = map.getOrDefault(poll, Collections.emptyList());        for (int[] arr : list) {            int next = arr[0];            // 如果没更新过，或者需要更新距离()            if (dis[next] == INF || dis[next] &gt; dis[poll] + arr[1]) {                // 更新距离                dis[next] = dis[poll] + arr[1];                // 如果队列中没有，就不需要再次入队了 （那么判断入度可以在这里做文章）                if (!vis[next]) {                    vis[next] = true;                    queue.offer(next);                }            }        }            }    int res = Arrays.stream(dis).max().getAsInt();    return res == INF ? -1 : res;}\n\n\n\n邻接矩阵写法public class Solution {    public int networkDelayTime(int[][] times, int N, int K) {        int[][] g = new int[N + 1][N + 1];        // 初始化 graph        for (int i = 1; i &lt;= N; i++) {            for (int j = 1; j &lt;= N; j++) {                g[i][j] = i == j ? 0 : -1;            }        }        // 单向边        for (int[] t : times) {            g[t[0]][t[1]] = t[2];        }        int INF = 0x3f3f3f3f;        // 初始化 dis、vis        int[] dis = new int[N + 1];        Arrays.fill(dis, INF);        dis[0] = dis[K] = 0;        boolean[] vis = new boolean[N + 1];        Queue&lt;Integer&gt; queue = new LinkedList&lt;&gt;();        queue.offer(K);        vis[K] = true;        while (!queue.isEmpty()) {            Integer poll = queue.poll();            vis[poll] = false;            // 遍历邻居            for (int next = 1; next &lt;= N; next++) {                // 如果是邻居 且 如果没有更新过，或者是需要更新，才往下走，注意这里是且，并不是判断了邻居就往下走了                // 下面是错误写法                 /*                如果是邻居，，一定要在这一步全部写完，如果能更新才能判断能不能入队，                if (edge[poll][i] != -1) {                    //更新                    if (dis[i] == INF || dis[i] &gt; dis[poll] + edge[poll][i]) {                        dis[i] = dis[poll] + edge[poll][i];                    }                    if (!vis[i]) {                        vis[i] = true;                        queue.offer(i);                    }                }                 */                int w = g[poll][next];                if (w != -1 &amp;&amp; (dis[next] == INF || dis[next] &gt; dis[poll] + w)) {                    dis[next] = dis[poll] + w;                    // 如果队列中没有，就可以入队，不要重复入队                    if (!vis[next]) {                        vis[next] = true;                        queue.offer(next);                    }                }            }        }        int res = Arrays.stream(dis).max().getAsInt();        return res == INF ? -1 : res;    }}\n\n\n\n\n\nFloyd\n\n由于是动态规划，所以都是用邻接矩阵\n并且它是不用 dis 数组和  vis 数组的\n这边注意，初始化邻接矩阵的时候，如果两个顶点没有边，最好初始化为INF，别初始化为-1，这也是我提交时候注意到的，上面说过Floyd是不能处理负权边的，只能判断有没有负环！\n\n\npublic class Solution {    private int INF = 0x3f3f3f3f;    public int networkDelayTime(int[][] times, int N, int K) {        int[][] g = new int[N + 1][N + 1];        // 初始化图,注意,一开始距离是初始化为INF的，而不是像 spfa初始化成-1        // spfa初始化成-1只是为了判断是否为邻居，这里初始化为INF是因为要取min的        for (int i = 1; i &lt;= N; i++) {            for (int j = 1; j &lt;= N; j++) {                g[i][j] = i == j ? 0 : 0x3f3f3f3f;            }        }        for (int[] t : times) {            g[t[0]][t[1]] = t[2];        }        // 使用K节点来松弛i-&gt;j的最短路径（大白话就是利用k作为中间节点）        for (int k = 1; k &lt;= N; k++) {            for (int i = 1; i &lt;= N; i++) {                for (int j = 1; j &lt;= N; j++) {                    // 判断语句不用写                    // if (k != i &amp;&amp; k != j &amp;&amp; g[i][k] != INF &amp;&amp; g[k][j] != INF) {                        g[i][j] = Math.min(g[i][j], g[i][k] + g[k][j]);                    // }                }            }        }        // g[a][b]表示a到b的最短距离        //拿结果        int res = 0;        for (int distance : g[K]) {            res = Math.max(res, distance);        }        return res == INF ? -1 : res;    }}\n\n","categories":["Algorithm"],"tags":["shortest path"]},{"title":"GC场景模拟与日志分析","url":"/2020/02/27/JVM8/","content":"GC场景模拟与日志分析一、Young GC场景模拟与日志分析1、JVM参数设置-XX:NewSize=5242880\t\t\t\t\t\t//新生代大小为5MB-XX:MaxNewSize=5242880\t\t\t\t//最大新生代大小为5MB-XX:InitialHeapSize=10485760\t//初始堆大小10MB-XX:MaxHeapSize=10485760\t\t\t//初始堆最大大小10MB-XX:SurvivorRatio=8\t\t\t\t\t\t//新生代5MB，Eden占4MB，两个S区各占0.5MB-XX:PretenureSizeThreshold=10485760\t\t//大对象阈值为10MB-XX:+UseParNewGC\t\t\t\t\t\t\t//新生代使用PN垃圾回收器-XX:+UseConcMarkSweepGC\t\t\t\t//老年代使用CMS垃圾回收器//设置打印JVM日志的参数-XX:+PrintGCDetils\t\t\t//打印详细的gc日志-XX:+PrintGCTimeStamps\t//这个参数可以打印出来每次GC发生的时间-Xloggc:gc.log\t\t\t\t\t//这个参数可以设置将gc日志写入一个磁盘文件\n\n \nidea参数设置步骤方法\n2、代码测试代码如下，new byte[1024 * 1024]这样的代码连续分配了3个数组，每个数组都是1MB（1024B*1024B），通过array1这个局部变量依次引用这三个对象，最后还把array1这个局部变量指向了null。\npublic class Demo1 &#123;    public static void main(String[] args) &#123;        byte[] array1 = new byte[1024 * 1024];        array1 = new byte[1024 * 1024];        array1 = new byte[1024 * 1024];        array1 = null;        byte[] array2 = new byte[2 * 1024 * 1024];    &#125;&#125;\n\n第一行byte[] array1 = new byte[1024 * 1024];代码一旦运行，就会在JVM的Eden区内放入一个1MB的对象，同时在main线程的虚拟机栈中会压入一个main()方法的栈帧，在main()方法的栈帧内部，会有一个“array1”变量，这个变量是指向堆内存Eden区的那个1MB的数组。\n第二行 array1 = new byte[1024 * 1024];此时会在堆内存的Eden区中创建第二个数组，并且让局部变量指向第二个数组，然后第一个数组就没人引用了，此时第一个数组就成了没人引用的“垃圾对象”了。\n第三行byte[] array1 = new byte[1024 * 1024];，让array1变量指向了第三个数组，此时前面两个数组都没有人引用了，就都成了垃圾对象。\n第四行array1 = null;array1这个变量什么都不指向了，此时会导致之前创建的3个数组全部变成垃圾对象。最后如图所示：\n\n第五行byte[] array2 = new byte[2 * 1024 * 1024];分配一个2MB大小的数组，尝试放入Eden区中,此时Eden放不下了，就会触发Young GC。\n运行程序，得到GC日志文件gc.log\n3、日志分析Java HotSpot(TM) 64-Bit Server VM (25.212-b10) for bsd-amd64 JRE (1.8.0_212-b10), built on Apr  1 2019 23:10:56 by &quot;java_re&quot; with gcc 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2336.11.00)Memory: 4k page, physical 16777216k(469700k free)/proc/meminfo:CommandLine flags: -XX:InitialHeapSize=10485760 -XX:MaxHeapSize=10485760 -XX:MaxNewSize=5242880 -XX:NewSize=5242880 -XX:OldPLABSize=16 -XX:PretenureSizeThreshold=10485760 -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:SurvivorRatio=8 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseConcMarkSweepGC -XX:+UseParNewGC 0.101: [GC (Allocation Failure) 0.102: [ParNew: 3473K-&gt;416K(4608K), 0.0018825 secs] 3473K-&gt;1442K(9728K), 0.0019891 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] Heap par new generation   total 4608K, used 3650K [0x00000007bf600000, 0x00000007bfb00000, 0x00000007bfb00000)  eden space 4096K,  78% used [0x00000007bf600000, 0x00000007bf928920, 0x00000007bfa00000)  from space 512K,  81% used [0x00000007bfa80000, 0x00000007bfae8100, 0x00000007bfb00000)  to   space 512K,   0% used [0x00000007bfa00000, 0x00000007bfa00000, 0x00000007bfa80000) concurrent mark-sweep generation total 5120K, used 1026K [0x00000007bfb00000, 0x00000007c0000000, 0x00000007c0000000) Metaspace       used 2934K, capacity 4496K, committed 4864K, reserved 1056768K  class space    used 320K, capacity 388K, committed 512K, reserved 1048576K\n\n（1）第一部分CommandLine flags就是一些默认参数以及我们设置的一些参数。\n（2）第二部分0.101: [GC (Allocation Failure) 0.102: [ParNew: 3473K-&gt;416K(4608K), 0.0018825 secs] 3473K-&gt;1442K(9728K), 0.0019891 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] \n\n这一段说的是本次GC执行的情况。\n\nGC (Allocation Failure)：GC发生原因，分配对象失败0.102,意思是系统运行了0.102s后发生GC\n\nParNew: 3473K-&gt;416K(4608K), 0.0018825 secs：前面是我们指定的垃圾回收器，3473K-&gt;416K(4608K)，意思是对新生代执行一次GC前已经使用了3473KB，，但是GC后只有416KB对象是存活下来的，然后(4608)代表新生代可用空间是4.5M（Eden+1个S），后面时间是本次GC耗费的时间。虽然我们创建的数组是1MB，但是为了存这个数组，JVM还附带了其他的一些信息，导致每个数组实际占的内存大于1M。这些其他信息是什么可以借助专门的工具来分析堆内存快照。\n\n如图所示是放了三个对象与位置对象的情况，共占3473KB\n接下来就进行了Young GC，存活416KB，如图\n\n\n3473K-&gt;1442K(9728K), 0.0019891 secs：这段话指的是整个Java堆内存的使用情况，总可用空间9728KB（9.5MB），就是年轻代+老年代，GC前整个Java堆内存使用了3473KB，GC后Java堆内存使用了1442KB\n\n[Times: user=0.01 sys=0.00, real=0.01 secs] ：这个是本次GC消耗的时间，从秒为单位来看几乎为0\n\n\n（3）第三部分Heap开始就是JVM退出的时候打印出当前堆内存的使用情况了。\nHeap par new generation   total 4608K, used 3650K [0x00000007bf600000, 0x00000007bfb00000, 0x00000007bfb00000)\n\n\n par new generation   total 4608K, used 3650K：意思是ParNew垃圾回收器负责的年轻代总共4608KB（4.5MB），目前使用了3650KB（3.5MB）。照理来说应该是（2M对象+之前400多KB未知的对象应该是2.5MB左右，但是为什么变成3.5MB呢？因为我们的2.5MB是理论值，具体情况和使用的IDE有差异。）\n\neden space 4096K,  78% used [0x00000007bf600000, 0x00000007bf928920, 0x00000007bfa00000)from space 512K,  81% used [0x00000007bfa80000, 0x00000007bfae8100, 0x00000007bfb00000)to   space 512K,   0% used [0x00000007bfa00000, 0x00000007bfa00000, 0x00000007bfa80000)\n\n\n这是新生代三个区域Eden、Survivor from、Survivor to三个区域的使用率。\n\nconcurrent mark-sweep generation total 5120K, used 1026K [0x00000007bfb00000, 0x00000007c0000000, 0x00000007c0000000) Metaspace       used 2934K, capacity 4496K, committed 4864K, reserved 1056768K  class space    used 320K, capacity 388K, committed 512K, reserved 1048576K\n\n\nconcurrent mark-sweep generation total 5120K, used 1026K：使用的是CMS回收器，管理老年代大小一共5MB，使用了1026KB\nMetaspace：元数据空间，存放一些类信息、常量池的东西\nclass space：Class 空间\n\n二、进入老年代的场景模拟与日志分析1、对象进入老年代的四个条件\n躲过15次GC后直接进入老年代\n动态年龄判断规则，如果Survivor区域内年龄1+年龄2+年龄3+年龄n的对象总和大于Survivor区的50%，此时年龄n以上的对象会进入老年代，不一定要达到15岁\nYoung GC后存活的对象太多而无法放入Survivor区，直接进入老年代\n大对象直接进入老年代\n\n2、场景一（动态年龄判断规则场景）在这里模拟根据动态年龄判断规则进入老年代的那个场景。\n（1）首先设置JVM参数-XX:NewSize=10485760\t\t\t\t\t//新生代大小为10MB-XX:MaxNewSize=10485760 \t\t\t//新生代最大大小为10MB-XX:InitialHeapSize=20971520 \t//初始化堆大小为20MB-XX:MaxHeapSize=20971520 \t\t\t//最大堆大小为20MB-XX:SurvivorRatio=8  \t\t\t\t\t//新生代区域划分8:1:1-XX:MaxTenuringThreshold=15 \t//默认是躲过15次GC进入老年代-XX:PretenureSizeThreshold=10485760 \t//超过10MB的对象直接进入老年代-XX:+UseParNewGC \t\t\t\t\t\t\t//新生代使用PN-XX:+UseConcMarkSweepGC \t\t\t//老年代使用CMS//设置打印JVM日志的参数-XX:+PrintGCDetils\t\t\t//打印详细的gc日志-XX:+PrintGCTimeStamps\t//这个参数可以打印出来每次GC发生的时间-Xloggc:gc.log\t\t\t\t\t//这个参数可以设置将gc日志写入一个磁盘文件\n\n（2）代码测试并分析GC日志//初步代码public class Demo1 &#123;    public static void main(String[] args) &#123;        byte[] array1 = new byte[2 * 1024 * 1024];        array1 = new byte[2 * 1024 * 1024];        array1 = new byte[2 * 1024 * 1024];        array1 = null;        byte[] array2 = new byte[128 * 1024];                byte[] array3 = new byte[2 * 1024 * 1024];    &#125;&#125;\n\nidea+debug模式\nJava HotSpot(TM) 64-Bit Server VM (25.212-b10) for bsd-amd64 JRE (1.8.0_212-b10), built on Apr  1 2019 23:10:56 by &quot;java_re&quot; with gcc 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2336.11.00)Memory: 4k page, physical 16777216k(573728k free)/proc/meminfo:CommandLine flags: -XX:InitialHeapSize=20971520 -XX:MaxHeapSize=20971520 -XX:MaxNewSize=10485760 -XX:MaxTenuringThreshold=15 -XX:NewSize=10485760 -XX:OldPLABSize=16 -XX:PretenureSizeThreshold=10485760 -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:SurvivorRatio=8 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseConcMarkSweepGC -XX:+UseParNewGC 0.138: [GC (Allocation Failure) 0.138: [ParNew: 8179K-&gt;627K(9216K), 0.0008498 secs] 8179K-&gt;627K(19456K), 0.0009520 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] Heap par new generation   total 9216K, used 2921K [0x00000007bec00000, 0x00000007bf600000, 0x00000007bf600000)  eden space 8192K,  28% used [0x00000007bec00000, 0x00000007bee3d8a0, 0x00000007bf400000)  from space 1024K,  61% used [0x00000007bf500000, 0x00000007bf59ccb8, 0x00000007bf600000)  to   space 1024K,   0% used [0x00000007bf400000, 0x00000007bf400000, 0x00000007bf500000) concurrent mark-sweep generation total 10240K, used 0K [0x00000007bf600000, 0x00000007c0000000, 0x00000007c0000000) Metaspace       used 2930K, capacity 4556K, committed 4864K, reserved 1056768K  class space    used 312K, capacity 392K, committed 512K, reserved 1048576K\n\n前四行\nbyte[] array1 = new byte[2 * 1024 * 1024];array1 = new byte[2 * 1024 * 1024];array1 = new byte[2 * 1024 * 1024];array1 = null;\n\n这一块连续创建3个2MB的数组，最后还把array1设置为null，此时的内存图如下所示\n\n前四行代码运行后堆内存中的结果\n第五行byte[] array2 = new byte[128 * 1024]在Eden区创建一个128KB的数组，由array2来引用。\n\n第五行代码运行后堆内存中的结果\n此时运行第六行代码，再分配一个2MB的数组发现Eden区没有空间了，这时候一定会先触发一次Young GC，我们可以在日志中看到有这么一句：ParNew: 8179K-&gt;627K(9216K)，这行日志清晰表明了，在GC之前新生代占用了8179KB的内存，这里大概就是6MB（6144）的3个数组 + 128KB的1个数组 + 几百KB的一些未知对象。接着看GC日志,Young GC存活下来的都进了Survivor区了，占了一半，这些是未知的对象+128KB数组，同时Eden区域内被占据了28%的空间，大概就是2MB左右，这就是新来的数组占用Eden的空间大小。此时如图所示。\npar new generation   total 9216K, used 2921K [0x00000007bec00000, 0x00000007bf600000, 0x00000007bf600000) eden space 8192K,  28% used [0x00000007bec00000, 0x00000007bee3d8a0, 0x00000007bf400000) from space 1024K,  61% used [0x00000007bf500000, 0x00000007bf59ccb8, 0x00000007bf600000) to   space 1024K,   0% used [0x00000007bf400000, 0x00000007bf400000, 0x00000007bf500000)\n\n\n第六行代码运行后堆内存中的结果。\n此时Survivor From区里的那些对象，他们都是1岁，熬过1次GC，年龄就增加1，而此时占用了总Survivor区域的61%，超过50%了。\n（3）再完善代码并分析GC日志把上述代码完善成这样子，我们要出发出来第二次Young GC，来看Survivor区域中的动态年龄判断规则是否生效。\npublic class Demo1 &#123;    public static void main(String[] args) &#123;        byte[] array1 = new byte[2 * 1024 * 1024];        array1 = new byte[2 * 1024 * 1024];        array1 = new byte[2 * 1024 * 1024];        array1 = null;        byte[] array2 = new byte[128 * 1024];        byte[] array3 = new byte[2 * 1024 * 1024];        //新增加的代码        array3 = new byte[2 * 1024 * 1024];        array3 = new byte[2 * 1024 * 1024];        array3 = new byte[128 * 1024];        array3 = null;        byte[] array4 = new byte[2 * 1024 * 1024];    &#125;&#125;\n\nGC日志（idea，Debug模式）\nJava HotSpot(TM) 64-Bit Server VM (25.212-b10) for bsd-amd64 JRE (1.8.0_212-b10), built on Apr  1 2019 23:10:56 by &quot;java_re&quot; with gcc 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2336.11.00)Memory: 4k page, physical 16777216k(578716k free)/proc/meminfo:CommandLine flags: -XX:InitialHeapSize=20971520 -XX:MaxHeapSize=20971520 -XX:MaxNewSize=10485760 -XX:MaxTenuringThreshold=15 -XX:NewSize=10485760 -XX:OldPLABSize=16 -XX:PretenureSizeThreshold=10485760 -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:SurvivorRatio=8 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseConcMarkSweepGC -XX:+UseParNewGC 0.400: [GC (Allocation Failure) 0.400: [ParNew: 8179K-&gt;617K(9216K), 0.0011641 secs] 8179K-&gt;617K(19456K), 0.0012530 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 0.403: [GC (Allocation Failure) 0.403: [ParNew: 7085K-&gt;0K(9216K), 0.0042709 secs] 7085K-&gt;521K(19456K), 0.0043461 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] Heap par new generation   total 9216K, used 2130K [0x00000007bec00000, 0x00000007bf600000, 0x00000007bf600000)  eden space 8192K,  26% used [0x00000007bec00000, 0x00000007bee14930, 0x00000007bf400000)  from space 1024K,   0% used [0x00000007bf400000, 0x00000007bf400000, 0x00000007bf500000)  to   space 1024K,   0% used [0x00000007bf500000, 0x00000007bf500000, 0x00000007bf600000) concurrent mark-sweep generation total 10240K, used 521K [0x00000007bf600000, 0x00000007c0000000, 0x00000007c0000000) Metaspace       used 2931K, capacity 4556K, committed 4864K, reserved 1056768K  class space    used 312K, capacity 392K, committed 512K, reserved 1048576K\n\n分析这4行代码\narray3 = new byte[2 * 1024 * 1024];array3 = new byte[2 * 1024 * 1024];array3 = new byte[128 * 1024];array3 = null;\n\n这些代码就是再生成2个2MB数组和个128KB数组，最后array3指向null，示意图如下\n\n接下来就运行最后一行代码byte[] array4 = new byte[2 * 1024 * 1024];这时候是放不下去的，必然会触发一次Young GC，看一下日志：\n0.403: [GC (Allocation Failure) 0.403: [ParNew: 7085K-&gt;0K(9216K), 0.0042709 secs] 7085K-&gt;521K(19456K), 0.0043461 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] \n\n第二次出发Young GC，此时发现7085K-&gt;0K(9216K)这就说明，第二次GC后新生代中没有对象了。没有任何对象是不可能的啊，我们的array2还指向这个变量呢。其实这会根据动态年龄判断规则，年龄1+年龄2+年龄n的对象总大小超过了Survivor区域的50%，年龄n以上的对象进入老年代。当然这里的对象都是年龄1的，所以直接全部进入老年代了。可以看到CMS管理的区域多了这么512KB。\nconcurrent mark-sweep generation total 10240K, used 521K [0x00000007bf600000, 0x00000007c0000000, \n\n\n然后array4变量引用的那个2MB的数组，此时就会分配到Eden区域中，如下图所示。所以日志中有这么几行（此时Survivor区域中的对象都到老年代去了）\neden space 8192K,  26% used [0x00000007bec00000, 0x00000007bee14930, 0x00000007bf400000)from space 1024K,   0% used [0x00000007bf400000, 0x00000007bf400000, 0x00000007bf500000)  to   space 1024K,   0% used [0x00000007bf500000, 0x00000007bf500000, 0x00000007bf600000)\n\n\n\n\n3、场景二（Survivor放不下则直接进老年代）抛出问题：那些放不下的对象，是全部进入老年代还是部分进入老年代呢？\nJVM参数和场景一相同\n（1）代码测试并分析GC日志public class Demo1 &#123;    public static void main(String[] args) &#123;        byte[] array1 = new byte[2 * 1024 * 1024];        array1 = new byte[2 * 1024 * 1024];        array1 = new byte[2 * 1024 * 1024];        byte[] array2 = new byte[128 * 1024];        array2 = null;        byte[] array3 = new byte[2 * 1024 * 1024];    &#125;&#125;\n\nJava HotSpot(TM) 64-Bit Server VM (25.212-b10) for bsd-amd64 JRE (1.8.0_212-b10), built on Apr  1 2019 23:10:56 by &quot;java_re&quot; with gcc 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2336.11.00)Memory: 4k page, physical 16777216k(407972k free)/proc/meminfo:CommandLine flags: -XX:InitialHeapSize=20971520 -XX:MaxHeapSize=20971520 -XX:MaxNewSize=10485760 -XX:MaxTenuringThreshold=15 -XX:NewSize=10485760 -XX:OldPLABSize=16 -XX:PretenureSizeThreshold=10485760 -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:SurvivorRatio=8 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseConcMarkSweepGC -XX:+UseParNewGC 0.150: [GC (Allocation Failure) 0.150: [ParNew: 8179K-&gt;488K(9216K), 0.0023498 secs] 8179K-&gt;2538K(19456K), 0.0024491 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] Heap par new generation   total 9216K, used 2782K [0x00000007bec00000, 0x00000007bf600000, 0x00000007bf600000)  eden space 8192K,  28% used [0x00000007bec00000, 0x00000007bee3d8a0, 0x00000007bf400000)  from space 1024K,  47% used [0x00000007bf500000, 0x00000007bf57a0a8, 0x00000007bf600000)  to   space 1024K,   0% used [0x00000007bf400000, 0x00000007bf400000, 0x00000007bf500000) concurrent mark-sweep generation total 10240K, used 2050K [0x00000007bf600000, 0x00000007c0000000, 0x00000007c0000000) Metaspace       used 2930K, capacity 4556K, committed 4864K, reserved 1056768K  class space    used 312K, capacity 392K, committed 512K, reserved 1048576K\n\n分析：\nbyte[] array1 = new byte[2 * 1024 * 1024];array1 = new byte[2 * 1024 * 1024];array1 = new byte[2 * 1024 * 1024];byte[] array2 = new byte[128 * 1024];array2 = null;\n\n首先创建3个2MB的数组，最开始两个变成垃圾，只有最后一个被array1指向了，接着创建了一个128KB的数组，然后array2指向空，128KB的数组也变成垃圾，如图所示：\n\n此时我们执行byte[] array3 = new byte[2 * 1024 * 1024];代码，发现放不进Eden了，要进行第一次Young GC。查看日志，发现ParNew: 8179K-&gt;488K(9216K)，GC后还剩余488KB。情况是这样的，2个2MB和1个128KB的数组被回收掉了，最后剩下一个2MB的数组和488KB的未知对象，这两个加起来大于Survivor区的大小，所以直接进入老年代，但是并不是全部进去的，我们可以看到日志中又这么几行\npar new generation   total 9216K, used 2782K [0x00000007bec00000, 0x00000007bf600000, 0x00000007bf600000)  eden space 8192K,  28% used [0x00000007bec00000, 0x00000007bee3d8a0, 0x00000007bf400000)  from space 1024K,  47% used [0x00000007bf500000, 0x00000007bf57a0a8, 0x00000007bf600000)  to   space 1024K,   0% used [0x00000007bf400000, 0x00000007bf400000, 0x00000007bf500000) concurrent mark-sweep generation total 10240K, used 2050K [0x00000007bf600000, 0x00000007c0000000, \n\nconcurrent mark-sweep generation total 10240K, used 2050K说明那个原来存在的2MB的数组进了老年代，另外from space 1024K,  47% used说明了把这个位置对象放进了S1区，以及eden space 8192K,  28% used这个说明我们新创建的对象也放进了了Eden区。最后如图所示：\n\n三、Old GC场景模拟与日志分析1、JVM参数设置-XX:NewSize=10485760 -XX:MaxNewSize=10485760 -XX:InitialHeapSize=20971520 -XX:MaxHeapSize=20971520 -XX:SurvivorRatio=8  -XX:MaxTenuringThreshold=15 -XX:PretenureSizeThreshold=3145728 \t//这里最大对象是3MB，超过则进入老年代-XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:gc.log\n\n\n\n2、代码测试与日志分析public class Demo1 &#123;    public static void main(String[] args) &#123;        byte[] array1 = new byte[4 * 1024 * 1024];        array1 = null;        byte[] array2 = new byte[2 * 1024 * 1024];        byte[] array3 = new byte[2 * 1024 * 1024];        byte[] array4 = new byte[2 * 1024 * 1024];        byte[] array5 = new byte[128 * 1024];        byte[] array6 = new byte[2 * 1024 * 1024];    &#125;&#125;\n\n日志如下\nJava HotSpot(TM) 64-Bit Server VM (25.212-b10) for bsd-amd64 JRE (1.8.0_212-b10), built on Apr  1 2019 23:10:56 by &quot;java_re&quot; with gcc 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2336.11.00)Memory: 4k page, physical 16777216k(912216k free)/proc/meminfo:CommandLine flags: -XX:InitialHeapSize=20971520 -XX:MaxHeapSize=20971520 -XX:MaxNewSize=10485760 -XX:MaxTenuringThreshold=15 -XX:NewSize=10485760 -XX:OldPLABSize=16 -XX:PretenureSizeThreshold=3145728 -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:SurvivorRatio=8 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseConcMarkSweepGC -XX:+UseParNewGC 0.125: [GC (Allocation Failure) 0.125: [ParNew (promotion failed): 8179K-&gt;8785K(9216K), 0.0032460 secs]0.129: [CMS: 8194K-&gt;6722K(10240K), 0.0026381 secs] 12275K-&gt;6722K(19456K), [Metaspace: 2924K-&gt;2924K(1056768K)], 0.0060166 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] 0.132: [GC (CMS Initial Mark) [1 CMS-initial-mark: 6722K(10240K)] 8770K(19456K), 0.0001890 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 0.132: [CMS-concurrent-mark-start]Heap par new generation   total 9216K, used 2294K [0x00000007bec00000, 0x00000007bf600000, 0x00000007bf600000)  eden space 8192K,  28% used [0x00000007bec00000, 0x00000007bee3d8a0, 0x00000007bf400000)  from space 1024K,   0% used [0x00000007bf500000, 0x00000007bf500000, 0x00000007bf600000)  to   space 1024K,   0% used [0x00000007bf400000, 0x00000007bf400000, 0x00000007bf500000) concurrent mark-sweep generation total 10240K, used 6722K [0x00000007bf600000, 0x00000007c0000000, 0x00000007c0000000) Metaspace       used 2930K, capacity 4556K, committed 4864K, reserved 1056768K  class space    used 312K, capacity 392K, committed 512K, reserved 1048576K\n\n分析：\n首先byte[] array1 = new byte[4 * 1024 * 1024];直接分配一个4MB大的对象，直接进入老年代，然后array1不指向它，它就变成了垃圾，接着有3个2MB大小的数组和1个128KB的数组进入Eden，如图：\n\n再接下来去运行byte[] array6 = new byte[2 * 1024 * 1024];这个代码，新来的2MB数组放不下了就会产生第一次Young GC，日志中有一条ParNew (promotion failed): 8179K-&gt;8785K(9216K),这行日志显示了，Eden区原来是有8179多KB的对象，但是回收之后发现一个都回收不掉，因为都有引用，所以要放到老年代去，但是此时新生代对象总大小大于老年代可用空间，所以会先发生一次Old GC\n[CMS: 8194K-&gt;6722K(10240K), 0.0026381 secs] 12275K-&gt;6722K(19456K), [Metaspace: 2924K-&gt;2924K(1056768K)], 0.0060166 secs]\n\n此时执行了CMS垃圾回收器的Full GC，我们之前讲过Full GC其实就是会对老年代进行Old GC，同时一般会跟一次Young GC关联，还会触发一次元数据区（永久代）的GC。这里看到CMS: 8194K-&gt;6722K(10240K)，老年代从8MB左右的对象占用，变成了6MB左右的对象占用，这个过程是这样的：在CMS Full GC之前，就已经触发过Young GC了，它先把2个2MB的数组放进了老年代，剩下1个2MB和1和128KB的数组放不下了此时已用空间8MB（4+2+2）如图：\n\n然后触发Full GC，回收掉其中的一个4MB的数组，接着放入进去1个2MB的数组和1个128KB的数组，就是8MB-4MB+2MB+128KB，大约6MB，此时最后一行代码要在年轻代分配2MB的数组就可以成功了，如图\n\n","categories":["JAVA"],"tags":["JVM"]},{"title":"线段树","url":"/2019/12/12/SegmentTree/","content":"线段树概念：线段树就是一棵二叉树，每个节点代表一个区间，主要用于解决区间类问题。每个节点的属性根据需要可以去自定义，比如节点的属性可以是区间和、区间最大/最小值。。\n一、线段树节点定义每个node有区间的左右端点，以及左右孩子\npublic class SegmentTreeNode{  \tint start,end,val;\t//val根据需要定义，比如我定义为区间最大值就是max  \tSegmentTreeNode left,right;  \tpublic SegmentTreeNode(int start, int end, int val){      \tthis.start = start;      \tthis.end = end;      \tthis.val = val;      \tthis.left = this.right = null;    }}\n\n二、线段树的构建、修改、查询1、构建自上而下，分治法，递归调用。\n对于区间[m1,m2]，mid = (m1+m2)/2，其左儿子区间是[m1,mid]，右儿子区间是(mid+1,m2)\n//线段树的构建,以求区间最大值为例,返回根节点public SegmentTreeNode build(int start, int end, int[] A) {    if (start &gt; end) {        return null;    }    if (start == end) {        return new SegmentTreeNode(start, end, A[start]);    }    //先new根区间,根区间最大值暂时为A[start],不能为其他乱七八糟的值比如-1这种...    SegmentTreeNode root = new SegmentTreeNode(start, end, A[start]);    if (start != end) {        int mid = (start + end) / 2;        root.left = build(start, mid, A);        root.right = build(mid + 1, end, A);    }    //改root的val    if (root.left != null &amp;&amp; root.left.max &gt; root.max) {        root.max = root.left.max;    }    if (root.right != null &amp;&amp; root.right.max &gt; root.max) {        root.max = root.right.max;    }    return root;}\n\n2、修改递归调用，一路向下找到最小区间，触底反弹的时候才去修改node。比如数组[6,3,5,1,9]，我要修改1位置上的3，那就是一路向下先找到3，然后返回途中修改 ，时间复杂度logN\n\n//线段树的修改,public void modify(SegmentTreeNode root, int index, int value) {    if (root.start == index &amp;&amp; root.end == index) {        root.max = value;        return;    }    int mid = (root.start + root.end) / 2;    //看index在左区间还是右区间    if (root.start &lt;= index &amp;&amp; index &lt;= mid) {        modify(root.left, index, value);    }    if (mid &lt; index &amp;&amp; index &lt;= root.end) {        modify(root.right, index, value);    }    //最后改下根    root.max = Math.max(root.left.max, root.right.max);}\n\n3、查询比如上面例子，找[0,3]，先找[0,2]，再找[3,3]。找[0,2]，直接返回，找[3-3]，就需要走到底\n//线段树的查询public int query(SegmentTreeNode root, int start, int end) {    if (start == root.start &amp;&amp; end == root.end) {        return root.max;    }    int mid = (root.start + root.end) / 2;    int left_max = Integer.MIN_VALUE;    int right_max = Integer.MIN_VALUE;    //求左边最大值    //如果给定查询范围起点在左子树    if (start &lt;= mid) {        //但是终点在右子树（横跨左子树和右子树）,那么左边最大值就在start到mid之间查询        if (mid &lt; end) {            left_max = query(root.left, start, mid);        } else {    //如果只在左子树            left_max = query(root.left, start, end);        }    }    //求右边最大值    if (mid &lt; end) {        //横跨左右子树的情况，起点为mid+1        if (start &lt;= mid) {            right_max = query(root.right, mid + 1, end);        } else {    //如果只在右子树            right_max = query(root.right, start, end);        }    }    return Math.max(left_max, right_max);}\n\n三、线段树性质对于区间[m1,m2]，mid = (m1+m2)/2，其左儿子区间是[m1,mid]，右儿子区间是(mid+1,m2)\n\n四、题目练习1、LintCode 206. Interval Sum区间求和\n\n给定一个整数数组（下标由 0 到 n-1，其中 n 表示数组的规模），以及一个查询列表。每一个查询列表有两个整数 [start, end] 。 对于每个查询，计算出数组中从下标 start 到 end 之间的数的总和\n输入: 数组 ：[1,2,7,8,5], 查询：[(0,4),(1,2),(2,4)]输出: [23,9,20]\n\n思路\n\n暴力，枚举O(nm)，n为数组长度，m为查询次数\n线段树/树状数组，O(mlogn)\n前缀和数组O(n+m)，这个题没有涉及到修改，可以用\n\n首先定义Node和树\n//线段树Node  class SegmentTreeNode{      int start;      int end;      long sum;      SegmentTreeNode left, right;      public SegmentTreeNode(int start, int end) {          this.start = start;          this.end = end;          sum = 0;          left = right = null;      }  }  class  SegmentTree{      private int size;   //区间      private SegmentTreeNode root;      public SegmentTree(int[] A) {          size = A.length;          root = buildTree(A,0, size - 1);      }      private SegmentTreeNode buildTree(int[] A, int start, int end) {          SegmentTreeNode node = new SegmentTreeNode(start, end);          //递归出口，叶子节点          if (start == end) {              node.sum = A[start];              return node;          }          //不是出口，递归建立左子树和右子树          int mid = (start + end) / 2;          node.left = buildTree(A, start, mid);          node.right = buildTree(A, mid + 1, end);          //别忘记维护当前节点的sum          node.sum = node.left.sum + node.right.sum;          return node;      }      //查询对外界接口      public long querySum(int start, int end) {          return querySum(root, start, end);      }      //重载方法.在node节点下查询原数组start到end区间内的和      private long querySum(SegmentTreeNode node, int start, int end) {          //递归出口          if (node.start == start &amp;&amp; node.end == end) {              return node.sum;          }          int mid = (node.start + node.end) / 2;          long leftSum = 0, rightSum = 0;          //左边区间          if (start &lt;= mid) {              //如果不是跨区间              if (end &lt;= mid) {                  leftSum = querySum(node.left, start, end);              } else {                  leftSum = querySum(node.left, start, mid);              }              //可以合并为一行 !!!!              // leftSum = querySum(node.left, start, Math.min(mid, end));          }          //要考虑右半区间，也就是start-end与右半区间有交集          if (end &gt;= mid + 1) {              //如果不是跨区间              if (start &gt;= mid + 1) {                  rightSum = querySum(node.right, start, end);              } else {                  rightSum = querySum(node.right, mid + 1, end);              }              // 可以合并为一句              // rightSum = querySum(node.right, Math.max(mid + 1, start), end);          }          return leftSum + rightSum;      }  }\n\n实现方法\npublic class Interval {      int start, end;      Interval(int start, int end) {          this.start = start;          this.end = end;      }  }  public List&lt;Long&gt; intervalSum(int[] A, List&lt;Interval&gt; queries) {      List&lt;Long&gt; res = new ArrayList&lt;&gt;();      SegmentTree segmentTree = new SegmentTree(A);      for (Interval query : queries) {          long sum = segmentTree.querySum(query.start, query.end);          res.add(sum);      }      return res;  }\n\n2、LintCode 207.  Interval Sum\n在类的构造函数中给一个整数数组, 实现两个方法 query(start, end) 和 modify(index, value):\n\n对于 query(start, end), 返回数组中下标 start 到 end 的 和。\n对于 modify(index, value), 修改数组中下标为 index 上的数为 value.\n\n\n比206多了modify，无法使用前缀和数组，暴力O(nm)，线段树/树状数组O(mlogn)，n为数组长度，m为操作次数。\n线段树类中提供三个方法\n\n构造器传入int[] A\nquerySum(int start, int end)\nmodify(int index, int val)\n\npublic class Solution {        private SegmentTree segmentTree;        public Solution(int[] A) {            if (A == null || A.length == 0) {                return;            }            segmentTree = new SegmentTree(A);        }        public long query(int start, int end) {            return segmentTree.querySum(start, end);        }        public void modify(int index, int value) {            segmentTree.modify(index, value);            return;        }    }    class SegmentTreeNode{        public int start, end;        public long sum;        public SegmentTreeNode left, right;        public SegmentTreeNode(int start, int end) {            this.start = start;            this.end = end;            sum = 0;            left = right = null;        }    }    class SegmentTree{        public SegmentTreeNode root;        public int size;        public SegmentTree(int[] A) {            size = A.length;            root = buildTree(A, 0, size - 1);        }        private SegmentTreeNode buildTree(int[] A, int start, int end) {            SegmentTreeNode node = new SegmentTreeNode(start, end);            //递归出口            if (start == end) {                node.sum = A[start];                return node;            }            //不是出口则递归建所有子树            int mid = (start + end) / 2;            node.left = buildTree(A, start, mid);            node.right = buildTree(A, mid + 1, end);            node.sum = node.left.sum + node.right.sum;            return node;        }        //公开接口        public long querySum(int start, int end) {            return querySum(root, start, end);        }        //公开接口        public void modify(int index, int val) {            modify(root, index, val);        }        private long querySum(SegmentTreeNode node, int start, int end) {            if (node.start == start &amp;&amp; node.end == end) {                return node.sum;            }            int mid = (node.start + node.end) / 2;  //这边不是start和end 是node的区间            long leftSum = 0, rightSum = 0;            if (start &lt;= mid) {                leftSum = querySum(node.left, start, Math.min(end, mid));            }            if (end &gt;= mid + 1) {                rightSum = querySum(node.right, Math.max(start, mid + 1), end);            }            return leftSum + rightSum;        }        private void modify(SegmentTreeNode node, int index, int val) {            //递归出口：到达这个叶子节点，并修改它的值            if (node.start == node.end &amp;&amp; node.end == index) {                node.sum = val;                return;            }            //递归：分为在左子树和右子树两种情况,不用求mid            if (node.left.end &gt;= index) {                modify(node.left, index, val);            } else {                modify(node.right, index, val);            }            //最后改下根            node.sum = node.left.sum + node.right.sum;        }    }\n\n3、LintCode 248. Count of Smaller Number统计比给定整数小的数的个数\n\n给定一个整数数组 （下标由 0 到 n-1，其中 n 表示数组的规模，数值范围由 0 到 10000），以及一个查询列表。对于每一个查询，将会给你一个整数，请你返回该数组中小于给定整数的元素的数量。\n输入: array =[1,2,7,8,5] queries =[1,8,5]输出:[0,4,2]\n\n时间复杂度：\n\n暴力求O(nm)，n为数组长度，m为查询次数\n线段树/树状数组O(mlogk)，m为查询次数，k为数组最大值\n二分,先排序，nlogn，然后查询比某个数小，只要得到它的位置即可，O(nlogn+mlogn)\n前缀和数组，线性，O(k+n+m)，本题较好的方式，但是扩展较为困难\n\n线段树思路：\n\n数组内元素范围在0～10000，用数组B[i]代表i这个值出现了多少次，那么查询比x小的元素只要计算B的前缀和B[0]+B[1]+…+B[x-1]，那就是查询B数组的某一个区间和，查询时间复杂度为logk（k为数组最大值）。这个题用前缀和也是非常的方便，但是遇到follow up就不行了。\n\npublic class Solution {        public List&lt;Integer&gt; countOfSmallerNumber(int[] A, int[] queries) {            int[] B = new int[10001];            for (int i : A) {                B[i]++;            }            //建立线段树，大小为10001            SegmentTree tree = new SegmentTree(10001);            for (int i = 0; i &lt; 10001; i++) {                tree.modify(i, B[i]);   //i位置修改为B[i]，表示这个数出现了多少次            }            List&lt;Integer&gt; res = new ArrayList&lt;&gt;();            for (int i : queries) {                if (i == 0) {                    res.add(0); //没有数比0小，都是正数                } else {                    res.add(tree.querySum(0, i - 1));                }             }            return res;        }    }    class SegmentTreeNode{        public int sum;        public  int start, end;        public  SegmentTreeNode left, right;        public SegmentTreeNode(int start, int end) {            this.start = start;            this.end = end;            sum = 0;            left = right = null;        }    }    class SegmentTree{        private int size;        private SegmentTreeNode root;        public SegmentTree(int size) {            this.size = size;            root = buildTree(0, size - 1);        }        //初始化得到的是全0的树        private SegmentTreeNode buildTree(int start, int end) {            SegmentTreeNode node = new SegmentTreeNode(start, end);            if (start == end) {                return node;            }            int mid = (start + end) / 2;            node.left = buildTree(start, mid);            node.right = buildTree(mid + 1, end);            return node;        }        public int querySum(int start, int end) {            return querySum(root, start, end);        }        //在node节点的子树下，查询[start,end]区间内维护的和        public int querySum(SegmentTreeNode node, int start, int end) {            if (node.start == start &amp;&amp; node.end == end) {                return node.sum;            }            int leftSum = 0, rightSum = 0;            int mid = (node.start + node.end) / 2;            if (start &lt;= mid) {                leftSum = querySum(node.left, start, Math.min(end, mid));            }            if (end &gt;= mid + 1) {                rightSum = querySum(node.right, Math.max(start, mid + 1), end);            }            return leftSum + rightSum;        }        public void modify(int index, int val) {            modify(root, index, val);        }        private void modify(SegmentTreeNode node, int index, int val) {            if (node.start == node.end &amp;&amp; node.end == index) {   //可以省略node.end == index                node.sum = val;                return;            }            if (node.left.end &gt;= index) {                modify(node.left, index, val);            } else {                modify(node.right, index, val);            }            //维护当前节点sum            node.sum = node.left.sum + node.right.sum;        }    }\n\n\n\n4、LintCode 249. Count of Smaller Number before itself统计前面比自己小的数的个数\n\n给定一个整数数组（下标由 0 到 n-1， n 表示数组的规模，取值范围由 0 到10000）。对于数组中的每个 ai 元素，请计算 ai 前的数中比它小的元素的数量。\n输入:[1,2,7,8,5]输出:[0,1,2,3,2]\n\n时间复杂度：\n\n暴力，O(n^2^)\n树状数组/线段树，O(nlogk)，n为数组长度，k为数组最大值\n\n思路：\n\n数组内范围为0～10000，假设数组B，B[i]表示数组A当前元素之前有多少个i（或者说B[i]表示A中有多少个i，只不过它是实时变化的）。查询比x小的数的个数相当于求B的x-1前缀和，B[0]+B[1]+…+B[x-1]\n\n\nA=[1,2,7,8,5] \nB=[0,0,0,0,0,0,0,0,0]    初始，这里B得开9，因为0～8一共9位\nB=[0,1,0,0,0,0,0,0,0]     B[1]++，统计比A中第二个元素(2)小的个数，B[0]+B[1]\nB=[0,1,1,0,0,0,0,0,0]     B[2]++，A中第三个元素为7，计算B[0]+…+B[6]\nB=[0,1,1,0,0,0,0,1,1]     B[7]++，A中第四个元素为8，计算B[0]+…+B[7]\nB=[0,1,1,0,0,1,0,1,1]     B[8]++，A中第五个元素为5，计算B[0]+…+B[4]\n\npublic class Solution {    public List&lt;Integer&gt; countOfSmallerNumberII(int[] A) {        List&lt;Integer&gt; res = new ArrayList&lt;&gt;();        SegmentTree tree = new SegmentTree(10001);        int[] B = new int[10001];        for (int i : A) {            if (i == 0) {                res.add(0);            } else {                res.add(tree.querySum(0, i - 1));            }            //更新B            B[i]++;            tree.modify(i, B[i]);        }        return res;    }}class SegmentTreeNode{    public int sum;    public  int start, end;    public SegmentTreeNode left, right;    public SegmentTreeNode(int start, int end) {        this.start = start;        this.end = end;        sum = 0;        left = right = null;    }}class SegmentTree{    private int size;    private SegmentTreeNode root;    public SegmentTree(int size) {        this.size = size;        root = buildTree(0, size - 1);    }    //初始化得到的是全0的树    private SegmentTreeNode buildTree(int start, int end) {        SegmentTreeNode node = new SegmentTreeNode(start, end);        if (start == end) {            return node;        }        int mid = (start + end) / 2;        node.left = buildTree(start, mid);        node.right = buildTree(mid + 1, end);        return node;    }    public int querySum(int start, int end) {        return querySum(root, start, end);    }    //在node节点的子树下，查询[start,end]区间内维护的和    public int querySum(SegmentTreeNode node, int start, int end) {        if (node.start == start &amp;&amp; node.end == end) {            return node.sum;        }        int leftSum = 0, rightSum = 0;        int mid = (node.start + node.end) / 2;        if (start &lt;= mid) {            leftSum = querySum(node.left, start, Math.min(end, mid));        }        if (end &gt;= mid + 1) {            rightSum = querySum(node.right, Math.max(start, mid + 1), end);        }        return leftSum + rightSum;    }    public void modify(int index, int val) {        modify(root, index, val);    }    private void modify(SegmentTreeNode node, int index, int val) {        if (node.start == node.end &amp;&amp; node.end == index) {   //可以省略node.end == index            node.sum = val;            return;        }        if (node.left.end &gt;= index) {            modify(node.left, index, val);        } else {            modify(node.right, index, val);        }        //维护当前节点sum        node.sum = node.left.sum + node.right.sum;    }}\n","categories":["Algorithm"],"tags":["Segment Tree"]},{"title":"ConcurrentHashMap 源码解读","url":"/2019/09/18/SourceCode-ConcurrentHashMap/","content":"ConcurrentHashMap碰到线程不安全场景下，需要使用 Map 的时候，我们第一个想到的 API 估计就是ConcurrentHashMap，ConcurrentHashMap 内部封装了锁和各种数据结构来保证访问 Map 是线程安全的。\n从类注释可以得到的信息是：\n\n所有的操作都是线程安全的\n多个线程同时进行 put、remove 等操作时并不会阻塞，可以同时进行\n迭代过程中，即使 Map 结构被修改，也不会抛 ConcurrentModificationException 异常\n除了数组 + 链表 + 红黑树的基本结构外，新增了转移节点，是为了保证扩容时的线程安全的节点\n提供了很多 Stream 流式方法，比如forEach、search、reduce 等等\n\n一、结构\nConcurrentHashMap 和 HashMap \n相同之处\n\n数组和链表的结构几乎一样，两个map对底层的操作思路是一样的，但是实现不一样。\n它们都实现了map接口，都继承了AbstractMap类，大多数方法都是相同的，我们需要把HashMap切换到ConcurrentHashMap也不需要考虑太多的兼容性问题。\n\n不同之处\n\n红黑树结构不同。HashMap红黑树的节点叫TreeNode，维护着红黑树的结构，比如新增节点、查找节点；ConcurrentHashMap中红黑树被拆分了，TreeNode仅维护属性和查找节点功能，并且新增了TreeBin，用来维护红黑树的结构，负责root的加锁和解锁。\n新增ForwardingNode，转移节点，扩容时，通过这个节点保证线程的安全。\n各种操作过程不是很相同\n\n二、put操作put是面试中的重中之重。在线程安全方面加入了一些代码。\n首先了解一下\nsynchronized是悲观锁，这种线程一旦得到锁，其他需要锁的线程就挂起的情况就是悲观锁。\nCAS是英文单词Compare And Set的缩写，翻译过来就是比较并设置。CAS操作的就是乐观锁，每次不加锁，而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。\n参考博客\nput步骤：\n\n如果table数组是空的，则初始化，否则就直接进入下一步\n根据key计算出hash值，找到槽点位置（也就是数组中的某个位置），进入自旋死循环！\n如果这个位置上没有值，通过cas来创建\n如果这个位置上有值，判断是不是在转移节点上（就是判断是不是正在扩容），如果在，则需要等待扩容结束\n在这个槽点上，先锁住这个槽点，保证只有一个线程进来了，再判断是链表还是红黑树，用各自的方法新增，红黑树的新增也改了，要锁住根节点\n新增完成后再判断下要不要扩容，这个是扩容的时机，和HashMap是一样的，但是扩容过程不一样\n\nfinal V putVal(K key, V value, boolean onlyIfAbsent) &#123;    if (key == null || value == null) throw new NullPointerException();  \t//计算key的hash    int hash = spread(key.hashCode());    int binCount = 0;    for (Node&lt;K,V&gt;[] tab = table;;) &#123;        Node&lt;K,V&gt; f; int n, i, fh;      \t//table是空的，进行初始化        if (tab == null || (n = tab.length) == 0)            tab = initTable();      \t//如果当前索引位置没有值，直接创建        else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123;          \t//cas 在 i 位置创建新的元素，当 i 位置是空时，即能创建成功，结束for循环，否则继续自旋            if (casTabAt(tab, i, null,                         new Node&lt;K,V&gt;(hash, key, value, null)))                break;                   // no lock when adding to empty bin        &#125;        //MOVED是转移节点的hash值，是一个固定的值        //如果当前索引位置是转移节点(MOVED)，表示该位置正在扩容，就会一直等待扩容完成        else if ((fh = f.hash) == MOVED)            tab = helpTransfer(tab, f);      \t//如果该位置上有值了        else &#123;            V oldVal = null;          \t//先把数组的节点node f锁住，其余线程不能操作            synchronized (f) &#123;              \t//这里再次判断 i 索引位置的数据没有被修改              \t//binCount 被赋值的话，说明走到了修改表的过程里面                if (tabAt(tab, i) == f) &#123;                  \t//链表的情况                    if (fh &gt;= 0) &#123;                        binCount = 1;                        for (Node&lt;K,V&gt; e = f;; ++binCount) &#123;                            K ek;                          \t//值有的话，直接返回                            if (e.hash == hash &amp;&amp;                                ((ek = e.key) == key ||                                 (ek != null &amp;&amp; key.equals(ek)))) &#123;                                oldVal = e.val;                                if (!onlyIfAbsent)                                    e.val = value;                                break;                            &#125;                            Node&lt;K,V&gt; pred = e;                          \t//把新增的元素赋值到链表的最后，退出自旋                            if ((e = e.next) == null) &#123;                                pred.next = new Node&lt;K,V&gt;(hash, key,                                                          value, null);                                break;                            &#125;                        &#125;                    &#125;                  \t//红黑树的情况，这里没有使用 TreeNode,使用的是 TreeBin                  \t//TreeBin 持有红黑树的引用，并且会对其加锁，保证其操作的线程安全                    else if (f instanceof TreeBin) &#123;                        Node&lt;K,V&gt; p;                        binCount = 2;                      \t//putTreeVal方法里面，给红黑树重新着色旋转时，会锁住红黑树的根节点                        if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key,                                                       value)) != null) &#123;                          \t//满足if的话，把老的值给oldVal                            oldVal = p.val;                            if (!onlyIfAbsent)                                p.val = value;                        &#125;                    &#125;                &#125;            &#125;          \t//binCount不为空，并且 oldVal 有值的情况，说明已经新增成功了            if (binCount != 0) &#123;              \t// 链表是否需要转化成红黑树                if (binCount &gt;= TREEIFY_THRESHOLD)                    treeifyBin(tab, i);                if (oldVal != null)                    return oldVal;                break;            &#125;        &#125;    &#125;  \t//check 容器是否需要扩容，如果需要去扩容，调用 transfer 方法去扩容  \t//如果已经在扩容中了，check有无完成    addCount(1L, binCount);    return null;&#125;\n\nConcurrentHashMap 在 put 过 程中，采用了哪些手段来保证线程安全。\n（1）数组初始化时的线程安全看一下initTable的源码\n  //初始化 table，通过对 sizeCtl 的变量赋值来保证数组只能被初始化一次private final Node&lt;K,V&gt;[] initTable() &#123;      Node&lt;K,V&gt;[] tab; int sc;    \t//通过自旋保证初始化成功      while ((tab = table) == null || tab.length == 0) &#123;        \t// 小于 0 代表有线程正在初始化，释放当前 CPU 的调度权，重新发起锁的竞争          if ((sc = sizeCtl) &lt; 0)              Thread.yield(); // lost initialization race; just spin                \t// CAS 赋值保证当前只有一个线程在初始化，-1 代表当前只有一个线程能初始化        \t// 保证了数组的初始化的安全性          else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123;            \t//CAS成功后再次判断有没有初始化完成              try &#123;                \t// 很有可能执行到这里的时候，table 已经不为空了，这里是双重 check                  if ((tab = table) == null || tab.length == 0) &#123;                    \t// 进行初始化                      int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY;                      @SuppressWarnings(&quot;unchecked&quot;)                      Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n];                      table = tab = nt;                      sc = n - (n &gt;&gt;&gt; 2);                  &#125;              &#125; finally &#123;                  sizeCtl = sc;              &#125;              break;          &#125;      &#125;      return tab;  &#125;\n\n数组初始化时，首先通过自旋来保证一定可以初始化成功，然后通过 CAS 设置 sizeCtl 变量的值，来保证同一时刻只能有一个线程对数组进行初始化，CAS 成功之后，还会再次判断当前数组是否已经初始化完成，如果已经初始化完成，就不会再次初始化，通过自旋 + CAS + 双重 check 等手段保证了数组初始化时的线程安全。\nsizeCtl：默认为0,sizeCtl中记录size大小的偏移量，用来控制table的初始化和扩容操作.它的数值有以下含义\n\n-1 :代表table正在初始化,其他线程应该交出CPU时间片,退出\n-N: 表示正有N-1个线程执行扩容操作\n&gt;0: 如果table已经初始化,代表table容量,默认为table大小的0.75,如果还未初始化,代表需要初始化的大小\n\n（2）新增槽点时的线程安全\n通过自旋死循环保证一定可以新增成功，for (Node&lt;K,V&gt;[] tab = table;;) \n\n当前槽点为空时，通过 CAS 新增\n\n这里没有在判断槽点为空的情况下直接赋值，因为在判断槽点为空和赋值的瞬间，很有可能槽点已经被其他线程赋值了，所以我们采用 CAS 算法，能够保证槽点为空的情况下赋值成功，如果恰好槽点已经被其他线程赋值，当前 CAS 操作失败，会再次执行 for 自旋，再走槽点有值的 put 流程。\n\n\n当前槽点有值，锁住当前槽点\n\n就是发生hash冲突的时候，此时数组上这个槽点，可能是链表、可能是红黑树，通过锁住槽点，保证同一时刻只有一个线程能对这个槽点进行修改。\n\n\n\n\n红黑树旋转时，锁住红黑树的根节点，保证同一时刻，当前红黑树只能被一个线程旋转\n\n\n\n\n\n（3）扩容时的线程安全ConcurrentHashMap 的扩容时机和 HashMap 相同，都是在 put 方法的最后一步检查是否需要扩容，但两者扩容过程完全不同。ConcurrentHashMap中put最后一步就是addCount方法，其中有一个transfer方法，它就是扩容方法。主要思路是：\n\n先把老数组中的值拷贝到扩容后的新数组上，从数组的尾巴开始拷贝\n\n拷贝数组的槽点时，先把原数组槽点锁住，保证原数组槽点不能操作，成功拷贝到新数组时，把原数组槽点赋值为转移节点\n\n这时如果有新数据正好需要 put 到此槽点时，发现槽点为转移节点，就会一直等待，所以在扩容完成之前，该槽点对应的数据是不会发生变化的\n\n从数组的尾部拷贝到头部，每拷贝成功一次，就把原数组中的节点设置成转移节点\n\n所有数组数据都拷贝到新数组时，直接把新数组整个赋值给数组容器，结束\n\n\n通过在原数组上设置转移节点，put 时碰到转移节点时会等待扩容成 功之后才能 put 的策略，来保证了整个扩容过程中肯定是线程安全的，因为数组的槽点一旦被 设置成转移节点，在没有扩容完成之前，是无法进行操作的。\nps：一开始我看的时候没看明白，这个意思是，把一个槽点拷贝完后，设置为转移节点，那就说明数组正在扩容，还没拷贝完，需要继续等待，如果这个槽点不是转移节点，那可以put，put完在拷贝到新数组上就可以了\n三、get操作读的话，就比较简单，先获取数组的下标，然后通过判断数组下标的 key 是否和我们的 key 相等，相等的话直接返回，如果下标的槽点是链表或红黑树的话，分别调用相应的查找数据的方法，整体思路和 HashMap 很像\npublic V get(Object key) &#123;    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek;  \t//计算键的hashcode    int h = spread(key.hashCode());  \t//不是空的数组 &amp;&amp; 并且当前索引的槽点数据不是空的，否则该key对应的值不存在，返回null    if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;        (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123;      \t//槽点第一个值和key相等，直接返回        if ((eh = e.hash) == h) &#123;            if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))                return e.val;        &#125;      \t//如果是红黑树或者转移节点，使用对应的find方法        else if (eh &lt; 0)            return (p = e.find(h, key)) != null ? p.val : null;      \t//如果是链表，遍历查找        while ((e = e.next) != null) &#123;            if (e.hash == h &amp;&amp;                ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))))                return e.val;        &#125;    &#125;    return null;&#125;\n\n四、问题（1）ConcurrentHashMap 和 HashMap 的相同点和不同点\n\n相同点\n\n都是数组 + 链表 +红黑树的数据结构，所以基本操作的思想相同，具体实现有所差别\n都实现了Map接口，都继承了AbstractMap类，方法差不多相似\n\n不同点\n\n前者线程安全，后者作为共享变量线程不安全\n数据结构上，HashMap用的是TreeNode，ConcurrentHashMap新增了TreeBin，以及转移节点，导致内部实现上有较大差别\n\n\n（2）ConcurrentHashMap 通过哪些手段保证了线程安全。\n\n\n储存 Map 数据的数组被 volatile 关键字修饰，一旦被修改，立马就能通知其他线程\nput时用的是无限死循环+cas算法来保证一定新增成功，如果put的时候，这个hash值正好是转移节点，会等扩容完毕再push，保证老数组的值不会变\n对数组槽点操作，会先锁住，然后再对链表或红黑树操作，对红黑树操作时也会锁住根节点，保证旋转时的线程安全。\n\n\n（3）ConcurrentHashMap 是如何发现当前槽点正在扩容的。\n\nConcurrentHashMap 新增了一个节点类型，叫做转移节点，当我们发现当前槽点是转移节点时(其 hash 值是 -1)，即表示 Map 正在进行扩容。\n\n（4）描述一下 CAS 算法在 ConcurrentHashMap 中的应用?\n\nhttps://www.jianshu.com/p/ae25eb3cfb5d\nCAS 其实是一种乐观锁，一般有三个值，分别为:赋值对象，原值，新值，在执行的时 候，会先判断内存中的值是否和原值相等，相等的话把新值赋值给对象，否则赋值失败，整个过 程都是原子性操作，没有线程安全问题。\nput 方法中，有使用到 CAS ，是结合无限 for 循环一起使用的，其步骤是\n\n首先计算出数组索引的下标，拿出下标对应的原值\n\nCAS 覆盖当前下标的值，赋值时，如果发现内存值和 1 拿出来的原值相等，执行赋值，退出\n循环，否则不赋值，进行下一次for循环\n\n\n\n（5）两种 Map 扩容时，有啥区别?\n\nHashMap 是直接在老数据上面进行扩容，ConcurrentHashMap 就不太一样，扩容过程是这样的：\n\n从数组的队尾开始拷贝\n拷贝数组的槽点时，先把原数组槽点锁住，拷贝成功到新数组时，把原数组槽点赋值为转移节点\n从数组的尾部拷贝到头部，每拷贝成功一次，就把原数组的槽点设置成转移节点，这样就把每一个槽点拷贝过来了\n所有数组数据都拷贝到新数组时，直接把新数组整个赋值给数组容器，拷贝完成\n\n简单来说，通过扩容时给槽点加锁，和发现槽点正在扩容就等待的策略，保证了 ConcurrentHashMap 可以慢慢地一个一个槽点的转移，保证了扩容时的线程安全\n\n（6）ConcurrentHashMap 在 Java 7 和 8 中关于线程安全的做法有啥不同?\n\n拿 put 方法为例，Java 7 的做法是:\n\n把数组进行分段，找到当前 key 对应的是那一段\n将当前段锁住，然后再根据 hash 寻找对应的值，进行赋值操作\n\nJava 7 的做法比较简单，缺点也很明显，就是当我们需要 put 数据时，我们会锁住改该数据对 应的某一段，这一段数据可能会有很多，比如我只想 put 一个值，锁住的却是一段数据，导致这一段的其他数据都不能进行写入操作，大大的降低了并发性的效率\n\n","categories":["JAVA"],"tags":["Source Code"]},{"title":"HashMap 源码解读","url":"/2019/09/12/SourceCode-HashMap/","content":"HashMap源码解读JDK 1.7中使用的是数组+链表，就是大学里数据结构课本上的那种实现\nJDK 1.8中，HashMap底层的数据结构是：数组+链表+红黑树。其中当链表的长度大于等于 8 时，链表会转化成红黑树，当红黑树的大小小于等于 6 时，红黑树会转化成链表，整体的数据结构如下:\n\n图中左边竖着的是 HashMap 的数组结构，数组的元素可能是单个 Node，也可能是个链表， 也可能是个红黑树\n换一张图，HashMap内部的结构，它可以看作是数组(Node[] table)和链表结合组成的复合结构，数组被分为一个个桶(bucket)，通过哈希值决定了键值对在这个数组的寻址；哈希值相同的键值对，则以链表形式存储你可以参考下面的示意图。这里需要注意的是，如果链表大小超过阈值(TREEIFY_THRESHOLD, 8)，图中的链表就会被改造为红黑树。\n\n一、类注释\n允许 null 值，不同于 HashTable，是线程不安全的\nload factor(影响因子) 默认值是 0.75，是均衡了时间和空间损耗算出来的值，较高的值会减少空间开销(扩容减少，数组大小增长速度变慢)，但增加了查找成本(hash 冲突增加，链表长度变长)，不扩容的条件：数组容量 &gt; 需要的数组大小 /load factor;\n如果有很多数据需要储存到 HashMap 中，建议 HashMap 的容量一开始就设置成足够的大小，这样可以防止在其过程中不断的扩容，影响性能;\n在迭代过程中，如果 HashMap 的结构被修改，会快速失败。\n\n二、常见属性//初始容量为16static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16//最大容量static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;//负载因子默认值static final float DEFAULT_LOAD_FACTOR = 0.75f;//桶上的链表长度大于等于8时，链表转化成红黑树static final int TREEIFY_THRESHOLD = 8;//桶上的红黑树大小小于等于6时，红黑树转化成链表static final int UNTREEIFY_THRESHOLD = 6;//当数组容量大于 64 时，链表才会转化成红黑树static final int MIN_TREEIFY_CAPACITY = 64;//记录迭代过程中 HashMap 结构是否发生变化，如果有变化，迭代时会 fail-fasttransient int modCount;//HashMap 的实际大小，可能不准(因为当你拿到这个值的时候，可能又发生了变化)transient int size;//存放数据的数组transient Node&lt;K,V&gt;[] table;// 扩容的门槛，有两种情况// 如果初始化时，给定数组大小的话，通过 tableSizeFor 方法计算，数组大小永远接近于 2 的幂次方（有一个公式的）// 如果是通过 resize 方法进行扩容，实际使用长度 = 数组容量 * 0.75int threshold;//链表的节点static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123;  //红黑树的节点static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; &#123;\n\n三、新增节点新增的步骤如下：\n\n空数组有没有初始化，没有的话需要初始化\n如果通过 key 的 hash 能够直接找到值，跳转到第6步，否则跳到第3步\n如果 hash 冲突，两种解决方案：链表 or 红黑树\n如果是链表，递归循环，把新元素追加到尾巴\n如果是红黑树，调用红黑树新增的方法\n通过 2、4、5 将新元素追加成功，再根据 onlyIfAbsent 判断是否需要覆盖\n判断是否需要扩容，需要扩容进行扩容，结束\n\n\n总结：要把键值对&lt;key,value&gt;放进去，首先会根据key计算出它的hash值，应该放到哪个位置，如果一开始数组是空的，那就会先resize初始化数组，初始化完后，就要去放键值对了，找到计算出的位置，如果那个索引位置是空的，就会直接新建Node，那就直接放在索引位置上，如果有值了，发生hash冲突了，那就要进行处理，判断是以红黑树还是链表的方式新增，递增完要更新版本号，并且如果HashMap的大小大于阈值了，就要resize，源码如下：\n  // 入参 hash:通过 hash 算法计算出来的值。// 入参 onlyIfAbsent:false 表示即使 key 已经存在了，仍然会用新值覆盖原来的值，默认为 false  final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123;    \t// n 表示数组的长度，i 为数组索引下标，p 为 i 下标位置的 Node 值      Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i;        \t//如果数组为空，使用 resize 方法初始化      if ((tab = table) == null || (n = tab.length) == 0)          n = (tab = resize()).length;        \t// 如果当前索引位置是空的，直接生成新的节点在当前索引位置上      if ((p = tab[i = (n - 1) &amp; hash]) == null)          tab[i] = newNode(hash, key, value, null);          // 如果当前索引位置有值(hash 冲突了),如何解决 hash 冲突      else &#123;        \t// e为当前节点的临时变量          Node&lt;K,V&gt; e; K k;                \t// 如果 key 的 hash 和值都相等，直接把当前下标位置的 Node 值赋值给临时变量          if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))              e = p;                \t// 如果是红黑树，使用红黑树的方式新增          else if (p instanceof TreeNode)              e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);                \t// 否则是个链表，把新节点放到链表的尾端          else &#123;            \t//自旋操作              for (int binCount = 0; ; ++binCount) &#123;                \t// e = p.next 表示从头开始，遍历链表\t\t\t\t\t\t\t\t// p.next == null 表明 p 是链表的尾节点                  if ((e = p.next) == null) &#123;                    \t// 把新节点放到链表的尾部                      p.next = newNode(hash, key, value, null);                    \t// 当链表的长度大于等于 8 时，链表转红黑树                      if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st                          treeifyBin(tab, hash);                      break;                  &#125;                \t// 链表遍历过程中，发现有元素和新增的元素相等，结束循环                  if (e.hash == hash &amp;&amp;                      ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))                      break;                \t//更改循环的当前元素，使 p 在遍历过程中，一直往后移动。                  p = e;              &#125;          &#125;        \t// 说明新节点的新增位置已经找到了          if (e != null) &#123; // existing mapping for key              V oldValue = e.value;            \t// 当 onlyIfAbsent 为 false 时，才会覆盖值              if (!onlyIfAbsent || oldValue == null)                  e.value = value;              afterNodeAccess(e);            \t// 返回老值              return oldValue;          &#125;      &#125;    \t// 记录 HashMap 的数据结构发生了变化      ++modCount;    \t//如果 HashMap 的实际大小大于扩容的门槛，开始扩容      if (++size &gt; threshold)          resize();      afterNodeInsertion(evict);      return null;  &#125;\n\n1、链表新增节点链表的新增比较简单，就是把当前节点追加到链表的尾部，和 LinkedList 的追加实现一样的。当链表长度大于等于 8 时，此时的链表就会转化成红黑树，转化的方法是treeifyBin（treeify是树化的意思），此方法有一个判断，当链表长度大于等于 8，并且整个数组大小大于 64 时，才会转成红黑树，当数组大小小于 64 时，只会触发扩容，不会转化成红黑树，转化成红黑树的过程也比较简单，具体转 化的过程源码可以去 github:https://github.com/luanqiu/java8 上面去查看。\n可能面试的时候，有人问你为什么是 8，这个答案在源码中注释有说，中文翻译过来大概的意思是：\n\n链表查询的时间复杂度是 O (n)，红黑树的查询复杂度是 O (log (n))。在链表数据不多的时候， 使用链表进行遍历也比较快，只有当链表数据比较多的时候，才会转化成红黑树，但红黑树需要的占用空间是链表的 2 倍（源码注释中写的），考虑到转化时间和空间损耗，所以要定义出这个转化的边界值：\n在设计 8 这个值的时候，参考了泊松分布概率函数，由泊松分布中得出结论，链表各个长度的命中概率为:\n* 0:    0.60653066* 1:    0.30326533* 2:    0.07581633* 3:    0.01263606* 4:    0.00157952* 5:    0.00015795* 6:    0.00001316* 7:    0.00000094* 8:    0.00000006\n\n\n当链表的长度是 8 的时候，出现的概率是 0.00000006，不到千万分之一，所以说正常情况下，链表的长度不可能到达 8 ，而一旦到达 8 时，肯定是 hash 算法出了问题，所以在这种情况下，为了让 HashMap 仍然有较高的查询性能，所以让链表转化成红黑树，我们正常写代码，使用 HashMap 时，几乎不会碰到链表转化成红黑树的情况，毕竟概念只有千万分之 一。\n\n2、红黑树新增节点\n首先判断新增的节点在红黑树上是不是已经存在，判断手段有如下两种：\n\n如果节点没有实现 Comparable 接口，使用 equals 进行判断;\n如果节点自己实现了 Comparable 接口，使用 compareTo 进行判断。\n\n\n新增的节点如果已经在红黑树上，直接返回;不在的话，判断新增节点是在当前节点的左边还是右边，左边值小，右边值大;\n\n自旋递归 1 和 2 步，直到当前节点的左边或者右边的节点为空时，停止自旋，当前节点即为我们新增节点的父节点;\n\n把新增节点放到当前节点的左边或右边为空的地方，并于当前节点建立父子节点关系;\n\n进行着色和旋转，结束。\n\n\n源码如下：\n   //入参h为hash值final TreeNode&lt;K,V&gt; putTreeVal(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab,int h, K k, V v) &#123;         Class&lt;?&gt; kc = null;         boolean searched = false;     \t\t//找到根节点         TreeNode&lt;K,V&gt; root = (parent != null) ? root() : this;     \t\t//自旋         for (TreeNode&lt;K,V&gt; p = root;;) &#123;             int dir, ph; K pk;           \t// p hash 值大于 h，说明 p 在 h 的右边（左小右大）             if ((ph = p.hash) &gt; h)                 dir = -1;           \t// p hash 值小于 h，说明 p 在 h 的左边             else if (ph &lt; h)                 dir = 1;           \t// 要放进去key在当前树中已经存在了(equals来判断)             else if ((pk = p.key) == k || (k != null &amp;&amp; k.equals(pk)))                 return p;           \t// 自己实现的Comparable的话，不能用hashcode比较了，需要用compareTo             else if ((kc == null &amp;&amp;                       // 得到key的Class类型，如果key没有实现Comparable就是null                       (kc = comparableClassFor(k)) == null) ||                      \t//当前节点pk和入参k不等                       (dir = compareComparables(kc, k, pk)) == 0) &#123;                 if (!searched) &#123;                     TreeNode&lt;K,V&gt; q, ch;                     searched = true;                     if (((ch = p.left) != null &amp;&amp;                          (q = ch.find(h, k, kc)) != null) ||                         ((ch = p.right) != null &amp;&amp;                          (q = ch.find(h, k, kc)) != null))                         return q;                 &#125;                 dir = tieBreakOrder(k, pk);             &#125;             TreeNode&lt;K,V&gt; xp = p;           \t//找到和当前hashcode值相近的节点(当前节点的左右子节点其中一个为空即可)             if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123;                 Node&lt;K,V&gt; xpn = xp.next;               \t//生成新的节点                 TreeNode&lt;K,V&gt; x = map.newTreeNode(h, k, v, xpn);               \t//把新节点放在当前子节点为空的位置上                 if (dir &lt;= 0)                     xp.left = x;                 else                     xp.right = x;               \t//当前节点和新节点建立父子，前后关系                 xp.next = x;                 x.parent = x.prev = xp;                 if (xpn != null)                     ((TreeNode&lt;K,V&gt;)xpn).prev = x;               \t//balanceInsertion 对红黑树进行着色或旋转，以达到更多的查找效率               \t//着色:新节点总是为红色;如果新节点的父亲是黑色，则不需要重新着色               \t//如果父亲是红色，则只能是黑色               \t//旋转: 父亲是红色，叔叔是黑色时，进行旋转               \t//如果当前节点是父亲的右节点，则进行左旋                \t//如果当前节点是父亲的左节点，则进行右旋                 //moveRootToFront 方法是把算出来的root放到根节点上                 moveRootToFront(tab, balanceInsertion(root, x));                 return null;             &#125;         &#125;     &#125;\n\n一般只会问到新增节点到红黑树上大概是什么样的一个过程，着色和旋转的细节不会问，因为很难说清楚，但我们要清楚着色指的是给红黑树的节点着上红色或黑色，旋转是为了让红黑树更加平衡，提高查询的效率，总的来说都是为了满足红黑树的 5 个原则：\n\n根是与叶子都是黑色\n节点是红色或黑色\n从任一节点到它每个叶子的所有简单路径都包含相同数目的黑色节点\n从每个叶子到根的所有路径上不能有两个连续的红色节点\n\n\n四、查找HashMap 的查找主要分为以下三步：\n\n根据 hash 算法定位数组的索引位置，equals 判断当前节点是否是我们需要寻找的 key，是的话直接返回，不是的话往下。\n判断当前节点有无 next 节点，有的话判断是链表类型，还是红黑树类型。\n分别走链表和红黑树不同类型的查找方法。\n\n\n链表查找关键源码如下\n// 采用自旋方式从链表中查找 key，e 初始为为链表的头节点do &#123;  // 如果当前节点 hash 等于 key 的 hash，并且 equals 相等，当前节点就是我们要找的节点  // 当 hash 冲突时，同一个 hash 值上是一个链表的时候，我们是通过 equals 方法来比较 key是否就是我们要找的那个  if (e.hash == hash &amp;&amp;      ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))    return e;  // 否则，把当前节点的下一个节点拿出来继续寻找&#125; while ((e = e.next) != null);\n\n红黑树查找代码思路：\n\n从根节点递归查找;\n\n根据 hashcode，比较查找节点，左边节点，右边节点之间的大小，根本红黑树左小右大的\n特性进行判断;\n\n判断查找节点在第 2 步有无定位节点位置，有的话返回，没有的话重复 2，3 两步;\n\n一直自旋到定位到节点位置为止。\n\n\n如果红黑树比较平衡的话，每次查找的次数就是树的深度。\n五、其他问题抛两个知乎专栏：专栏1、专栏2\n（1）初始容量为什么必须是2的幂次方？能不能传别的数进去？\nstatic final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16\n\n哈希桶的个数为2的幂次方， 在JDK1.7中，如果还没初始化它就会进行初始化，如果输入其他数字，它初始化的时候会调用一个roundUpToPowerOf2方法，就是把它调整为2的幂。hashCode一共是42亿个数，比如初始一共16个桶，你要把42亿个数放进16个桶里面，如果用取余操作，它缺点很多，比如要对负数额外进行处理，并且处理速度很慢，所以写JDK的有一个很鬼畜的操作，它们用了&amp;，他们将hash值与（length-1）与运算了一下。length是桶的个数（数组长度），它是2的幂次方，比如10000（16的2进制），2^4^-1 = 1111，这个时候把hash值跟它与操作，得到一个二进制数字，就得到了数组下标了，前面都是0根本不用管它。（位运算基本知识：和1做与操作取得这个位上的值）\n（2）JDK7中HashMap的问题\n\n\n引发HashMap死锁，见网页\n\n在多线程环境下，JDK 7中数组+链表的HashMap实现，有可能出现成环，然后就死循环，并且很难重现。视频讲解（30分钟左右）\nJAVA 7它是头插法，啥意思呢，比如我们本来有个hash表 某个节点上它是下面这样的\nNode1 -&gt; key:1,value:1 -&gt; key:2,value:2 -&gt; key:3,value:3经过扩容rehash后，变成了Node1 -&gt; key:3,value:3Node2 -&gt; key:2,value:2 -&gt; key:1,value:1\n\n因为它是头插法，我先把key=1的摘下来，插进一个新的节点，然后再把2摘下来，头插刀新的节点，2就变到了1的前面了！那这样一来顺序就反了。在多线程的情况下，线程调度本来就随机的嘛。原先是1-&gt;2，扩容后变为2-&gt;1，这样就可能出现死锁，出现环形链表。正常情况查找元素是找到头，往下挨个找，变成环，就有死循环了，线上系统cpu 100%。\n\n还有一个安全隐患，可以通过精心构造的恶意请求引发Dos\nTomcat使用了一个hash表来存储http的请求参数，那么就可以构造hashCode值一样的字符串，不断发送请求，这样直接导致hash表退化成链表，链表查找时间复杂度是O(n)，这样大大使得性能损耗， 1.7时通过hashSeeds这么一个补丁，就是对它再hash，来避免，接下来就到了1.8。\n\n\n\n\n（3）JDK 8中对HashMap的改进\n\n\n数组+链表+红黑树\n\n扩容时插入顺序的改进\nJDK 1.7是头插法，1.8改成了尾插把，特别加了个注释preserve order，保持顺序\n\n扩容\n之前讲了数组长度为什么是2的幂次方，这里扩容的时候，比如把2^4^扩容成2^5^，就是由1111变为11111，那么hashCode和它与运算，最高位要么多个1，要么多个0，后面四位不变的，那么它针对hash桶上某个index上对应的链表，这个链表会拆分成两部分，一部分留在原地，另一部分被移走了，这边就把这条链表拆分成了高位和低位，判断哪一部分是要移动的，并且移动的时候顺序是保持的，不会再像JDK 7中出现环，完事后，把高位链表和低位链表赋到新的hash桶中的index下去\n\n\n\n\n（4）hash方法怎么实现的？为什么要用异或^运算符\n\nJDK 1.8 中，是通过 hashCode() 的高 16 位异或低 16 位实现的：(h = k.hashCode()) ^ (h &gt;&gt;&gt; 16)，主要是从速度，功效和质量来考虑的，减少系统的开销，使用异或保证了对象的 hashCode 的 32 位值只要有一位发生改变，整个 hash() 返回值就会改变。尽可能的减少碰撞。\n\n","categories":["JAVA"],"tags":["Source Code"]},{"title":"双序列型动态规划","url":"/2019/12/11/dp-double-sequence/","content":"动态规划：双序列型双序列型，就是有两个子序列/字符串，每个序列本身是一维的，可以转换为二维dp，序列型开数组开n+1，双序列型也是开n+1。\n突破口：看串A和串B的最后一个字符是否匹配，是否需要串A/串B的最后一个字符，来缩减规模。\n两种类型：计数型：情况1+情况2+…以及最值型min/max{情况1，情况2…}\n初始条件：要特别当心空串的处理。\n1、LintCode 77 Longest Common Subsequence【问题】最长公共子序列。给出两个字符串，找到最长公共子序列(LCS)，返回LCS的长度。\n【分析】字符串A的长度为n，字符串B的长度为m，要组成最长公共子串一定是一个个对子，不能交叉，要按照顺序来，假设现在得到了最长公共子序列，有这么几种情况：\n\n字符串A的最后一个字符不在这个LCS中，那最长公共子串就是A中下标为0～n-2与B中下标为0～m-1的字符串的最长公共子序列。\n字符串B的最后一个字符不在这个LCS中，那最长公共字串就是B中下标为0～n-2与A中下标为0～m-1的字符串的最长公共子序列\n字符串A中的最后一个字符与B中的一个字符正好是一对，那最长公共字串就是A中下标为0～n-2与B中下标为0～m-2的字符串的最长公共子序列+A[n-1]\n\n【转移方程】dp[i] [j]代表A中前i个字符和B中前j个字符\n\ndp[i][j] = max{dp[i-1][j], dp[i][j-1], dp[i-1][j-1] + 1|A[i-1]=B[j-1]}\n\n时间复杂度O(MN)，空间复杂度O(MN)\npublic int longestCommonSubsequence(String A, String B) {        int n = A.length();        int m = B.length();        if (n == 0 || m == 0) {            return 0;        }        int[][] dp = new int[n + 1][m + 1]; //双序列型的本质还是序列型        //初始化第0行和第0列        for (int i = 0; i &lt;= m; i++) {            dp[0][i] = 0;        }        for (int i = 0; i &lt;= n; i++) {            dp[n][0] = 0;        }        for (int i = 1; i &lt;= n; i++) {            for (int j = 1; j &lt;= m; j++) {                dp[i][j] = Math.max(dp[i - 1][j], dp[i][j - 1]);                if (A.charAt(i - 1) == B.charAt(j - 1)) {                           dp[i][j] = Math.max(dp[i][j], dp[i - 1][j - 1] + 1);                }            }        }        return dp[n][m];    }\n\n可以用滚动数组优化空间复杂度至O(N)\nPlus：要求打印所有路径\nprivate static void LCS(String A, String B) {        int m = A.length();        int n = B.length();        int[][] dp = new int[m + 1][n + 1];        //初始化        int i, j;        for (j = 0; j &lt;= n; j++) {            dp[0][j] = 0;        }        for (i = 0; i &lt;= m; i++) {            dp[i][0] = 0;        }        for (i = 1; i &lt;= m; i++) {            for (j = 1; j &lt;= n; j++) {                //如果A的最后一个不在其中，或者是B的最后一个不在其中的情况                dp[i][j] = Math.max(dp[i - 1][j], dp[i][j - 1]);                //如果最后一个都在其中                if (A.charAt(i - 1) == B.charAt(j - 1)) {                    dp[i][j] = Math.max(dp[i][j], dp[i - 1][j - 1] + 1);    //+1 ！！！                }            }        }        //获得了dp数组，dfs获取结果        Set&lt;String&gt; set = new TreeSet&lt;&gt;();        dfs(\"\", m, n, A, B, dp, set);        //打印结果        for (String s : set) {            System.out.println(s);        }    }    private static void dfs(String temp, int i, int j, String A, String B, int[][] dp, Set&lt;String&gt; set) {        if (temp.length() == dp[A.length()][B.length()]) {            set.add(new StringBuilder(temp).reverse().toString());            return;        }        if (A.charAt(i - 1) == B.charAt(j - 1)) {   //只有相等时才添加            temp += A.charAt(i - 1);            dfs(temp, i - 1, j - 1, A, B, dp, set);        } else {            //上边更大            if (dp[i - 1][j] &gt;= dp[i][j - 1]) {                dfs(temp, i - 1, j, A, B, dp, set);            }            //左边更大            if (dp[i][j - 1] &gt;= dp[i - 1][j]) {                dfs(temp, i, j - 1, A, B, dp, set);            }        }    }\n\n2、LintCode 29 Interleaving String【问题】交错字符串。给出三个字符串：s1、s2、s3，判断s3是否由s1和s2交叉构成。\n\n输入：s1=“aabcc” s2=“dbbac”, s3=“aadbbcbcac” 输出：True( s3=“aadbbcbcac” )【分析】首先如果s3的长度不等于s1+s2的长度，直接输出false，设s1的长度为n，s2的长度为m，s3的长度为n+m，从最后一步出发，假设s3是由s1和s2交错构成的，那么s3的最后一个字符，要么是s1的最后一个字符，要么是s2的最后一个字符。这就是两种情况：\n\n\n如果是s1的最后一个字符，那么s3[0...n+m-2]是由s1[0..n-2]与s2[0..m-1]交错形成的\n如果是s2的最后一个字符，那么s3[0...n+m-2]是由s1[0..n-1]与s2[0..m-2]交错形成的\n\n这两种情况只要一种成立即可。\n【状态】dp[s][i][j]为s3前s个字符是否由A前i个字符A[0..i-1]和B前j个字符B[0..j-1]交错形成，这是最直观的，由于s = i + j，便可以开成两维，设dp[i][j]为s3前i+j个字符是否由A前i个字符 A[0..i-1]和B前j个字符B[0..j-1]交错形成。\n【转移方程】dp[i][j] = (dp[i-1] [j] &amp;&amp; s1[i] == s3[i+j-1]) || (dp[i][j-1] &amp;&amp; s2[j] == s3[]i+j-1)\n【初始条件】空串本身可以由s1的空串和s2的空串交错形成，dp[0][0] = true\n【边界情况】如果i=0，不考虑情况一,因为没有s1[i-1];如果j=0，不考虑情况二，因为没有s2[j-1]\n【计算顺序】\n\nf[0] [0], f[0] [1], …, f[0] [m]\nf[1] [0], f[1] [1], …, f[1] [m]\n……\nf[n] [0], f[n] [1], …, f[n] [m]\n\n时间复杂度O(NM)，空间复杂度O(NM)，可以用滚动数组优化\npublic boolean isInterleave(String s1, String s2, String s3) {        int n = s1.length();        int m = s2.length();        int l = s3.length();        if (l != n + m) {            return false;        }        boolean[][] dp = new boolean[n + 1][m + 1];        //初始化        dp[0][0] = true;        //需要把空串也纳入考虑        for (int i = 0; i &lt;= n; i++) {            for (int j = 0; j &lt;= m; j++) {                //如果是s1中最后一个字符                if (i &gt; 0 &amp;&amp; dp[i - 1][j] &amp;&amp; s1.charAt(i - 1) == s3.charAt(i + j - 1)) {                    dp[i][j] = true;                }                //如果是s2中最后一个字符                if (j &gt; 0 &amp;&amp; dp[i][j - 1] &amp;&amp; s2.charAt(j - 1) == s3.charAt(i + j - 1)) {                    dp[i][j] = true;                }            }        }        return dp[n][m];    }\n\n3、LintCode 119 Edit Distance【问题】编辑距离。给出两个单词word1和word2，计算出将word1 转换为word2的最少操作次数。你总共三种操作方法：插入一个字符、删除一个字符、替换一个字符。\n\n输入: \"horse\", \"ros\",输出: 3解释: horse -&gt; rorse (替换 'h' 为 'r')、rorse -&gt; rose (删除 'r')、rose -&gt; ros (删除 'e')\n\n【分析】要变成一模一样，一定要有个顺序的概念，不然会做起来很麻烦，比如从左往右的顺序。A长度为m，B长度为n，编辑过后A长度为n且与B的字符顺序一样。从最后一步出发，最后一步就是让A的最后一个字符变为B的最后一个字符，一共有三种操作，每种操作考虑一番，得到以下四种情况。\n\n情况一：A最后插入B[n-1]，才能转换为B，剩下要做的就是要先将A[0..m-1]（前面不动）变成B[0..n-2]\n情况二：A最后一个字符替换为B[n-1]，才能转换为B，剩下要做的就是要先将A[0..m-2]变成B[0..n-2]\n情况三：A删去最后一个字符，才能转换为B，剩下要做的就是要先将A[0..m-2]变成B[0..n-2]\n情况四：A和B最后一个字符相等，就是要先将A[0..m-2]变成B[0..n-2]\n\n【状态】dp[i][j]代表A中前i个字符和B中前j个字符的最小编辑距离\n【转移方程】dp[i][j] = min{dp[i][j-1]+1,dp[i-1][j-1]+1,dp[i-1][j]+1,dp[i-1][j-1] &amp;&amp; A[i-1] = B[j-1]}\n\n增加dp[i][j-1]+1 \n替换dp[i-1][j-1]+1\n删除dp[i-1][j]+1\n\n【初始条件】一个空串和一个长度为L的串的最小编辑距离是L\n【计算顺序】\n\nf[0] [0], f[0] [1], …, f[0] [m]\nf[1] [0], f[1] [1], …, f[1] [m]\n……\nf[n] [0], f[n] [1], …, f[n] [m]\n\n时间复杂度O(NM)，空间复杂度O(NM)，可以用滚动数组优化\npublic int minDistance(String A, String B) {        int n = A.length();        int m = B.length();        int[][] dp = new int[n + 1][m + 1];        int i, j;        //初始化，空串到任意非空串的编辑距离        for (j = 0; j &lt;= m; j++) {            dp[0][j] = j;        }        for (i = 0; i &lt;= n; i++) {            dp[i][0] = i;        }        for (i = 1; i &lt;= n; i++) {            for (j = 1; j &lt;= m; j++) {                dp[i][j] = Math.min(dp[i][j - 1] + 1, Math.min(dp[i - 1][j - 1] + 1, dp[i - 1][j] + 1));                if (A.charAt(i - 1) == B.charAt(j - 1)) {                    dp[i][j] = Math.min(dp[i][j], dp[i - 1][j - 1]);                }            }        }        return dp[n][m];    }\n\n4、LintCode 118 Distinct Subsequences【问题】给定字符串 S 和 T，计算 S 的所有子序列中有多少个 T。子序列字符串是原始字符串删除一些(或零个)字符之后得到的字符串，并且要求剩下的字符的相对位置不能改变。(比如 \"ACE\" 是 ABCDE 的一个子序列, 而 \"AEC\" 不是)\n\n输入: S = \"rabbbit\", T = \"rabbit\"输出: 3解释: 你可以删除 S 中的任意一个 'b', 所以一共有 3 种方式得到 T.输入: S = \"abcd\", T = \"\"输出: 1解释: 只有删除 S 中的所有字符这一种方式得到 T\n\n【分析】给定序列A和B，问B在A中出现多少次，可以不连续。相当于A和B的LCS是B，但这的侧重点是B。 从最后一步出发，就是B的最后一个字符，设A的长度为n，B的长度为m，有两种情况：\n\nB[m-1] != A[n-1]，需要考虑A[0..n-2]与B[0..m-1]\nB[m-1] = A[n-1]，只需考虑A[0..n-2]与B[0..m-2]\n问次数，就是考虑加法，无重复无遗漏。\n\n【转移方程】dp[i][j] = dp[i-1][j] + dp[i-1][j-1] &amp;&amp; A[i-1]=B[i-1]\n【初始条件】考虑空串\n\n若A是空串，B不是空串，B在A中出现次数为0，dp[0][j] = 0\n若B是空串，B在A中出现次数是1（A可以是空串），就是把A中的字符都删掉dp[i][0] = 1\n\n【计算顺序】\n\nf[0] [0], f[0] [1], …, f[0] [m]\nf[1] [0], f[1] [1], …, f[1] [m]\n……\nf[n] [0], f[n] [1], …, f[n] [m]\n\n时间复杂度O(NM)，空间复杂度O(NM)，可以用滚动数组优化成O(N)\npublic int numDistinct(String A, String B) {        int n = A.length();        int m = B.length();        int[][] dp = new int[n + 1][m + 1];        int i, j;        //初始化：若A是空串而B不是空串，则出现次数为0        for (j = 1; j &lt;= m; j++) {            dp[0][j] = 0;        }        //初始化：若B是空串，则出现次数为1        for (i = 0; i &lt;= n; i++) {            dp[i][0] = 1;        }        for (i = 1; i &lt;= n; i++) {            for (j = 1; j &lt;= m; j++) {                dp[i][j] = dp[i - 1][j];                if (A.charAt(i - 1) == B.charAt(j - 1)) {                    dp[i][j] += dp[i - 1][j - 1];                }            }        }        return dp[n][m];    }\n\n5、LintCode 154 Regular Expression Matching【问题】正则表达式匹配。实现支持.和*的正则表达式匹配。.匹配任意一个字母。*匹配零个或者多个前面的元素。匹配应该覆盖整个输入字符串，而不仅仅是一部分。\n\n需要实现的函数是：bool isMatch(string s, string p)isMatch(\"aa\",\"a\") → falseisMatch(\"aa\",\"aa\") → trueisMatch(\"aaa\",\"aa\") → falseisMatch(\"aa\", \"a*\") → trueisMatch(\"aa\", \".*\") → trueisMatch(\"ab\", \".*\") → trueisMatch(\"aab\", \"c*a*b\") → true\n\n【分析】从最后一步出发，关注最后进来的字符。假设A的长度为n，B的长度为m，关注正则表达式B的最后一个字符是谁，它有三种可能，正常字符、*、.\n\n如果B的最后一个字符是正常字符，那就是看A[n-1]是否等于B[m-1]，相等则看A[0..n-2]与B[0..m-2]，不等则是不能匹配，break\n\n如果B的最后一个字符是.，它能匹配任意字符，直接看A[0..n-2]与B[0..m-2]\n\n如果B的最后一个字符是*它代表B[m-2]=c可以重复0次或多次，它们是一个整体c*\n\n情况一：A[n-1]是0个c，B最后两个字符废了，能否匹配取决于A[0..m-1]和B[0..n-3]是否匹配\n情况二：A[n-1]是多个c中的最后一个（这种情况必须A[n-1]=c或者c='.'），所以A匹配完往前挪一个，B继续匹配，因为可以匹配多个，继续看A[0..n-2]和B[0..m-1]是否匹配。\n\n\n\n【转移方程】dp[i] [j]代表A的前i个和B的前j个能否匹配\n\n对于1和2，可以合并成一种情况dp[i][j] = dp[i-1][j-1] (if A[i-1]=B[j-1] || B[j-1]='.')\n\n对于3，分为不看c*和看c*两种情况\n\n不看：直接砍掉dp[i][j] = dp[i][j-2]\n看：dp[i][j] = dp[i-1][j](if A[i-1]=B[j-2] || B[j-2]='.')\n\n\n\n【初始条件】考虑空串空正则\n\n空串和空正则是匹配的，dp[0][0] = true\n非空串和空正则必不匹配，dp[1][0]=...=dp[n][0]=false\n空串和非空正则，不能直接定义true和false，必须要计算出来。（在1、2中不能计算，在3中dp[i][j] = dp[i][j-2]可能出现，比如A=\"\",B=a*b*c*）\n大体上可以分为空正则和非空正则两种\n\n【计算顺序】\n\nf[0] [0], f[0] [1], …, f[0] [m]\nf[1] [0], f[1] [1], …, f[1] [m]\n……\nf[n] [0], f[n] [1], …, f[n] [m]\n\n时间复杂度O(NM)，空间复杂度O(NM)，可以用滚动数组优化成O(N)\npublic boolean isMatch(String A, String B) {        int n = A.length();        int m = B.length();        boolean[][] dp = new boolean[n + 1][m + 1];        for (int i = 0; i &lt;= n; i++) {            for (int j = 0; j &lt;= m; j++) {                //分为空正则与非空正则两种讨论                if (j == 0) {                    if (i == 0) {                        dp[i][j] = true;                    } else {                        dp[i][j] = false;                    }                } else {                    //非空正则，大致分为最后一个是不是 *                    if (B.charAt(j - 1) != '*') {                        if (i &gt; 0 &amp;&amp; (A.charAt(i - 1) == B.charAt(j - 1) || B.charAt(j - 1) == '.')) {                            dp[i][j] = dp[i - 1][j - 1];                        }                    } else {                        //最后一个是 * ，分为不看和看两种情况                        //不看                        if (j &gt;= 2) {                            dp[i][j] |= dp[i][j - 2];                        }                        //看                        if (i &gt;= 1 &amp;&amp; j &gt;= 2 &amp;&amp; (A.charAt(i - 1) == B.charAt(j - 2) || B.charAt(j - 2) == '.')) {                            dp[i][j] |= dp[i - 1][j];                        }                    }                }            }        }        return dp[n][m];    }\n\n6、LintCode 192 Wildcard Matching【问题】通配符匹配，上一题是正则表达式匹配。判断两个可能包含通配符？和*的字符串是否匹配。匹配规则如下：?可以匹配任何单个字符，* 可以匹配任意字符串（包括空字符串）。两个串完全匹配才算匹配成功。\n【分析】通配符匹配和正则表达式匹配很像，正则表达式中的.与通配中的?作用是一样的，不同的是*，正则表达式中的*能匹配零个或者多个前面的元素，通配中的*能匹配0个或多个任意字符，实际上通配的情况要比正则表达式中的情况简单得多。仍然从B的最后一个字符出发，有三种可能：正常字符、?、*，讨论如下：（前两条情况和正则表达式一样）\n\n如果B的最后一个字符是正常字符，那就是看A[m-1]是否等于B[n-1]，相等则看A[0..m-2]与B[0..n-2]，不等则是不能匹配，break\n\n如果B的最后一个字符是？，它能匹配任意字符，直接看A[0..m-2]与B[0..n-2]\n\n如果B的最后一个字符是*，他能匹配0个或多个任意字符，那就分为两种情况\n\n匹配0个：就是这个*直接废了，需要看A[0..n-1]与B[0..m-2]\n匹配多个：则需要看A[0..n-2]与B[0..m-1]\n\n\n\n【转移方程】dp[i] [j]代表A的前i个和B的前j个能否匹配\n\n对于1和2，可以合并成一种情况dp[i][j] = dp[i-1][j-1] (if A[i-1]=B[j-1] || B[j-1]='?')\n对于3，分为不看c*和看c*两种情况\n匹配0个，就是不看，直接砍掉：dp[i][j] = dp[i][j-1]\n匹配多个：dp[i][j] = dp[i-1][j](if B[j-1]='*')\n\n\n\n【初始条件】大体上依旧是分为空正则和非空正则两种\n\n空正则和空串匹配\n空正则和非空串必不匹配\n非空正则和空串需要看情况\n\n【计算顺序】\n\nf[0] [0], f[0] [1], …, f[0] [m]\nf[1] [0], f[1] [1], …, f[1] [m]\n……\nf[n] [0], f[n] [1], …, f[n] [m]\n\n时间复杂度O(NM)，空间复杂度O(NM)，可以用滚动数组优化成O(N)\npublic boolean isMatch(String A, String B) {        int n = A.length();        int m = B.length();        boolean[][] dp = new boolean[n + 1][m + 1];        for (int i = 0; i &lt;= n; i++) {            for (int j = 0; j &lt;= m; j++) {                //空正则与非空正则两种情况讨论                if (j == 0) {                    if (i == 0) {                        dp[i][j] = true;                    } else {                        dp[i][j] = false;                    }                } else {                    //分为最后一个字符是不是 * 的两种情况                    if (B.charAt(j - 1) != '*') {                        if (i &gt; 0 &amp;&amp; (A.charAt(i - 1) == B.charAt(j - 1) || B.charAt(j - 1) == '?')) {                            dp[i][j] = dp[i - 1][j - 1];                        }                    } else {                        //分为匹配0个和匹配多个两种情况,这里j必定&gt;1                        //匹配0个                        dp[i][j] |= dp[i][j - 1];                        if (i &gt; 0) {                            dp[i][j] |= dp[i - 1][j];                        }                    }                }            }        }        return dp[n][m];    }\n\n7、LintCode 668 Ones And Zeroes【问题】假设你分别是 m个 0 和 n个 1 的统治者。 另一方面, 有一个只包含 0 和 1 的字符串构成的数组。现在你的任务是找到可以由 m个 0 和 n个 1 构成的字符串的最大个数。每一个 0 和 1 均只能使用一次\n\n输入：[\"10\", \"0001\", \"111001\", \"1\", \"0\"] 5 3输出：4解释：这里总共有 4 个字符串可以用 5个 0s 和 3个 1s来构成, 它们是 \"10\", \"0001\", \"1\", \"0\"。输入：[\"10\", \"0001\", \"111001\", \"1\", \"0\"] 7 7输出：5解释：所有字符串都可以由7个 0s 和 7个 1s来构成.\n\n【分析】如果没有0，只有1，这就相当于背包问题。这边只是多了个0，用背包思路考虑，看最后一个物品有没有进去，就是分为放和不放两种情况：\n\n情况一：不放，最后一个字符串（物品）没有进去，一共给定了T个串，那就是去看前T-1个串中，用给的0和1最多能组成多少个01串\n情况二：放，最后一个字符串（物品）进去了，最后一个串中有多少个0和1，那么就在m和n中减去，比如最后一个串中有j个0，k个1，那么剩下0就是m-j，剩下1就是n-k，看这些剩下的在前T-1个串中最多能组成多少个。\n\n【转移方程】用dp[i][j][k]代表前i个串最多能有多少个被j个0和k个1组成\n\ndp[i][j][k] = max{dp[i-1][j][k],dp[i-1][j-a][k-b]}，a代表放的这个01串中0的个数，b代表放的这个01串中1的个数。\n\n【转移方程】前0个串，最多组成0个\n\nf[0][0~m][0~n] = 0\n\n【答案】dp[T][m][n]，len为字符串的个数\n时间复杂度:O(Tmn)，空间复杂度:O(Tmn)，可以用滚动数组优化至 O(mn)\npublic int findMaxForm(String[] strs, int m, int n) {        int len = strs.length;        if (len == 0) {            return 0;        }        int[][][] dp = new int[len + 1][m + 1][n + 1];        int i, j, k;        //初始化        for (j = 0; j &lt;= m; j++) {            for (k = 0; k &lt;= n; k++) {                dp[0][j][k] = 0;            }        }        for (i = 1; i &lt;= len; i++) {            for (j = 0; j &lt;= m; j++) {                for (k = 0; k &lt;= n; k++) {                    //不放                    dp[i][j][k] = dp[i - 1][j][k];                    //放                    String s = strs[i - 1];                    char[] chs = s.toCharArray();                    int count0 = 0, count1 = 0;                    for (int l = 0; l &lt; chs.length; l++) {                        if (chs[l] == '0') {                            count0++;                        } else {                            count1++;                        }                    }                    if (j &gt;= count0 &amp;&amp; k &gt;= count1) {                        dp[i][j][k] = Math.max(dp[i][j][k], dp[i - 1][j - count0][k - count1] + 1);                    }                }            }        }        return dp[len][m][n];    }\n\n滚动数组优化，当前的i之和前一个i-1有关联，空间复杂度O(mn)\npublic int findMaxForm(String[] strs, int m, int n) {        int len = strs.length;        if (len == 0) {            return 0;        }        int[][][] dp = new int[2][m + 1][n + 1];        int i, j, k;        //初始化        for (j = 0; j &lt;= m; j++) {            for (k = 0; k &lt;= n; k++) {                dp[0][j][k] = 0;            }        }        int old = 0, now = 0;        for (i = 1; i &lt;= len; i++) {            old = now;            now = 1 - now;            for (j = 0; j &lt;= m; j++) {                for (k = 0; k &lt;= n; k++) {                    //不放                    dp[now][j][k] = dp[old][j][k];                    //放                    String s = strs[i - 1];                    char[] chs = s.toCharArray();                    int count0 = 0, count1 = 0;                    for (int l = 0; l &lt; chs.length; l++) {                        if (chs[l] == '0') {                            count0++;                        } else {                            count1++;                        }                    }                    if (j &gt;= count0 &amp;&amp; k &gt;= count1) {                        dp[now][j][k] = Math.max(dp[now][j][k], dp[old][j - count0][k - count1] + 1);                    }                }            }        }        return dp[now][m][n];    }\n\n","categories":["Algorithm"],"tags":["Dynamic programming"]},{"title":"序列型动态规划","url":"/2019/12/10/dp-sequence/","content":"序列型dp就是序列+状态，直接看几个例子。\n1、LintCode 515 Paint House【问题】这里有n个房子在一列直线上，现在我们需要给房屋染色，分别有红色蓝色和绿色。每个房屋染不同的颜色费用也不同，你需要设计一种染色方案使得相邻的房屋颜色不同，并且费用最小，返回最小的费用。费用通过一个nx3 的矩阵给出，比如cost[0][0]表示房屋0染红色的费用，cost[1][2]表示房屋1染绿色的费用。\n【分析】典型的序列型动态规划，序列型动态规划 = 序列+状态。确定状态，一共三种\n\n如果最优策略中，最后一栋是红色，那么倒数第二栋只能是蓝色或绿色\n如果最优策略中，最后一栋是蓝色，那么倒数第二栋只能是红色或绿色\n如果最优策略中，最后一栋是绿色，那么倒数第二栋只能是蓝色或红色\n\n那么需要分别记录倒数第二栋房子是红色、蓝色、绿色的最小花费即可，只要最后一栋和倒数第二栋颜色不一样。\n初始条件：序列型dp需要开n+1行，每列表示一种状态，dp[0][0] = dp[0][1] = dp[0][2] = 0，第0栋房子花费是0。\npublic int minCost(int[][] costs) {        if (costs.length == 0) {            return 0;        }        int rows = costs.length;        //序列型动态规划，一共三种颜色，一共要rows栋房子，另外加一个第0栋存放初始值        int[][] dp = new int[rows + 1][3];        //初始化第0栋        dp[0][0] = dp[0][1] = dp[0][2] = 0;        //i是第i栋房子        for (int i = 1; i &lt; dp.length; i++) {            //第i栋房子要染成3种颜色种的哪一种            for (int j = 0; j &lt; 3; j++) {                dp[i][j] = Integer.MAX_VALUE;                //前i-1栋房子的颜色                for (int k = 0; k &lt; 3; k++) {                    if (j != k) {                        dp[i][j] = Math.min(dp[i][j], dp[i - 1][k] + costs[i-1][j]);                    }                }            }        }        return Math.min(dp[rows][0], Math.min(dp[rows][1], dp[rows][2]));    }\n\n2、LintCode 516 Paint House II【问题】这里有n个房子在一列直线上，现在我们需要给房屋染色，共有k种颜色。每个房屋染不同的颜色费用也不同，你需要设计一种染色方案使得相邻的房屋颜色不同，并且费用最小。费用通过一个nxk 的矩阵给出，比如cost[0][0]表示房屋0染颜色0的费用，cost[1][2]表示房屋1染颜色2的费用。\n【分析】原来是三种颜色，现在变成k种颜色\n第一种写法，直接把刚才的3改成现在的k，时间复杂度O(NK^2^)\npublic static int minCostII(int[][] costs) {        if (costs == null || costs.length == 0 || costs[0].length == 0) {            return 0;        }        int n = costs.length;        int m = costs[0].length;        int[][] dp = new int[n + 1][m];     //序列型        dp[0][0] = 0;   //第0栋耗费为0        //从第一栋房子开始        for (int i = 1; i &lt;= n; i++) {            //第一栋房子的三种颜色            for (int j = 0; j &lt; m; j++) {                dp[i][j] = Integer.MAX_VALUE;                //前一栋房子                for (int k = 0; k &lt; m; k++) {                    if (j != k) {                        dp[i][j] = Math.min(dp[i][j], dp[i - 1][k] + costs[i - 1][j]);                    }                }            }        }        int min = Integer.MAX_VALUE;        for (int i = 0; i &lt; dp[0].length; i++) {            if (dp[n][i] &lt; min) {                min = dp[n][i];            }        }        return min;    }\n\n优化：上面的思路每次需要求f[i-1][1], ..., f[i-1][K]中除了一个元素之外，其他元素的最小值。这里解决思路是保存最小值和次小值，首先把f[i-1][1], ..., f[i-1][K]中的最小值和次小值先记录下来。\n\n如果除掉的元素不是最小值，那剩下的最小值就是最小值它本身\n如果除掉的元素是最小值，那剩下的元素中，最小值就是次小值\n\n假设i-1栋房子，最小值是f[i-1][a]，次小值是f[i-1][b]，如果第i栋染颜色a，那么最小花费就是加上次小值，否则就是加上最小值。\n时间复杂度O(NK)\npublic static int minCostII(int[][] costs) {        if (costs == null || costs.length == 0 || costs[0].length == 0) {            return 0;        }        int n = costs.length;       //房屋数        int m = costs[0].length;    //颜色个数        int[][] dp = new int[n + 1][m];        for (int i = 0; i &lt; dp[0].length; i++) {    //初始化第一行，第0栋            dp[0][i] = 0;        }        int min1, min2; //min1存放最小值，min2存放次小值        int id1 = 0;   //id1存放最小值的颜色下标，id2存放次小值的颜色下标        int id2 = 0;        for (int i = 1; i &lt;= n; i++) {            min1 = min2 = Integer.MAX_VALUE;            //第i-1栋房子的最小花费和次小花费            for (int j = 0; j &lt; m; j++) {                //如果当前值比最小值还小，就把最小值先传递给次小值，再更新最小值,其次还要更新id                if (dp[i - 1][j] &lt; min1) {                    min2 = min1;                    id2 = id1;                    min1 = dp[i - 1][j];                    id1 = j;                }                //如果当前值比次小值小，但比最小值大，只需要更新次小值                else {                    if (dp[i - 1][j] &lt; min2) {                        min2 = dp[i - 1][j];                        id2 = j;                    }                }            }            for (int j = 0; j &lt; m; j++) {                //如果和i-1栋颜色不一样,那就直接加最小值，否则加次小值                if (j != id1) {                    dp[i][j] += min1 + costs[i - 1][j];                } else {                    dp[i][j] += min2 + costs[i - 1][j];                }            }        }        int res = Integer.MAX_VALUE;        for (int j = 0; j &lt; dp[0].length; j++) {            if (res &gt; dp[n][j]) {                res = dp[n][j];            }        }        return res;    }\n\n3、LintCode 392 House Robber【问题】假设你是一个专业的窃贼，准备沿着一条街打劫房屋。每个房子都存放着特定金额的钱。你面临的唯一约束条件是：相邻的房子装着相互联系的防盗系统，且 当相邻的两个房子同一天被打劫时，该系统会自动报警。给定一个非负整数列表，表示每个房子中存放的钱， 算一算，如果今晚去打劫，在不触动报警装置的情况下, 你最多可以得到多少钱 。\n简而言之，不能偷相邻两家，求最多能偷多少金币。\n【分析】从最后一步出发，最后一栋房子i是偷还是不偷\n\n偷i，结果 = 第i栋的金币数 + 前i-2（包括i-2）栋偷得的总额\n不偷i，结果 = 前 i-1（包括i-1） 栋房子的最优策略\n\n两个状态，用0表示不偷，用1表示偷\n\n第i栋不偷，i-1可偷可不偷，dp[i][0] = max{dp[i-1][0], dp[i-1][1]}\n第i栋选择偷，i-1不能偷，dp[i][1] = dp[i-1][0] + A[i-1]\n\n//一般写法public static long houseRobber(int[] A) {        int n = A.length;        long[][] dp = new long[n + 1][2];        //初始化第0栋房屋        dp[0][0] = dp[0][1] = 0;        for (int i = 1; i &lt;= n; i++) {            //不偷            dp[i][0] = Math.max(dp[i - 1][0], dp[i - 1][1]);            //偷            dp[i][1] = dp[i - 1][0] + A[i - 1];        }        return Math.max(dp[n][0], dp[n][1]);    }\n\n简化：偷i栋房子时，i-1肯定不能偷，直接去问前i-2栋一功能偷多少，不偷i栋时，问前i-1栋能偷多少\n\ndp[i] = max{dp[i-1], dp[i-2] + A[i-1]}\n\npublic static long houseRobber(int[] A) {        int n = A.length;        if (n == 0) {            return 0;        }        if (n == 1) {            return A[0];        }        long[] dp = new long[n + 1];        dp[0] = 0;  //前0栋房子，0        dp[1] = A[0];        for (int i = 2; i &lt;= n; i++) {            dp[i] = Math.max(dp[i - 2] + A[i - 1], dp[i - 1]);        }        return dp[n];    }\n\n使用滚动数组优化\npublic static long houseRobber2(int[] A) {        int n = A.length;        if (n == 0) {            return 0;        }        if (n == 1) {            return A[0];        }        long old = 0;   //dp[0]        long now = A[0];    //dp[1]        for (int i = 2; i &lt;= n; i++) {            long t = Math.max(old + A[i - 1], now);            old = now;            now = t;        }        return now;    }\n\n4、LintCode 534 House Robber II【问题】上一题是一排房子，现在是一圈房子，然后不能偷任何挨着的两家，求最多能偷多少金币。\n【分析】现在第一栋房子和最后一栋房子成了邻居，首尾不能同时偷，就有两种情况：①偷第一栋，最后一栋不能偷，②偷最后一栋，第一栋不能偷。所以只要分别计算去头和去尾两种情况，取一个最大值即可。\npublic static int houseRobber2(int[] nums) {        int n = nums.length;        if (n == 0) {            return 0;        }        if (n == 1) {            return nums[0];        }        int[] A = new int[n - 1];        long res = Integer.MIN_VALUE;        for (int i = 0; i &lt; n - 1; i++) {            A[i] = nums[i];     //去尾的情况        }        res = Math.max(res, calc(A));        for (int i = 0; i &lt; n - 1; i++) {            A[i] = nums[i+1];       //去头的情况        }        res = Math.max(res, calc(A));        return (int) res;    }    public static long calc(int[] A) {        int n = A.length;        if (n == 0) {            return 0;        }        if (n == 1) {            return A[0];        }        long old = 0;   //dp[0]        long now = A[0];    //dp[1]        for (int i = 2; i &lt;= n; i++) {            //now = dp[i-1],old = dp[i-2]            long t = Math.max(old + A[i - 1], now);            old = now;            now = t;        }        return now;    }\n\n5、LintCode 149 买卖股票的最佳时机I【问题】假设有一个数组，它的第i个元素是一支给定的股票在第i天的价格。如果你最多只允许完成一次交易(例如,一次买卖股票),设计一个算法来找出最大利润。\n【分析】维护到当前位置i的最小值，利润 = 当天卖出价格 - 最小值价格，更新res数组\npublic int maxProfit(int[] prices) {        int n = prices.length;        if (n == 0 || n &lt; 2) {            return 0;        }        int minVal = prices[0];        int res = 0;        for (int i = 0; i &lt; n; i++) {            minVal = Math.min(minVal, prices[i]);            res = Math.max(res, prices[i] - minVal);        }        return res;    }\n6、LintCode 149 买卖股票的最佳时机II【问题】给定一个数组 prices 表示一支股票每天的价格.你可以完成任意次数的交易, 不过你不能同时参与多个交易 (也就是说, 如果你已经持有这支股票, 在再次购买之前, 你必须先卖掉它).设计一个算法求出最大的利润。\n简而言之：I中只能买卖一次，现在可以买卖任意多次，任何时刻最多持有一股，求获得的最大利润。\n【分析】贪心，只要今天价格比昨天价格高，就卖掉，这里贪心就是最优的，因为抓住了每一个上升段\npublic int maxProfit(int[] prices) {        int n = prices.length;        if (n &lt; 2) {            return 0;        }        int res = 0;        for (int i = 1; i &lt; n; i++) {            if (prices[i] - prices[i - 1] &gt; 0) {\t\t//只要比昨天价格高，就卖掉                res += prices[i] - prices[i - 1];            }        }        return res;    }\n\n7、LintCode 151 买卖股票的最佳时机III——序列型【问题】假设你有一个数组，它的第i个元素是一支给定的股票在第i天的价格。设计一个算法来找到最大的利润。你最多可以完成两笔交易。你不可以同时参与多笔交易(你必须在再次购买前出售掉之前的股票)\n限定交易次数为2次，不能手里同时有两支股票，可以同一天卖完后买入\n【分析】需要记录已经买卖多少次。最后一步就是最后一次卖掉，发生在第j天，需要枚举最后一次买是在第几天，但不知道之前有没有买卖过，所以需要记录状态，一共五种状态如下所示\n\n阶段1、3、5手里虽然没股票，但是境界不一样，分别是买卖过0次、1次、2次\n阶段2、4是持有股票阶段，可以选择持有股票或卖出\n最优策略必定处于阶段1、3、5，不可能处于2、4，买了不卖，那就亏了。所以需要求在阶段1、阶段3、阶段5时三种清仓状态下的最大获利分别是多少。\n\n【状态转移方程】\n\ndp[i][j]表示前i天（第i-1）天结束后，在阶段j的最大获利\n阶段1、3、5，无股票状态，两种可能：昨天无股票并保持无股票状态 或 昨天有股票今天卖出\ndp[i][j] = max{dp[i-1][j],dp[i-1][j-1] + prices[i-1] - prices[i-2]}\n\n\n阶段2、4，手里持有股票，两种可能：昨天有股票并保持有股票状态（获利和亏损都有可能，要加上） 或 昨天没股票今天买入\ndp[i][j] = max{dp[i-1][j] + prices[i-1] - prices[i-2],dp[i-1][j-1]}\n\n\n\n【初始化与边界】\n\ndp[0][1] = 0;dp[0][2] = ... = dp[0][5] = Integer.MIN_VAULE\n注意几个边界\n最多买卖两次，必定在清仓状态下获利最多\n\npublic int maxProfit(int[] prices) {        int n = prices.length;        int[][] dp = new int[n + 1][5 + 1];        //初始化        dp[0][1] = 0;        for (int i = 2; i &lt;= 5; i++) {            dp[0][i] = Integer.MIN_VALUE;        }        //遍历n天的价格        for (int i = 1; i &lt;= n; i++) {            //阶段1、3、5，手里不持有股票            for (int j = 1; j &lt;= 5; j += 2) {                dp[i][j] = dp[i - 1][j];                //肯定是第一个阶段以后的，所以j&gt;1,且上一个阶段dp[i - 1][j - 1]不能为无穷小                if (i - 2 &gt;= 0 &amp;&amp; j &gt; 1 &amp;&amp; dp[i - 1][j - 1] != Integer.MIN_VALUE) {                    //继续不持有，或者昨天持有，今天卖掉变为不持有                    dp[i][j] = Math.max(dp[i - 1][j], dp[i - 1][j - 1] + prices[i - 1] - prices[i - 2]);                }            }            //阶段2、4，手里持有股票            for (int j = 2; j &lt;= 4; j += 2) {                //从上一个不持有的阶段变为持有                dp[i][j] = dp[i - 1][j - 1];                //不用判断j，从阶段2开始，且昨天持有时dp[i - 1][j]不能为无穷小                if (i - 2 &gt;= 0 &amp;&amp; dp[i - 1][j] != Integer.MIN_VALUE) {                    //继续持有，继续获利，或是今天才买入                    dp[i][j] = Math.max(dp[i - 1][j] + prices[i - 1] - prices[i - 2], dp[i - 1][j - 1]);                }            }        }        return Math.max(dp[n][1], Math.max(dp[n][3], dp[n][5]));    }\n\n8、LintCode 393 买卖股票的最佳时机IV【问题】在买卖股票的最佳时机III的中，买卖次数为2次，在这里变为K次买卖。\n【分析】原来2次买卖股票，分为5个阶段，现在K次买卖，就分成了2K+1次\n\n阶段1、3、5...2K+1都是没有持有股票的阶段\n阶段2、4、6...2K都是持有股票的阶段\n\n这样就能直接套买卖股票III中的模版了，但是解题时发现超时，因为当K &gt; N/2时，直接退化为任意次买卖股票了，需要特殊考虑，解题代码如下\npublic int maxProfit(int K, int[] prices) {        int n = prices.length;        if (K &gt; n / 2) {            int res = 0;            for (int i = 1; i &lt; n; i++) {                if (prices[i] - prices[i - 1] &gt; 0) {                    res += prices[i] - prices[i - 1];                }            }            return res;        } else {            int[][] dp = new int[n + 1][2 * K + 1 + 1];            //初始化            dp[0][1] = 0;            for (int i = 2; i &lt;= 2 * K + 1; i++) {                dp[0][i] = Integer.MIN_VALUE;            }            for (int i = 1; i &lt;= n; i++) {                                //阶段1、3、5...2K+1，不持有股票                for (int j = 1; j &lt;= 2 * K + 1; j += 2) {                    //初始是继续保持不持有的状态                    dp[i][j] = dp[i - 1][j];                    if (i &gt;= 2 &amp;&amp; j &gt; 1 &amp;&amp; dp[i - 1][j - 1] != Integer.MIN_VALUE) {                        //保持不持有的状态或是昨天有股票，今天卖出                        dp[i][j] = Math.max(dp[i - 1][j], dp[i - 1][j - 1] + prices[i - 1] - prices[i - 2]);                    }                }                //阶段2、4、6...2K，持有股票的阶段                for (int j = 2; j &lt;= 2 * K; j += 2) {                    //初始是从不持有的阶段过来                    dp[i][j] = dp[i - 1][j - 1];                    if (i &gt;= 2 &amp;&amp; dp[i - 1][j] != Integer.MIN_VALUE) {                        //继续保持持有阶段并获利，或是昨天没有，今天买入                        dp[i][j] = Math.max(dp[i - 1][j] + prices[i - 1] - prices[i - 2], dp[i - 1][j - 1]);                    }                }            }            int res = Integer.MIN_VALUE;            for (int i = 1; i &lt;= 2 * K + 1; i += 2) {                res = Math.max(res, dp[n][i]);            }            return res;        }    }\n\n9、LintCode 76 最长上升子序列【问题】给定一个整数序列，找到最长上升子序列（LIS），返回LIS的长度。这里可以不连续，因为是子序列，不是子串。\n【分析】假设最长上升子序列是以a[j]结尾的，那么子序列中倒数第二个元素必定比a[j]小\n\n很容易得出f[j] = max{1, f[i] + 1 | i &lt; j &amp;&amp; a[i] &lt; a[j]}，答案是其中的最大值\n\n写出如下代码，这里我试着打印子序列的路径，时间复杂度为O(N^2^)\npublic static int longestIncreasingSubsequence(int[] nums) {        int n = nums.length;        if (n == 0) {            return 0;        }        int[] dp = new int[n];        int[] path = new int[n];    //记录路径        int end = -1;        int res = Integer.MIN_VALUE;        for (int i = 0; i &lt; n; i++) {            dp[i] = 1;            path[i] = -1;   //初始路径为-1            for (int j = 0; j &lt; i; j++) {                if (nums[j] &lt; nums[i]) {                    dp[i] = Math.max(dp[i], dp[j] + 1);                    //如果第i个个来自j处，那就更新                    if (dp[i] == dp[j] + 1) {                        path[i] = j;                    }                }            }            res = Math.max(res, dp[i]);            //记下来是在哪结束的            if (res == dp[i]) {                end = i;            }        }        int[] temp = new int[res];        for (int i = 0; i &lt; temp.length; i++) {            temp[i] = nums[end];            end = path[end];        }        for (int i = temp.length - 1; i &gt;= 0; i--) {            System.out.print(temp[i] + \" \");        }        return res;    }\n\n优化：时间复杂度为O(nlogn)\n/**     * 优化成O(N logN),看到这个就只有二分法了     * 优化:一旦前面有两个dp值一样了，比如dp[i] = dp[j],并缺nums[i] &gt; nums[j] ，那就只要考虑第j个就可以了     * 也就是 同样的dp值，存一个坐标，这个坐标对应的nums[index]值最小。那么对于每个dp值，保存一下对应的nums[i]的值     * 序列是单调上升的，在单调上升中找最后一个比自己小的数用二分法     * 我们开个数组，数组的下表为dp值，对应存的是该dp值下最小的nums[idx]     */    //1、使用 binarySearch()    public static int longestIncreasingSubsequence(int[] nums) {        if (nums == null || nums.length == 0) {            return 0;        }        int n = nums.length;        int[] a = new int[n];        int res = 0;        for (int i = 0; i &lt; nums.length; i++) {            //在a数组的这个区间内找有没有nums[i]，如果key在数组中，则返回搜索值的索引；否则返回-1或“-”（插入点）。插入点是索引键将要插入数组的那一点            int index = Arrays.binarySearch(a, 0, res, nums[i]);            //如果如果这个数比之前的数大，就找不到插入位置，它就会在新位置插入，如果这个数比之前的数小，就会直接覆盖之前的数            if (index &lt; 0) {                index = -index - 1;            }            //把这个数放在插入点上            a[index] = nums[i];            if (index == res) {                res++;            }        }        return res;    }    /**     * 使用TreeSet     * TreeSet基本操作全是log(n)复杂度（欢迎纠正），时间复杂度也一致。     * TreeSet.ceiling(x)方法可以直接找出set中大于x的最小数字，如果不存在则返回null。     *     * 1. 如果这个数字存在，则删除这个数字，然后把x插入set中，相当于代替该数字。     * 2. 如果这个数字不存在，说明x大于set中任何数字，直接把x插入set中。     * 最后返回set的大小即可。     */    public int longestIncreasingSubsequence(int[] nums) {        TreeSet&lt;Integer&gt; set = new TreeSet&lt;&gt;();        for (int num : nums) {            Integer ceiling = set.ceiling(num);            //如果set中大于num的最小数字存在，删除这个数字，放入num            if (ceiling != null) {                set.remove(ceiling);            }            set.add(num);        }        return set.size();    }\n\n10、LintCode 602 俄罗斯套娃信封【问题】给一定数量的信封，带有整数对 (w, h) 分别代表信封宽度和高度。一个信封的宽高均大于另一个信封时可以放下另一个信封。求最多嵌套多少个信封。\n【分析】这个属于最长序列型dp，dp都是从最后一步出发，先考虑最后一步，也就是最后一个信封Ei，然后考虑次外层信封，一定是某个Ej，并且Ej里面嵌套的信封也是最多的。得出\n\ndp[i] = max{1,dp[j] + 1}（①只能这一个信封，②Ej能放进Ei中）dp[i]表示以信封Ei为最外层信封时，最多嵌套层数。\n\n由于有宽和高两个维度，我们选择一个维度，比如选择宽度，先按照以宽度升序排序\n下面算法是正常思路，但时间复杂度为O(N^2^)，在Lintcode上通过不了，必须要O(nlogn)，但在Leetcode上能通过。\npublic int maxEnvelopes(int[][] envelopes) {        if (envelopes == null || envelopes.length == 0) {            return 0;        }        //首先对信封按长度进行升序排序，如果长度一样则按照宽度进行升序排序/*        Arrays.sort(envelopes, new Comparator&lt;int[]&gt;() {            @Override            public int compare(int[] o1, int[] o2) {                int res = o1[0] - o2[0];                    if (res == 0) {                    return o1[1] - o2[1];                } else {                    return res;                }            }        });*/  \t\t//直接用lamda表达式        Arrays.sort(envelopes, Comparator.comparing((int[] a) -&gt; a[0]).thenComparing((int[] a) -&gt; a[1]));        int n = envelopes.length;        int[] dp = new int[n];        int res = Integer.MIN_VALUE;        for (int i = 0; i &lt; n; i++) {            //初始化,别忘记            dp[i] = 1;            //i前面所有的信封            for (int j = 0; j &lt; i; j++) {                if (envelopes[i][0] &gt; envelopes[j][0] &amp;&amp; envelopes[i][1] &gt; envelopes[j][1]) {                    dp[i] = Math.max(dp[i], dp[j]+1);                }            }            res = Math.max(res, dp[i]);        }        return res;    }\n\n使用二分优化，原理和最长上升序列一样\n//使用二分    public int maxEnvelopes2(int[][] envelopes) {        if (envelopes == null || envelopes.length == 0 || envelopes[0] == null || envelopes[0].length != 2) {            return 0;        }        // 先按 w 升序排序，再按 h 降序 排序！！        // 然后只需考虑h即可，因为w已经升序排列好，因为h大的在前，所以相同的w下的不同h，只会选择最大的那个h，来看以这个h结尾的最长上升子序列        // 当w相同的情况下，h高的在前面，也就是说同样w中是不可能满足increasing subsequence的序列存在，所以任何的increasing subsequence的w一定都是升序的        // 就可以将问题转换为 h 的 Longest Increasing subSequence        Arrays.sort(envelopes, Comparator.comparing((int[] a) -&gt; a[0]).thenComparing((int[] a) -&gt; a[1], Comparator.reverseOrder()));        int dp[] = new int[envelopes.length];        int len = 0;        for (int[] a : envelopes) {            int index = Arrays.binarySearch(dp, 0, len, a[1]);            if (index &lt; 0) {                index = -index - 1;            }            dp[index] = a[1];            if (index == len) {                len++;            }        }        return len;    }","categories":["Algorithm"],"tags":["Dynamic programming"]},{"title":"数据仓库","url":"/2019/11/05/DataWarehouse/","content":"目录第二章 数据仓库\n第三章 数据预处理\n第四章 特征化和区分\n数据挖掘\n第五章 关联规则挖掘\n第六章 分类挖掘\n第七章 聚类挖掘\n第二章 数据仓库1、B树索引考题：为何B树等在数据库中广泛使用的索引技术无法直接被引入数据仓库？\n1、B树要求属性必须具有许多不同的值，比如身份证号这种取值字段，取值范围很广，几乎没有重复。2、B树要求查询应具有更简单的条件和更少的结果3、创建B树的空间复杂度和时间复杂度很大\n\n\n2、位图索引 BitMap Index位图索引分为两种，简单位图索引和编码位图索引，考试时候会让你画简单位图索引。\n（1）简单位图索引对于每个属性，将属性中的不同取值生成不同的位向量！有几个不同的取值就有几个不同的位向量。如果数据表中某一元组的属性 值为 v，则在位图索引的对应行表示该值的位为 1，该行的其它位为 0。 \n例如：\n如果我们要找买了b产品的女性，计算时候首先取出b产品和女性F向量做&amp;操作\n\nb：0 0 1 1 1 0 0 0\nF：1 0 1 1 0 1 0 0\n\n0 0 1 1 0 0 0 0\n\n发现第3位和第4位为1，表示第三行、第四行数据是我们要的结果\n\n位图索引适合只有几个固定值的列，如性别、婚姻状况、行政区等等，对于性别，可取值的范围只有’男’,’女’，并且男和女可能各站该表的50%的数据，这时添加B树索引还是需要取出一半的数据， 因此完全没有必要。如果某个字段的取值范围很广，几乎没有重复，比如身份证号，就不适合用位图索引，适合B树索引。\n3、连接索引 Join Index适用于复杂的查询！复杂的查询往往需要多表连接，使用连接索引能提高性能。考试时候要求画出连接索引怎么画？\n先说下什么是事实表、维表。事实表就是你要关注的内容，比如各种销售数据，通常包含大量的行。维表就是你观察该事物的角度，你从哪个角度去查看这个内容？比如对于销售数据，可以从某个地区的来看，地区就是维度。\n例如，在一个星型模式中，事实表 Sales 与维表 Customer 和 Item 三者之间的链接关系如图所示。\n\n它们的连接索引表如图所示。 \n\n4、数据仓库存储策略在逻辑模型设计的基础上确定数据存储结构、索引策略、存储分配和数据存放位置等与物理有关的内容，与数据库设计中大致相似。\n常用技术\n\n合并表表的连接操作消耗很多时间，将表合并后存放，可以节约连接的时间，这是以空间换时间的策略\n数据序列将连续使用的数据连续存储，原先表示逻辑的部分可以继续存在\n引入冗余此处特指将一个属性从一张表扩散到其它表的过程，这个过程中，冗余就可以节约访问的连接次数\n表的物理分割类似逻辑设计阶段的数据分割，用拆分的表来表达原有逻辑意义上的一张表\n生成导出数据如果某张表的统计数据被频繁访问，这部分聚集数据就可以另行记录\n建立广义索引记录与“最”有关的统计结果。这部分数据非常小，又可以在数据刷新阶段直接建立，进行此类查询时就可以将统计操作转换为简单查找所以不用B树索引！\n\n5、数据仓库（1）数据仓库的出现？建立数据仓库不是要替代传统的事务处理系统和数据库，而是在新的领域中更加适应分析型处理的需要。数据仓库正成为信息集成的主要手段之一。\n其出现目的：\n\n提高两个系统的性能\n提高操作性数据库的事务吞吐量\n两个系统中的数据结构、内容和用法可以不同\n\n（2）数据仓库的特点/特征\n面向主题\n主题就是企业中某一领域涉及到的分析对象，面向主题就是说：数据仓库内的信息是按照主题进行组织的。主题是要经过抽取得出的\n\n集成\n全部数据放置在同一个地方，形成完整、一致的数据汇总\n\n非易失\n数据仓库的数据与操作型数据环境隔离\n\n时变\n数据仓库随时都是一个只读的备份，每隔一段时间完成一次对数据仓库的刷新\n\n\n6、OLAPOLAP即联机分析处理，通过专门的数据综合引擎，辅以更加直观的数据访问界面，在短时间内相应非数据处理专业人员的复杂查询要求。\n（1）OLAP特点\nOLAP是面向特定问题的联机数据访问和分析OLAP是只读的工具，这是与SQL的巨大差异\n通过对信息多种可能的观察形式进行快速、稳定一致和交互性的存取多个“维度”\n允许决策人员对数据进行深入观察以人为主导\n\n（2）OLAP的基本数据模型\nMOLAP多维数据库\n\nROLAP\n用事实表的二维模型存放度量值，定义大量外关键字指向维度\n\n星形模型\n雪花模型\n\n\n\n详细介绍ROLAP\n\n星型模式\n\nn维的多维表有一个事实表和n个维表增加一个新的维度，就增加一个维表，从而易于扩充\n应对多维查询时，依赖标准SQL将事实表与维表进行连接与聚集\n星型模式的优势在于架构一旦确定下来，影响架构的宏观因素就很少，可以以基本固定的方式进行优化\n\n\n雪花模型\n\n对星型模式的扩展某些维表并不是单一的平面结构，所有维属性的地位并不等同\n优点\n更加适应人类的理解和观察内在的关联性通过将子维表分列而体现出来\n规范化的设计趋势节约存储空间\n\n\n缺点\n结构远比星型模式复杂\n额外进行的多次连接造成性能损失\n即使维数相同，表的结构也可能有很大差异难以优化\n\n\n\n\n其它扩展模式\n\n星座模式通过公共维度连接多个星型模式\n雪暴模式通过公共维度连接多个雪花模型\n\n\n\n7、数据立方体数据立方体是一种多维数据模型，主要有星形模式、雪花模式和事实星座模式。\n\n星形模式它是最常见的模式，它包括一个大的中心表（事实表），包含了大批数据但是不冗余；一组小的附属表（维表），每维一个。如下所示，从item、time、branch、location四个维度去观察数据，中心表是Sales Fact Table，包含了四个维表的标识符（由系统产生）和三个度量。每一维使用一个表表示，表中的属性可能会形成一个层次或格。\n\n雪花模式它是星模式的变种，将其中某些表规范化，把数据进一步的分解到附加的表中，形状类似雪花。 \n\n事实星座\n允许多个事实表共享维表，可以看作是星形模式的汇集。如下所示，Sales和Shipping两个事实表共享了time、item、location三个维表。\n\n\n\n在数据仓库中多用事实星座模式，因为它能对多个相关的主题建模；而在数据集市流行用星形或雪花模式\n8、多维数据分析手段\n切片\n\n只看与该维成员相关的数据，就是降维\n\n切块\n\n可以认为是切片的复合操作，维度可能无法下降，但数据量得以减少\n\n旋转\n\n交换维度的排列顺序，获取全新的呈现方式。高维的旋转操作会很有用，交换了某些维度的焦点\n\n上钻\n\n将层次较低的数据集提高层次，上钻不会变更观察的主体\n\n下钻\n\n上钻的逆操作，降低数据层次，上钻与下钻并不能无限地进行下去，下界为原子层。\n\n其它操作\n跨钻同步地对多个多维模型进行上钻或下钻，方便进行多个事实的对比\n\n\n钻透\n下钻到数据立方体最低细节后，继续细化到数据仓库/数据库的关系型表格\n可以发现一些错误\n\n\n\n9、数据仓库的设计见ppt\n第三章 数据预处理1、数据预处理过程\n数据清洗\n\n缺失值、噪声、非一致\n\n\n数据集成\n\n模式集成、发现冗余、数据值冲突检测和处理 \n\n\n数据变换\n\n光滑、聚集、泛化、规范化、属性构造 \n\n\n数据规约\n\n数据立方体聚集、属性子集选择、维度规约、数值规约、离散化和概念 分层产生 \n\n\n数据离散化\n\n数值数据\n\n分箱、直方图、聚类、基于熵的离散化、基于直观划分离散化 \n\n\n分类数据\n\n用户或专家在模式级显示说明属性偏序，层次高，属性值个数越少 \n\n\n\n\n\n2、数据清洗噪声数据：测量变量时出现的随机错误或是差异，出现原因可能是属性值不正确（数据收集工具问题、数据的输入或传输问题等）以及数据不完整、不一致、重复记录产生的\n针对噪声数据的处理方法：分箱/分桶、聚类、人工检查、回归\n简单离散化方法：分箱\n\n等宽分箱 equip-width\n 将范围分为相等大小的N个间隔  \n\n\n 间隔的宽度将为：W =（B-A）/ N  （属性最高值-最低值）/N个间隔\n\n\n\n\n等深分箱 equip-depth\n分成N个间隔，每个间隔样本数相同\n\n\n\n分箱后需要平滑数据，主要方法有：按箱平均值平滑、按箱中值平滑、按箱边界平滑\n3、数据集成与变换数据集成主要讲了去除冗余啥的，这边主要看数据转换的方式\n（1）数据变换\n平滑\n消除噪声数据\n\n\n聚合\n汇总数据\n\n\n泛化\n概念层次爬升，就是概念化\n\n\n归一化\n缩放数据到指定范围内\n\n\n属性/特征构造\n\n（2）归一化的三种方式\nmin-max normalization\n\nvalue’ =（value-最小值）/（最大值-最小值）\n\n\nZ-score normalization \nZ标准化也叫标准差标准化，这种方法给予原始数据的均值（mean）和标准差（standard deviation）进行数据的标准化。\n\n\nnormalization by decimal scaling\n进制缩放归一化。这种方法通过移动数据的小数点位置来进行标准化。小数点移动多少位取决于属性A的取值中的最大绝对值。公式中j是满足条件的最小整数。例如 假定A的值由-986到917，A的最大绝对值为986，为使用小数定标标准化，我们用每个值除以1000（即，j=3），这样，-986被规范化为-0.986。\n\n\n4、数据规约 Data Reduction，即数据规约，PPT中提到了4中策略\n\n\n数据立方体聚合\n降维\nNumerosity reduction\n离散化和概念层次生成\n\n观察往年试卷，考过离散化         maxdiff：先给数据排序，给定β个桶或是分组，相邻数据的最大差是β-1，超过这个最大差就不能放进一个桶。\n例子：有个疑惑，最小方差每组算出来为什么要x2？\n离散化的其他方法\n\n基于熵的离散化      Entropy-based discretization  \n给定一组样本S，如果使用边界T将S划分为两个区间S1和S2，则划分后的熵为\n选择在所有可能的边界上使熵函数最小的边界作为二进制离散化。该过程将递归应用于获得的分区，直到满足某些停止条件为止。\n\n3-4-5规则\n3-4-5规则可用于将数字数据分段为相对均匀的“自然”间隔。\n看这个博客！\n\n如果间隔的最高有效位数涵盖3、6、7或9个不同的值，则将范围划分为3个等宽间隔\n如果它的最高有效位涵盖2、4或8个不同的值，请将范围划分为4个间隔\n如果它的最高有效位涵盖1、5或10个不同的值，请将范围划分为5个间隔\n\n\n\n第四章 特征化和区分废话\n数据挖掘1、数据挖掘（1）数据挖掘是什么？数据挖掘=数据库里的知识发现，在大量的、完整的数据中进行挖掘，总结规律、得出知识，来指导客观世界。\n（2）数据挖掘基本概念\n模式\n任何用高级语言表达一定逻辑含义的信息都是模式（信息+判断）\n\n\n知识\n满足用户对客观评价标准（支持度/置信度……）和主观评价标准要求的模式\n\n\n置信度 condidence\n某个数据集上，模式成立的程度，例如在购买面包和黄油的顾客中，大部分的人同时也买了牛奶，该模式的置信度为：同时购买面包、黄油、牛奶的顾客人数占同时购买面包、黄油的顾客人数的百分比。\n置信度不是固定的\n没有足够的置信度，模式也不能称为知识\n\n\n支持度 support\n某一数据集上，模式被用户关注的程度，也叫做兴趣度\n\n\n非平凡性\n平凡的知识不是数据挖掘的目标，因为这样的知识已经成为常识，我们要找的是不平凡的知识\n\n\n\n（3）数据挖掘和数据仓库啥关系？\n数据挖掘原本建立在数据库的基础之上\n产生数据仓库技术后由于数据仓库中的数据都是经过抽取、整理和预处理后的综合数据，因而数据挖掘工作可以在数据仓库上直接运行，任务相对来说会简单很多，但并不代表数据挖掘可以无缝地架设在数据仓库之上\n\n（4）数据挖掘步骤\n数据的集成\n\n没数据怎么行？一般都集成到数据仓库\n\n在数据仓库要对数据预处理\n\n清洗、集成、转换、减少\n\n\n\n\n数据规约\n\n用于数据挖掘的数据量非常巨大，数据规约可以减低数据量，提高数据挖掘操作的性能\n\n常见的数据规约技术\n\n数据立方体计算\n挖掘范围的选择\n在不影响挖掘结果的前提下，尽可能地选取那些与挖掘操作有关的属性集，去除明显无关的因素，或由于法规、风俗等原因，即使有相应的分析结果也无法应用的\n时间范围或备份内容上的选择\n\n\n数据压缩减低数据的规模，节省存储空间开销和数据通讯开销，如果采用的数据挖掘算法不需要解压就可直接对压缩数据进行挖掘，数据压缩技术将非常有用\n离散化处理将属性值的连续区域划分为若干个区域，用每个区域的标识代替原来的值，以减低该属性上属性值的个数，也可利用这种数据规约技术来自动地建立该属性的概念层次树\n\n\n\n\n挖掘\n\n挖掘方法\n关联规则挖掘–第五章\n分类挖掘–第六章\n聚类挖掘–第七章\n\n\n\n\n表示\n\n可以包括文字、图形、表格、图标等可视化形式\n\n\n\n第五章：关联规则挖掘1、关联规则资料\n\n关联规则用于表示事务数据库中诸多属性之间的关联程度\n\n关联规则挖掘则是利用数据库中的大量数据通过关联算法寻找属性间的相关性\n\n属性在这里被称为 项\n若干个属性所构成的属性集被称为一个 项集\n\n例：超级市场在购买商品A的客户中有90%的人会同时购买商品B，则可用关联规则表示为：\nR1：A-&gt;B 表示一条规则\n\nA-&gt;B与B-&gt;A的支持度是相同的，但置信度通常不同\n\n任意组合均能构成关联规则\n为了发现有意义的关联规则，需要给定两个阈值：\n最小支持度 和 最小置信度\n\n满足最小置信度和最小支持度的规则为强规则，否则为弱规则\n关联规则挖掘的实质是在数据库（数据仓库）中寻找强规则\n\n\n\n支持度：\n置信度：\n2、Apriori算法推荐博客\n（1）基本概念\n项在数据库中出现的属性值，每一个属性值构成一个项\n项集在数据库中出现的属性值的集合\nk-项集由k个项构成的项集\n频繁项集\n该项集在数据库中出现的频度满足用户规定的最小支持度的要求\n即同时含有该项集中的所有属性值的记录数 占 所有记录数的百分比 大于等于用户规定的最小支持度\n\n\n关联规则一定是在满足用户的最小支持度要求的频繁项集中产生的\n关联规则的挖掘过程也就是在数据库中寻找频繁项集的过程\n寻找频繁项集过程中，遵循每个频繁项集的任一子集也是一个频繁项集\n\n\n\n（2）寻找频繁项集的方法\n\n寻找一阶频繁项集C1除去非频繁项集，得到L1\n从L1生成二阶超集，即候选频繁项集C2除去非频繁项集，得到L2\n从L2生成三阶超集C3除去暂时不需要考虑的更高阶超集除去非频繁项集，得到L3\n……\n\n最后得到的频繁项集是L1、L2、L3……的并\n\nApriori算法：执行算法之前，用户需要先给定最小的支持度和最小的置信度。生成关联规则一般被划分为如下两个步骤：\n\n利用最小支持度从数据库中找到频繁项集。\n给定一个数据库 D ，寻找频繁项集流程如下图所示\n    首先寻找一阶频繁项集C1，C1中，{1}的支持度为2/4 = 0.5（数据库D中一共四条事物，{1}出现在其中的两条事物中），C1中的其他几个也是这么计算的，假设给定的最小支持度 $SUP_{min} = 0.5$，{4}就被排除了，得到L1。\n\n    接下来从L1生成二阶超集，即候选频繁项集C2，除去非频繁项集（也就是低于SUP_min = 0.5的），得到L2。\n\n    从L2生成三阶超集C3，除去暂时不需要考虑的更高阶超集，除去非频繁项集，得到L3\n\n    我们可以看到 itemset 中所包含的 item 是从 1 增长到 3 的。并且每次增长都是利用上一个 itemset 中满足支持度的 item 来生成的，这个过程称之为**候选集生成**\n\n\n利用最小置信度从频繁项集中找到关联规则。（3）中内容\n同样假定最小的置信度为 0.5 ，从频繁项集 {2 3 5} 中我们可以发现规则 {2 3} ⇒ {5} 的置信度为 1 &gt; 0.5 ，所以我们可以说 {2 3} ⇒ {5} 是一个可能感兴趣的规则。（这里看不懂的话看一下上面置信度公式就懂了）\n\n\n如何发现全部的频繁项集？\n包含N种物品的数据集共有2^N-1种不同的项集，例如包含4种物品的全部项集：\n（3）生成关联规则\n\n由此确定关联规则的生成算法：（输入参数：数据集和一个频繁项集）\n\n针对频繁项集{A,C}可以构造两条规则\nR1：A-&gt;CR2：C-&gt;A\n\n一阶频繁项集无法构造关联规则，只能得到平凡知识将每个频繁项集分为左右两部分，穷举即可以得到\n\n对这些规则进行测试（依次计算置信度，用到的支持度数据在生成频繁项集的时候都存下来了）\n\n通过预先设定的阈值对关联规则进行过滤\n\n合并所有第一个列表中的剩余规则，创建第二个规则列表，其中规则右部包含两个元素\n\n对第二个列表中的规则进行测试\n\n过程重复到N为止（或者无法产生新规则）\n\n最后剩余的关联规则上升为知识，用于决策支持\n\n\n\n比如上面那个例子{2,3,5}，就可以分为 {2}–&gt;{3,5} 与 {2,3}–&gt;{5}，然后计算置信度，也就是\n置信度con(X–&gt;Y) = (X U Y)/X。这里有个窍门\n假设最小置信度为p，且规则0,1,23并不满足最小置信度要求，即 P(0,1,2,3)/P(0,1,2)&lt;p那么任何左部为{0,1,2}的子集的规则也不会满足最小置信度要求\n\n（5）Apriori算法的优化方法由于算法是时间开销花在数据库的多次扫描上，主要的优化方法有：\n\n数据库的划分（Partitioning）方法\n针对硬件限制进行优化\n虽然置信度和支持度指标可能有变化，但\n所有关联规则一定都会出现在各个划分中\n划分可能导致产生的关联规则数量过大，提高阈值又会损失原有的规则\n\n每一部分都能全部放在内存中进行扫描\n最后对得到的所有频繁项集进行归并\n\n\n利用Hash方法筛选2阶频繁项集将每个项哈希到哈希表里，从而大量地过滤不需要的候选集\n\n利用采样数据集得到可能成立的规则，再利用数据库中的剩余数据验证这些规则的正确性由于无法保证结论的正确性，此方式未必靠谱\n\n减少每一遍扫描所处理的记录数\n如果一条记录不含有长度为k的频繁项集，那么这条记录也不可能含有长度为(k+1)的频繁项集\n\n得到所有k阶频繁项集后，以后的每次扫描就不必再访问上述的记录，从而逐步减少被扫描的记录数\n\n\n3、FP-Growth算法（1）介绍FP核心：利用FP树递归地增长频繁模式路径（分治）\nFP优点：去除了不相关的信息；出去节点连接和计数规模比原数据库小；快速；将发现长频繁模式的问题转换成递归地搜索一些较短的模式。\n关联分析算法，它采取如下分治策略：将提供频繁项集的数据库压缩到一棵频繁模式树（FP-Tree），但仍保留项集关联信息；该算法和Apriori算法最大的不同有两点：第一，发现频繁项集而不产生候选  ，第二，只需要两次遍历数据库，大大提高了效率。但是FP-Growth算法只能用来发现频繁项集，不能用来发现关联规则。\n（2）算法伪代码详细见博客\n（3）PPT例子博客\n给定数据库D以及min_sup\n\n\nFP-Tree构建——第一步\n第一步：扫描数据库，得到一阶频繁项集。由于min_sup = 0.5，所以至少出现3次，低于3次的直接不考虑了，得到项集如下\n\n\n\n\nFP-Tree构建——第二步\n第二步：以频率递减的顺序对频繁项进行排序，注意里面的顺序\n\nFP-Tree构建——第三步\n每个事务中的数据项按降序依次插入到一棵以NULL为根结点的树中，这样所有的ordered frequent items都保存在了树中。，排序靠前的节点是祖先节点，而靠后的是子孙节点。如果有共用的祖先，则对应的公用祖先节点计数加1。插入后，如果有新节点出现，则项头表对应的节点会通过节点链表链接上新节点。直到所有的数据都插入到FP树后，FP树的建立完成。\n\nFP-Tree挖掘——第一步\n 得到了FP树和项头表以及节点链表，我们首先要从项头表的底部项依次向上挖掘。对于项头表对应于FP树的每一项，我们要找到它的条件模式基。条件模式基是以我们要挖掘的节点作为叶子节点所对应的FP子树。得到这个FP子树，我们将子树中每个节点的的计数设置为叶子节点的计数，并删除计数低于支持度的节点。从这个条件模式基，我们就可以递归挖掘得到频繁项集了。\n\n\n\n      意思是item是x的时候，也就是后缀是x，他的前缀有哪些？出现次数是多少个。比如后缀是c，前缀是f，出现了3次；再比如后缀是b的，他的前缀有fca（1次），f（1次），c（1次），就这个意思\n\nFP-Tree挖掘——第二步\n将得到的FP子树的每个节点的计数设置为叶子节点的而计数，并删除计数低于支持度（这里至少是3）的节点。我们就可以得到频繁项集。\n\n\n  一定要看这个例子\n   举例叶子结点是一阶的情况\n   从底向上挖掘。先看p，它的频繁项集为{f:2,c:3,a:2,m:2,b:1,p:3}、前面5个代表条件模式基（大白话就是每个出现了几次，比如c出现了2+1次）,f、a、m、b的个数低于3个，低于我们要求的支持度，删除，合并一下，得到p结点的频繁二项集{c:3,p:3}，p对应的最大的频繁项集为频繁二项集。\n   再看m，它的频繁项集为f:3,c:3,a:3,b:1,m:3}，删除b，得到m的频繁四项集{f:3,c:3,a:3m:3}\n   再看b，它的频繁项集为{f:2,c:2,a:1,b:3}，删除fca，他只是个平凡知识，empty\n   再看a，它的频繁项集为{f:3,c:3,a:3}，这就是它的三阶频繁项集\n   再看c，…..\n   老师举的例子（一阶）\n   一阶结果，明显和我们刚才做的思路结果一致\n   举例叶子结点是二阶及以上的情况，同样思路\n第六章：分类挖掘1、数据分类\n通过分析训练数据样本，产生关于类别的精确描述\n这种类别通常由分类规则组成，可以用来对未来的数据进行分类和预测\n\n首先为每一个数据（记录）打上一个标记，即按标记对数据（记录）进行分类，而分类分析则是对每类数据（具有相同标记的一组记录）找出其固有的特征与规律。\n2、数据分类的步骤建立一个模型，描述给定的数据类集或概念集，通过分析由属性描述的数据库元组来构造模型\n\n用于建立模型的元组集称为训练数据集，其中每个元组成为训练样本训练样本的性质与待分析样本本质上没有差别，都是在实际环境中累积得到的数据\n每个训练样本属于一个预定义的类，由类标号属性确定\n由于给出了类标号属性，因此该步骤又成为有指导的学习需要知道分类的数量，与对应分类对人来说的意义如果训练样本的类标号是未知的，则称为*无指导的学习（聚类）*\n学习模型可以用分类规则、决策树和数学公式的形式给出\n\n使用模型对数据进行分类\n\n评估模型的分类准确性训练数据和测试数据性质应当是一样的，但不能是两份相同的数据评价的标准包括正确性、效率、可理解性\n对类标号未知的元组按模型进行分类\n\n3、分类分析方法是一种特征归纳的方法，将每类数据共有的特性抽取以获得规律性的规则，目前有很多分析方法，看了下往年试卷就考了决策树和朴素贝叶斯\n\n决策树——考试考ID3\n朴素贝叶斯\n通过前验概率和后验概率，决定某一特定样本属于标签中某一分类的概率概率的值根据训练样本提供\n贝叶斯方法得到的结果不唯一，并且能提供相应结果的概率大小\n贝叶斯方法计算复杂在各属性独立时，贝叶斯方法的计算可以简化\n\n\n\n以上两种方法基于信息论，具有很好的可剪枝性\nK邻近算法也考了。。。不难，看一下就好。\n4、决策树——ID3算法（1）概念又称为判定树，是运用于分类的一种树结构\n\n根据对一个判定进行拆分，连接到下一个判定或结论，构成的关系就是一棵决策树\n\n每个内部结点代表对某个属性的一次测试\n\n每条边代表一个测试结果\n\n叶结点代表某个类或者类的分布\n\n最上面的结点是根结点\n\n通过对信息量的计算，判断每个属性对分类所作判断的贡献大小将一个集合S拆分为S1和S2，其信息量大小有以下关系：\nI(S)≥I(S1)+I(S2)（在属性对分类不起任何作用时取等号）属性的信息增益A=I(S)-[I(S1)+I(S2)]\n\n将贡献最优的属性放在顶层，迭代进行\n\n中止条件\n训练数据集为空\n分类已经确定I(S)=0\n属性已经用完，仍然无法确定地分类\n\n\n\n\n\n（2）ID3算法推荐博客\n一种基于决策树的算法，根据信息增益，自顶向下贪心建树，信息增益用于度量某个属性对样本集合分类的好坏程度，我们要选择具有最高信息增益的属性。基于训练对象和已知类标号创建决策树，以信息增益为度量来为属性排序。\n两个类标记：P（假设有p个元素） 和 N（假设有n个元素），用来判断任一元素属于P还是N的信息量为：根据属性A将集合S划分为集合{S1，S2，…，Sv}，在每个Si中，属于类P的元素为Pi，属于N的元素为ni，用来区分的信息量（熵）为\n计算属性A的信息增益 Gain(A)直接看PPT例子\n给了这个一张表，按照哪个属性来分类？\n这个例子中\n\n\nP：buys_computer = “yes” ,N:：buys_computer = “no”,一个14个数据,p:9个，n:5个\n\nI(p, n) = I(9, 5) =0.940\n\nage属性的熵的计算\n\n根据age属性，把整个输入集S划分成了三部分：&lt;=30岁，31～40岁，&gt;40岁\n&lt;=30岁的5人中，yes 2人，no 3人，那就是 5/14*I(2,3)\n31~40岁的4人中，yes 4人，no 0人，那就是 4/14*I(4,0)\n大于40岁的5人中，yes 3人，no 2人，那就是5/14*I(3,2)\n求和可得age属性的熵E(age)\n\n\nGain(age) = I(9,5) - E(age)\n\n按照同样的方法求Gain(income)、Gain(student)、Gain(credit_rating)\n\n\n\n结果\n这样就知道哪个属性的排序了，然后对age分类下的三种情况\n\n在&lt;30情况下，计算信息增益，发现student的信息增益最大，则将student设为节点；\n在30-40之间只有yes，所以不需要计算\n在&gt;40情况下，发现credit rating的信息增益最大，则设它为节点。\n\n\n5、朴素贝叶斯朴素贝叶斯算法的数学基础都是围绕贝叶斯定理展开的，因此这一类算法都被称为朴素贝叶斯算法。分类原理是通过对象的先验概率，利用贝叶斯公式计算出后验概率，即对象属于某一类的概率，选择具有后验概率最大的类作为该对象所属的类。下面是贝叶斯公式，要使P(C|X)最大（先验概率），则要使得P(X|C)·P(C)最大（后验概率），\n\n朴素贝叶斯就是假设属性是独立的情况，特征（属性）之间互相独立\n\n例1\n网球比赛示例，p代表能进行比赛，n代表不能进行比赛，X = &lt;rain, hot, high, false&gt;\n\n例2：贝叶斯信念网络/概率网络\n就是将贝叶斯推理与属性之间的因果关系相结合\nPPT上例题直接看这博客\n\n首先计算患心脏病的先验概率\n\n\nα：E的可能取值，β：D的可能取值\n由于朴素贝叶斯假设属性之间的独立，即E与D独立，则：P(E=α,D=β) = P(E=α) * P(D=β)\n那就是四种情况加起来，PPT顺序错了\n\n用了这些数据\n\n     结论：不得心脏病的概率更大\n\nBP=high的情况下，利用同样方法计算高血压数据，它与HD有关\n\n结论：如果血压高，得心脏病概率更大\n在BP=high,D=healthy,E=yes的情况下HD的概率（血压高，饮食健康，做运动的心脏病的概率）\n第七章：聚类挖掘1、聚类分析聚类分析是在数据中发现数据对象之间的关系，将数据进行分组，组内的相似性越大，组间的差别越大，则聚类效果越好。\n\n又称集群分析，它是研究分类问题的一种多元统计方法\n分为距离聚类和相似系数聚类，即定义相似程度的两种方式，实际上没必要严格地区分\n没有筛选出一小部分数据，经过处理得到模型，再以此模型进行通用处理的两个阶段\n\n与分类分析的混合使用\n由于聚类分析的时间复杂度与整体样本数量有关，因此可以抽样一部分数据进行聚类分析，得到结果后，对每个聚类进行概念规则挖掘，人为确定一些概念规则，再以此规则对剩余数据进行分类\n\n聚类分析输入的是没有被标记的记录，系统按照一定的规则合理的划分记录集合相当于给记录打标记，但分类标准不是用户确定的\n然后采用分类方法对数据进行分析，并根据分析结果重新对原来的记录集合进行划分，进而再进行一次分类分析\n如此循环往复，直到获得满意的分析结果\n\n2、主要的聚类方法\n基于划分方法\n一些场景中，划分聚类的数量k是知道的；即使不知道划分聚类的数量，也是可以以穷举的方法进行确定的（1≤k≤N）\n\n随机地选择k个数据\n将其它所有数据打上距离最近的标记完成一次迭代\n根据当前聚类选择一个实际（或虚拟）的数据点具有代表性的\n第二次迭代，根据选择的点再进行一次划分代表性的数据点继续发生变化\n如此循环往复，直到每个数据的聚类不再发生变化为止\n代表数据点的选择问题\n如果选择实际的数据点作为代表，选择的标准难以确定\n如果选择虚拟的数据点作为代表，数据点又可能没有意义,需要根据实际任务选择类型\n\n\n\n\n基于层次的方法\n将相似程度最大的两个数据合并，以一个虚拟数据点作为其代表，重复进行计算\n\nk值是可以不必给定的以聚类内的相似程度和聚类间的相异程度作为指标\n没有迭代的过程，结果可能并不精确\n\n\n\nps：往年考了K-means算法和 凝聚式层次式距离算法\n3、K-means聚类算法这是一种基于划分的距离技术，它将各个聚类子集内的所有数据样本的均值作为该聚类的代表点，算法的主要思想是通过迭代过程把数据集划分为不同的类别，从而使生成的每个聚类内紧凑，类间独立。\n考试会出现的距离主要是曼哈顿距离\nk-means算法输入：簇的数目k和包含n个对象的数据库。输出：k个簇，使平方误差准则最小。算法步骤：   1.为每个聚类确定一个初始聚类中心，这样就有 K 个初始聚类中心。   2.将样本集中的样本按照最小距离原则分配到最邻近聚类    3.使用每个聚类中的样本均值作为新的聚类中心。  4.重复步骤2.3直到聚类中心不再变化。  5.结束，得到K个聚类\n\n面向考题学习【2012期末】\n\n第一个问题：要求给出相异矩阵，相异度矩阵（存储n个对象两两之间的近似性）。同时，也提出了一个表示n个对象的矩阵，即数据矩阵（用p个变量来表示n个对象），如下图。\n\n我们只需要把每一元组的x、y值带进曼哈顿距离算一下就是答案了-_-\n\n第二个问题：对数据集进行聚类，给定了簇的数量为k = 3，给定了三个起始中心点（3，5）、（2，6）、（3，8），一共12个点（对象），那么对于剩余的9个点（对象），根据其与各个簇中心的距离，将它赋给最近的簇。大白话就是对剩下的点，用曼哈顿距离算一下它和哪个中心点近，就把它归类过去。\n\n就看前三列，取最小的放入对应聚类\n(1,4,6,7,11,12)(2,9)(3,5,8,10)\n\n重新调整三个聚类的中心点\n(1,4,6,7,11,12)\t--&gt; x = (3+3+4+9+5+4)/6 = 4.6;y = (5+4+5+1+2+2)/6 = 3.17\t(4.6,3.17)(2,9) --&gt; x = (2+1)/2 = 1.5;y = (6+6)/2 = 6 (1.5,6)(3,5,8,10) x = (3+7+4+6)/4 = 5;y=(8+7+10+8)/4 = 8.25 (5,8.25)\n\n然后再每个点算到三个中心点的距离，得到三个聚簇\n一直这么算直到聚簇内不变化\n4、凝聚式层次式距离算法【2014期末】b问\n\n把每个点与其他点的距离都算出来，选距离最小的作为初始的那两个点，聚到一起之后算它们的中心点，然后这个中心点和其他n-2个点再算距离，再挑出两个最小的聚到一起，再算中心点…..一直到所有的都聚进来。最后我们想要聚成几类就在倒数第几步砍一刀。比如要求聚成两类，在step3砍一刀，一类是cde，另一类是ab。\n初始a问曼哈顿距离\n\n聚1和3，再计算其他点到新点距离\n\n聚135，再计算其他点到新点距离\n\n聚1352，最后聚成12345\nPs：凝聚式层次式距离算法倒数第二步应该是聚45，写错了\n完结撒花，希望有帮助到你。\n","categories":["NJU"],"tags":["lesson"]}]